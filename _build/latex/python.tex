%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]


\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=2,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}



        % Start of preamble defined in sphinx-jupyterbook-latex %
         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        \hypersetup{
            pdfencoding=auto,
            psdextra
        }
        % End of preamble defined in sphinx-jupyterbook-latex %
        

\title{Data 88E: Economic Models Textbook}
\date{Jan 21, 2022}
\release{}
\author{Data 88E Course Staff}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{content/intro::doc}}


\sphinxAtStartPar
Economics is in the world around us, and so is Data Science! It’s in our every day lives. As we connect Data Science with Economics, we will be exploring real life datasets to illustrate how Economics concepts are shaped and how decisions lead to real\sphinxhyphen{}life impacts. This is a textbook developed for UC Berkeley’s course Data 88E: Economic Models. Data 88E is a generic course listing for Data 8 connector courses.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\Large Course Description}
\end{DUlineblock}

\sphinxAtStartPar
The idea for the class is to take students through a series of exercises to motivate and illustrate key concepts in Economics with examples in Python Jupyter notebooks. The class will cover concepts from Introductory Economics, MIcroeconomic Theory, Econometrics, Development Economics, Environmental Economics and Public Economics. The course will give data science students a pathway to apply python programming and data science concepts within the discipline of economics. The course will also give economics students a pathway to apply programming to reinforce fundamental concepts and to advance the level of study in upper division coursework and possible thesis work.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Acknowledgements}
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{Course Instructor:} Eric Van Dusen

\sphinxAtStartPar
\sphinxstylestrong{Textbook Developer:} \sphinxhref{https://chrispyles.io}{Christopher Pyles}, Rohan Jha

\sphinxAtStartPar
\sphinxstylestrong{Content Developers:} \sphinxhref{http://alanliang.me/}{Alan Liang}, Amal Bhatnagar, Andrei Caprau, \sphinxhref{https://chrispyles.io}{Christopher Pyles}, Eric Van Dusen, Matthew Yep, Rohan Jha, Sreeja Apparaju, Shashank Dalmia, Umar Maniku

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large License}
\end{DUlineblock}

\sphinxAtStartPar
This textbook is licensed under a \sphinxhref{https://github.com/ds-connectors/econ-models-textbook/blob/master/LICENSE}{BSD 3\sphinxhyphen{}Clause License}.


\section{Introduction}
\label{\detokenize{content/00-intro/index:introduction}}\label{\detokenize{content/00-intro/index::doc}}

\subsection{The Financial Benefits of Your Major}
\label{\detokenize{content/00-intro/index:the-financial-benefits-of-your-major}}
\sphinxAtStartPar
Welcome to Data 88E: \sphinxstyleemphasis{Economics Models}! This class will explore the intersection of Data Science and Economics.
Specifically, we will utilize methods and techniques in data science to examine both basic and upper\sphinxhyphen{}division Economics concepts.
Throughout the course, we will consider a variety of economic problems both on the macro and micro level.

\sphinxAtStartPar
In the first demo of the course, we hope to give you a sense of the types problems you can expect to explore this semester by considering a problem that may be of personal relevance to you: the post\sphinxhyphen{}graduate incomes of different majors at Cal.

\sphinxAtStartPar
We will be using various visualization techniques to analyze the median incomes of different majors at UC Berkeley, in addition to the median incomes of those same majors at other colleges.
If you forgot, the median income is the “middle” value: if you sorted all the individual incomes of a major in ascending order, the median would be the value that’s exactly in the middle. The median is also called the 50th percentile – at the median, exactly 50\% of the individuals have an income lower than the median.

\sphinxAtStartPar
Do not be concerned if you don’t understand the code below: this entire exercise is purely a demo to motivate many profound concepts in Economics.
If you’re interested, you may choose to come back to this demo at the end of the course and consider all the different techniques utilized in it \sphinxhyphen{} it’d be a great way of reflecting upon how much you’ve learnt!


\subsection{Data Collection}
\label{\detokenize{content/00-intro/index:data-collection}}
\sphinxAtStartPar
Before we can use data science to tackle any issue, we must–well–obtain data (kind of mind\sphinxhyphen{}boggling, I know).
Recall that we want to examine the median incomes of different majors at UC Berkeley as well as the median incomes of those same majors at other colleges.
The term ‘other colleges’ is a fairly general one, and in this case we shall consider the average median incomes of those majors at alll other colleges in the United States.

\sphinxAtStartPar
In order to obtain a dataset, you can either collect it yourself (via surveys, questionnaires, etc.) or you can use datasets that others have gathered for you.
In this demo, we are combining 3 different datasets:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The median income for each major at Cal was obtained from \sphinxhref{https://career.berkeley.edu/survey/survey}{Cal’s 2019 First Destination survey}.

\item {} 
\sphinxAtStartPar
The median income for each major overall was obtained from surveys conducted by the American Community Survey (ACS) from 2010 to 2012, a very popular data source for Economics Research! In the survey, ACS essentially calls college graduates and asked them their income as well as what they majored in at college. (As a side note, FiveThirtyEight later published this \sphinxhref{https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/}{article} using the results of the survey.) In this project, we will be using a modified version of the ACS survey \sphinxhyphen{} we will only be looking at the respondents who are 28 or younger. Can you think of why we would do this?

\item {} 
\sphinxAtStartPar
The longitudinal data on long\sphinxhyphen{}run outcomes of UC Berkeley alumni was obtained from the \sphinxhref{https://www.universityofcalifornia.edu/infocenter/berkeley-outcomes}{University of California webpage}. We will use this dataset later for a slightly different analysis.

\end{itemize}

\sphinxAtStartPar
Take a moment to consider the ways in which the 3 different datasets were created.
Is it fair to draw direct comparisons between the datasets? What would be some potential issues and how could the differences in our datasets affect our analysis?


\subsubsection{Mean vs Median}
\label{\detokenize{content/00-intro/index:mean-vs-median}}
\sphinxAtStartPar
Before proceeding further, it is important to consider why we are choosing to look at the median, and not the average, income.
In order to answer this question, let us think about what the \sphinxstyleemphasis{distribution} of incomes for a population would look like.
Most likely, you would see a high amount of incomes around or slightly below the mean, with a few massive outlier incomes above the mean.
For example, consider a theatre major who becomes a star on Broadway \sphinxhyphen{} while they’d be doing absolutely fantastic in their career, they are not representative of the average theatre graduate from Berkeley and would likely pull the average income way up.
For this reason, using the median is more \sphinxstyleemphasis{robust}: it gives us a better idea of what the typical graduate for any major can generally expect to earn.

\sphinxAtStartPar
Now we’ll load in all the data.
Take a look at the tables for each dataset.
Note that \sphinxcode{\sphinxupquote{P25th}} referes to the 25th percentile of incomes (the income level at which exactly 25\% of incomes are lower) and \sphinxcode{\sphinxupquote{P75th}} refers to the 75th percentile of incomes (the income level at which exactly 75\% of incomes are lower).
You may not know what all the different columns in the tables mean. That’s okay!
As data scientists, we often encounter a lot of irrelevant data that we will discard later.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Load in table of all majors\PYGZsq{} median incomes at Cal}
\PYG{n}{cal\PYGZus{}income} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cal\PYGZus{}income.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{cal\PYGZus{}income}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)} 
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Load in table of all other universities\PYGZsq{} average major median incomes}
\PYG{n}{other\PYGZus{}income} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{recent\PYGZhy{}grads.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} 
\PYG{n}{other\PYGZus{}income}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
To make direct comparisons across majors, we combined all the tables above into a single one for us to use below.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{majors} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cal\PYGZus{}vs\PYGZus{}all.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{majors}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Our combined table above dropped the columns in above tables that we didn’t need to conduct our exploration.
It has a column \sphinxcode{\sphinxupquote{Median Income Difference}}: this column is the Berkeley median income minus the overall median income for each major.
It gives us a sense of the value of Cal over the average university: the difference is the additional income we recieve from obtaining a Cal degree.

\sphinxAtStartPar
Before moving forward, take a second to consider how well the above tables would match with each other.
For example, Electrical Engineering and Computer Science (EECS) is a popular major at Berkeley. However, the \sphinxcode{\sphinxupquote{majors}} dataset didn’t have a direct equivalent for it.
Instead, the \sphinxcode{\sphinxupquote{majors}} dataset had Electrical Engineering, Electrical Engineering Technologies and Computer Engineering as separate majors.
Since in theory students in EECS focus more on computer engineering, we chose to use the computer engineering data for drawing comparions in our final, combined table.
However, there’s room for ambiguity here and that is another potential flaw in our exploration!

\sphinxAtStartPar
The below graph displays all the median salaries for all the majors in our dataset side by side. Feel free to look at the values for a few seconds \sphinxhyphen{} do you find anything interesting?

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}


\subsection{The most lucrative major}
\label{\detokenize{content/00-intro/index:the-most-lucrative-major}}
\sphinxAtStartPar
Let’s imagine that Belfort is a freshman at Berkeley.
Belfort is a very unique individual \sphinxhyphen{} he is someone who would be equally good at all majors and enjoys all majors equally.
He also believes that money is the most important thing in the world.
These assumptions are vastly oversimplifcations and not the case for anyone in real life; but in Economics you’ll find that we end up making significant simplifications to abstract away all the potential complications!

\sphinxAtStartPar
Since Belfort is equally good at and happy with all majors at Cal, the major he chooses is purely dependent on how much money he can earn after college with that major.
Therefore, he will choose the major with the highest median income.

\sphinxAtStartPar
Let us sort our table by the \sphinxcode{\sphinxupquote{Cal Median}} column in descending order to see which major that would be.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{majors}\PYG{o}{.}\PYG{n}{sort}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Cal Median}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{descending}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
However, what if instead of just wanting the maximum amount of cash after college, Belfort was super proud of getting into Berkeley and instead wanted to maximise the amount of additional benefit he recieves from attending Berkeley over other universities?
Let’s sort our table by the \sphinxcode{\sphinxupquote{Median Income Difference}} column in descending order to see which major would give Belfort the highest additional income from going to Berkeley.

\sphinxAtStartPar
Do any values in either of our sorted table surprise you? Why might that be?

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{majors}\PYG{o}{.}\PYG{n}{sort}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Median Income Difference}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{descending}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Let’s now do the opposite and sort our table by the \sphinxcode{\sphinxupquote{Median Income Difference}} column in ascending order.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{majors}\PYG{o}{.}\PYG{n}{sort}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Median Income Difference}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
As you can see in the table, the median income difference for both nuclear engineering and astrophysics is negative.
This is rather peculiar, especially since Cal has great programs for both those majors.
Why would Cal graduates earn less income than the graduates of the average college for those 2 majors?

\sphinxAtStartPar
\sphinxstyleemphasis{Hint}: consider what each of our datasets describes. Is it an apples\sphinxhyphen{}to\sphinxhyphen{}apples comparison?

\sphinxAtStartPar
The answer is because the dataset with the median incomes for all colleges actually described recent graduates (people who are 28 and younger, rather than just fresh college graduates.
It is likely that most people who graduate with Nuclear Engineering and Astrophysics degrees in other colleges tend to stay in the industry for their fields and keep accumulating experience. This would explain why a dataset that includes data from 28 year olds would have a higher median income than fresh Cal graduates in the same field.


\subsubsection{Generalization and Causal Inference}
\label{\detokenize{content/00-intro/index:generalization-and-causal-inference}}
\sphinxAtStartPar
While Belfort would be equally good at and enjoy all majors equally, the implications for him may not generalize for anyone else.

\sphinxAtStartPar
If you decide to major in EECS, it does not mean that you will have more income post\sphinxhyphen{}grad than that from majoring in anything else. For example, someone who is a fantastic artist but not very good at computer science would probably make far more money majoring in art than in EECS. In addition, just because EECS has the highest median income overall doesn’t mean that any individual is guaranteed a high median income if they decide to major in EECS. Overall, our results are not completely \sphinxstyleemphasis{generalizable} to others.

\sphinxAtStartPar
The causal effect of majoring in EECS on incomes may also be overstated. Consider the fact that those who major in EECS tend to come from families whose parents are already in working in tech. As a result, these students will likely also find better jobs post\sphinxhyphen{}grad. This is what we call a confounding variable – it is positively correlated with our treatment variable of majoring in EECS. If we do not observe this confounding factor, our analysis would likely overstate the effect of an EECS degree on post\sphinxhyphen{}grad incomes.


\subsubsection{A brief discourse on utility}
\label{\detokenize{content/00-intro/index:a-brief-discourse-on-utility}}
\sphinxAtStartPar
From seeing our results, you may be wondering: \sphinxstyleemphasis{why doesn’t everyone just major in EECS then}?

\sphinxAtStartPar
For Belfort, money is the only thing in the world that derives happiness.
However, this is once again an oversimplication for the vast majority of people in the real world.
People derive utility from sources other than just their bank account; often, we choose relatively lower\sphinxhyphen{}paying jobs in order to derive more happiness in our lives.

\sphinxAtStartPar
\sphinxstylestrong{Utility} is a measure of ‘satisfaction’ or ‘happiness’ when we consume a good, while \sphinxstylestrong{disutility} is a measure of ‘unsatisfaction’ or ‘harm’ when we consume a \sphinxstyleemphasis{bad}. In economics, one assumption we will always make is that people will always seek to maximize their utility and minimize their disutility.

\sphinxAtStartPar
However, we encounter \sphinxstyleemphasis{diminishing marginal utility} as we consume more and more of a good. For example, the utility of the first cookie you eat is likely much higher than the 20th cookie you eat. Similarly, we may encounter \sphinxstyleemphasis{increasing marginal disutility} as we consume more and more of a bad. For example, the disutility of the first hour doing something you dread is probably not as bad as the 10th hour of doing something you dread.

\sphinxAtStartPar
For many of us, money provides a source of utility, while working or the studying required to get there may provide a source of disutility. This presents a tradeoff: for some, the disutility from studying EECS or working as a programmer greatly outweights the utility from the money. Perhaps another job in a different field requires significantly lower disutility to achieve, without much impact on the utility of the income associated with it. This phenomenon would explain why not everyone decides to major in EECS!


\subsection{Incomes Over Time: Computer Science vs Economics}
\label{\detokenize{content/00-intro/index:incomes-over-time-computer-science-vs-economics}}
\sphinxAtStartPar
So far our exploration of the data has considered a rather general timeframe of “post graduation”, but perhaps it would be more insightful if we dove in and took a look at how incomes differed across various ages. We can do so using the table below that consists of data collected by the \sphinxhref{http://uccliometric.org/}{UC ClioMetric History Project}.
By compiling a database of digital student transcripts of all UC undergraduates and then linking California wages to individuals in the transcript database,
they were able to produce comprehensive dashboards that visualize demographics, major choices, and long\sphinxhyphen{}run incomes of each UC campus’s alumni over the past 70 years.

\sphinxAtStartPar
You can learn more about how they collected the data \sphinxhref{https://www.universityofcalifornia.edu/infocenter/long-run-methodology}{here}, but for now we will just focus on a snapshot of the data.
In particular, we are interested in exploring how percentile incomes compare between Cal alumni who majored in computer science versus those who majored in economics. Run the following cell to check it out.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cs\PYGZus{}vs\PYGZus{}econ}\PYG{o}{=}\PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cs\PYGZus{}econ\PYGZus{}by\PYGZus{}age.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{cs\PYGZus{}vs\PYGZus{}econ}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here we have a table where each row corresponds to a certain age.
It begins with age 23 (typically how old people are when getting their first job out of college), and goes up until age 62 (when people retire from the workforce).

\sphinxAtStartPar
Let’s graph our data using some line plots: line plots are especially useful when trying to visualize trends that change over time.

\sphinxAtStartPar
Run the following cell to visualize the data. The yellow lines correspond to CS incomes, while the blue lines correspond to Econ incomes.

\noindent\sphinxincludegraphics{{index_26_0}.png}

\sphinxAtStartPar
Let’s take a look at how the incomes compare at each percentile. The most notable trend is probably the fact that for the most the part, CS majors typically make more money than Econ majors.
We especially observe this trend in the 25th and 50th percentiles, and this follows accordingly with our exploration earlier in the notebook that students who majored in L\&S Computer Science on average had a higher median income than pretty much every other major.

\sphinxAtStartPar
The graph above helps explain why CS is one of the most popular majors here at Berkeley.
Software engineering and related disciplines have a huge demand for fresh talent, so that individuals entering these fields are duly compensated. This in and of itself is a big appeal of students wanting to major in computer science.

\sphinxAtStartPar
Right off the bat out of college, fresh CS graduates are looking at a six figure income: even the 25th percentile of CS majors are making over \$103,000 by the time they are 25. At any given percentile level, CS graduates outearn their Economics counterparts immediately post\sphinxhyphen{}graduation.


\subsubsection{Intertemporal Effects}
\label{\detokenize{content/00-intro/index:intertemporal-effects}}
\sphinxAtStartPar
However, we don’t just choose our majors based off of the immediate post\sphinxhyphen{}graduation income. Intuitively, we would want to maximize our total lifetime income we make. This idea is called \sphinxstyleemphasis{intertermporal utility maximization}: Economists often take into account one’s utility across all possible time periods.

\sphinxAtStartPar
Considering lifetime income, which major would be better? Well, it depends: if you are at the bottom 25th or 50th percentile, CS is better. This suggests that the typical Economics major will likely never outearn the the typical CS major.

\sphinxAtStartPar
However, we observe that Economics majors at higher percentiles ultimately overtake CS majors in earnings. Intuitively, this should make sense. Perhaps top Economics majors are more likely to become successful executives later on in their careers while make more money than top CS majors, who continue to stay as software engineers or become engineering managers.


\subsubsection{Risk}
\label{\detokenize{content/00-intro/index:risk}}
\sphinxAtStartPar
We observe that Economics majors have a much larger spread in their lifetime earnings than CS majors: top Economics graduates make significantly more than bottom Economics graduates, compared to top CS and bottom CS graduates.

\sphinxAtStartPar
This brings to the light the notion of risk. Majoring in CS carries relatively lower variance: whether you are
a top notch developer in the 75th percentile or a subpar developer in the 25th percentile, you will probably make a solid living. Since most CS majors typically end up pursuing similar careers in the realms of software development, there is less \sphinxstylestrong{variance} in the occupations. There is also less \sphinxstylestrong{risk}: most CS majors can expect to land a software engineering job and continue working as one twenty years into their career.

\sphinxAtStartPar
The same story is less true for Economics majors: a top\sphinxhyphen{}notch Economics major will significantly out\sphinxhyphen{}earn a subpar Economics major. This is partly due to the vastly differing occupation types Economics majors become: analysts, bankers, consultants, just to name a few (Economics is a very versatile degree, afterall). Twenty years down the line, the top Economics majors will have higher ceilings perhaps with a lot of opportunity for leadership or executive positions. There is a lot more \sphinxstylestrong{variance} in the types of jobs and thus salaries that Economics majors will attain. In addition, there is a lot more \sphinxstylestrong{risk}: not every Economics major will become a top executive, and most end up with more ‘average’ jobs that earn less than that of similar percentile CS majors.

\sphinxAtStartPar
This means that if you know you are at the top regardless of your major, you will tend to ultimately earn more income as an Economics major than a CS major. But a caveat: it’s impossible to guarantee that you will be in the top, no matter how hard you work. Often, life has uncertainties and involves a great deal of luck to become successful.

\sphinxAtStartPar
The table and graph above only considered the percentile incomes of CS and Economics majors, but if you’re interested in drawing more comparisons, check out \sphinxhref{https://www.universityofcalifornia.edu/infocenter/berkeley-outcomes}{this page}. You can compare between all types of popular majors at UC Berkeley, and even toggle around with more features like gender, ethnicity, or even specific courses.


\subsection{An Afterword}
\label{\detokenize{content/00-intro/index:an-afterword}}
\sphinxAtStartPar
In this demo, we’ve covered a series of fundamental Economics ideas such as income, utility, and risk. We’ve also gone over a series of more statistical concepts that are also at the heart of empirical Economics such as causal inference, generalization, and unobserved variables. We did this all using data science techniques and visualizations, while being cognizant of potential sources of error. We will be revisiting a lot of these themes in later parts of the course.

\sphinxAtStartPar
From this exercise you may have noticed that pursuing either Economics, Data Science, or both are great options in terms of post\sphinxhyphen{}graduation incomes. This means you’ve probably chosen wisely to have ended up in this class.

\sphinxAtStartPar
Welcome to Data 88E!


\section{Demand and Elasticities}
\label{\detokenize{content/01-demand/index:demand-and-elasticities}}\label{\detokenize{content/01-demand/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{Student Learning Outcomes:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Understand basic properties of the demand curve, including movements along and shifts in the curve

\item {} 
\sphinxAtStartPar
Examine different types of demand curves and their implications: non\sphinxhyphen{}log, semi\sphinxhyphen{}log, and log\sphinxhyphen{}log

\item {} 
\sphinxAtStartPar
Use \sphinxcode{\sphinxupquote{np.polyfit}} to create a demand curve from provided data

\item {} 
\sphinxAtStartPar
Understand different types of elasticities and calculate price elasticities for demand

\end{itemize}


\subsection{Demand Curves}
\label{\detokenize{content/01-demand/01-demand:demand-curves}}\label{\detokenize{content/01-demand/01-demand::doc}}
\sphinxAtStartPar
In this chapter, we will explore one of the most foundational yet important concepts in economics: demand curves. The demand curve shows the graphical relationship between the price of a good or service and the quantity demanded for it over a given period of time.
In other words, it shows the quantity of goods or services consumers are willing to buy at each market price.
The quantity of goods or services demanded or supplied can be modeled as a function of price, as in:
\begin{equation*}
\begin{split}\text{Quantity} = f(\text{Price})\end{split}
\end{equation*}
\sphinxAtStartPar
Notably, the curve is downwards sloping because of the law of demand, which states that \sphinxstyleemphasis{as the price of a good or service increases, the quantity demanded for it decreases, assuming all other factors are held constant}.

\sphinxAtStartPar
This should make intuitive sense: as prices increase, fewer people are willing to pay the higher price for the same good. On the other hand, as prices decrease, more people are willing to pay the lower price for the same good. Hence, the quantity demanded of a good or service has an inverse relationship with the price.

\sphinxAtStartPar
For now, let’s assume that the relationship is somewhat linear and can be described as
\begin{equation*}
\begin{split}\text{Quantity}_{d}=-a \cdot \text{Price}_{d} + b\end{split}
\end{equation*}
\sphinxAtStartPar
We can interpret the equation above as follows: \sphinxstyleemphasis{as the price of a unit increases by 1, there is an \(a\) unit decrease in the quantity demanded.} For example, \(\text{Quantity}_{d}=-2 \cdot \text{Price}_{d} + 3\) would suggest that a price increase by 1 would decrease overall quantity demanded in the market by 2.

\sphinxAtStartPar
Price can also be measured as function of quantity to denote demand. In this case, we use an inverse demand function, as it is the inverse function of the demand function above. Since price is a function of quantity,
\begin{equation*}
\begin{split}\text{Price} = f(\text{Quantity})\end{split}
\end{equation*}
\sphinxAtStartPar
As we are solving for the inverse of the previous demand function, the inverse demand function for the example above is
\begin{equation*}
\begin{split}\text{Price}_{d}=-\frac{1}{2} \cdot \text{Quantity}_{d} - \dfrac{3}{2}\end{split}
\end{equation*}

\subsubsection{Movement and the Demand Curve}
\label{\detokenize{content/01-demand/01-demand:movement-and-the-demand-curve}}

\paragraph{Shifts in the Demand Curve}
\label{\detokenize{content/01-demand/01-demand:shifts-in-the-demand-curve}}
\sphinxAtStartPar
The demand curve can shift in or out based on exogenous events that occur outside of the market.
Some factors other than a change in price of the good/service could be changes in:
\begin{itemize}
\item {} 
\sphinxAtStartPar
buyer’s income

\item {} 
\sphinxAtStartPar
consumer preferences

\item {} 
\sphinxAtStartPar
expectation of future price/supply/demand

\item {} 
\sphinxAtStartPar
changes in the price of related goods

\end{itemize}

\sphinxAtStartPar
If any of these changes occur and causes the demand for the selected good/service to decrease, then the curve shifts to the left as less of the good or service will be demanded at every price. Similarly, if any of these changes causes the demand for the selected good/service to increase, the curve would shift to the right. This signifies that more of the good or service will be demanded at every price. For example, consumers’ incomes decreased during the 2008 recession, thus decreasing overall buying power and shifting the demand curve leftwards; a left shift in the demand curve suggests that consumers would purchase fewer quantities of goods at every price.

\noindent\sphinxincludegraphics{{01-demand_4_0}.png}


\paragraph{Movements along the Demand Curve}
\label{\detokenize{content/01-demand/01-demand:movements-along-the-demand-curve}}
\sphinxAtStartPar
Above, we looked at when exogenous events affect the demand curve. Another concept is movements along the demand curve, which would be considered endogenous events. In movements along the demand curve, changes in price affect the quantity demanded of the good or service. This assumes ceteris paribus, which means holding all other factors constant. This phenomenom is called the Movement of the Demand Curve. With a change in price, the quantity demanded for the good or service can shift the quantity demanded either upward or downward on the demand curve. For example, consider the shift on the graph below from quantity \(q_1\) at price \(p_1\) to quantity \(q_2\) at price \(p_2\).

\noindent\sphinxincludegraphics{{01-demand_7_0}.png}


\subsubsection{Income and Substitution Effect}
\label{\detokenize{content/01-demand/01-demand:income-and-substitution-effect}}
\sphinxAtStartPar
Changes in the price of a good also leads to 2 effects, which can help explain the law of demand:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Income Effect}: Examines how the change in price of the good affects income, which then affects the quantity demanded of a good or service. If the price of a good increases, it would require the consumer to spend more of their income on the good. This dissuades consumers from purchasing more of the good, decreasing the quantity demanded. If the price of a good decreases, consumers would spend less money to receive the same good. This increases the quantity demanded for the good, because consumers would have more income remaining to purchase additional units, given the increase in the amount of purchasing power required to obtain the good.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Substitution Effect}: Examines how the change in price of the good affects its demand relative to other goods and services. If the price of a good increases, then consumers might look at similar goods that function in the same way or yield an equivalent amount of utility as the original good. Consumers are effectively shifting or substituting away from the relatively more expensive good to a cheaper alternative, thereby decreasing the quantity demanded for the original good. The converse is also true: if the price of a good decreases, then consumers that currently purchase other similar goods might start consuming this good instead, because it would cost less money for them to obtain.

\end{itemize}

\sphinxAtStartPar
For example, if the price of gas increases, the higher price for gas might encourage consumers to look at purchasing more efficient cars, such as electric or hybrid cars, thus decreasing the demand for gas. This is the subsitution effect. If the consumer stays with their original car, then they would have less disposable income after purchasing the now\sphinxhyphen{}more\sphinxhyphen{}expensive gas, so they might purchase less gas. This is the income effect.


\subsection{An Empirical Demand Curve}
\label{\detokenize{content/01-demand/02-example:an-empirical-demand-curve}}\label{\detokenize{content/01-demand/02-example::doc}}
\sphinxAtStartPar
Let’s examine some historical data on non\sphinxhyphen{}organic avocado prices and sales volumes in San Francisco from 2015 to 2018. The original dataset is taken from Kaggle and can be found \sphinxhref{https://www.kaggle.com/neuromusic/avocado-prices}{here}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{avocados} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{avocados.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} is it avocados or avocadoes?}
\PYG{n}{avocados}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Date       | Average Price | Total Volume
2015\PYGZhy{}12\PYGZhy{}27 | 1.05          | 692206
2015\PYGZhy{}12\PYGZhy{}20 | 1.15          | 637091
2015\PYGZhy{}12\PYGZhy{}13 | 1.22          | 616016
2015\PYGZhy{}12\PYGZhy{}06 | 1.06          | 694982
2015\PYGZhy{}11\PYGZhy{}29 | 1.05          | 651639
2015\PYGZhy{}11\PYGZhy{}22 | 1.04          | 709444
2015\PYGZhy{}11\PYGZhy{}15 | 0.99          | 775849
2015\PYGZhy{}11\PYGZhy{}08 | 1.4           | 599884
2015\PYGZhy{}11\PYGZhy{}01 | 0.97          | 869927
2015\PYGZhy{}10\PYGZhy{}25 | 1.55          | 561342
... (159 rows omitted)
\end{sphinxVerbatim}


\subsubsection{Visualizing the Relationship between Price and Quantity}
\label{\detokenize{content/01-demand/02-example:visualizing-the-relationship-between-price-and-quantity}}
\sphinxAtStartPar
To construct the demand curve, let’s first see what the relationship between price and quantity is. We would expect to see a downward\sphinxhyphen{}sloping line between price and quantity; if a product’s price increases, consumers will purchase less, and if a product’s price decreases, then consumers will purchase more.

\sphinxAtStartPar
To find this, we will create a scatterplot and draw a regression line (by setting \sphinxcode{\sphinxupquote{fit\_line = True}} in the \sphinxcode{\sphinxupquote{tbl.scatter}} call) between the points. Regression lines are helpful because they consolidate all the datapoints into a single line, helping us better understand the relationship between the two variables.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{avocados}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Total Volume}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Average Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{fit\PYGZus{}line} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{width} \PYG{o}{=} \PYG{l+m+mi}{7}\PYG{p}{,} \PYG{n}{height} \PYG{o}{=} \PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Demand Curve for Avocados}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{fontsize} \PYG{o}{=} \PYG{l+m+mi}{16}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{02-example_4_0}.png}

\sphinxAtStartPar
The visualization shows a negative relationship between quantity and price, which is exactly what we expected! As we’ve discussed, as the price increases, fewer consumers will purchase avocados, so the quantity demanded will decrease. This corresponds to a leftward movement along the demand curve. Alternatively, as the price decreases, the quantity sold will increase because consumers want to maximize their purchasing power and buy more avocados; this is shown by a rightward movement along the curve.

\sphinxAtStartPar
As a quick refresher, scatterplots can show positive, negative, or neutral correlations among two variables:
\begin{itemize}
\item {} 
\sphinxAtStartPar
If two variables have a positive correlation, then as one variable increases, the other increases too.

\item {} 
\sphinxAtStartPar
If two variables have a negative correlation, then as one variable increases, the other decreases.

\item {} 
\sphinxAtStartPar
If two variables have a neutral correlation, then if one varible increases, the other variable is unaffected.

\end{itemize}

\sphinxAtStartPar
Note that scatterplots do not show or prove causation between two variables– it is up to the data scientists to prove any causation.


\subsubsection{Fitting a Linear Demand Curve}
\label{\detokenize{content/01-demand/02-example:fitting-a-linear-demand-curve}}
\sphinxAtStartPar
We will now quantify our demand curve using NumPy’s \sphinxhref{https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html}{\sphinxcode{\sphinxupquote{np.polyfit}} function}. \sphinxcode{\sphinxupquote{np.polyfit}} returns an array of size 2, where the first element is the slope and the second is the \(y\)\sphinxhyphen{}intercept.

\sphinxAtStartPar
It takes 3 parameters:
\begin{itemize}
\item {} 
\sphinxAtStartPar
array of x\sphinxhyphen{}coordinates

\item {} 
\sphinxAtStartPar
array of y\sphinxhyphen{}coordinates

\item {} 
\sphinxAtStartPar
degree of polynomial

\end{itemize}

\sphinxAtStartPar
Because we are looking for a \sphinxstylestrong{linear} function to serve as the demand curve, we will use 1 for the degree of polynomial.

\sphinxAtStartPar
The general template for the demand curve is \(y = mx + b\), where \(m\) is the slope and \(b\) is \(y\)\sphinxhyphen{}intercept.


\paragraph{Demand with Price as a Function of Quantity}
\label{\detokenize{content/01-demand/02-example:demand-with-price-as-a-function-of-quantity}}
\sphinxAtStartPar
First, we will fit a demand curve expressed in terms of price as a function of quantity. This aligns with the axes of supply and demand curves, in which the quantity is on the x\sphinxhyphen{}axis and price is on the y\sphinxhyphen{}axis:
\begin{equation*}
\begin{split}P(Q) = m\cdot Q + b\end{split}
\end{equation*}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{slope}\PYG{p}{,} \PYG{n}{intercept} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{polyfit}\PYG{p}{(}\PYG{n}{avocados}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Total Volume}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{avocados}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Average Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The slope is:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{slope}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The intercept is:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{intercept}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
The slope is: \PYGZhy{}1.0909269659806726e\PYGZhy{}06
The intercept is: 2.2495304122570334
\end{sphinxVerbatim}

\sphinxAtStartPar
Thus, our demand curve is \(P(Q) = -0.00000109Q+ 2.2495\); The slope is \sphinxhyphen{}0.00000109 and \(y\)\sphinxhyphen{}intercept is 2.2495. This means that as the quantity demanded increases by 1 unit (in this case, 1 avocado), we would expect to see price to decrease by 0.00000109 units.

\sphinxAtStartPar
We can plot this line on a graph. Notice that it is the same line as the one when we indicated \sphinxcode{\sphinxupquote{fit\_line=True}} above.

\noindent\sphinxincludegraphics{{02-example_12_0}.png}


\paragraph{Demand with Quantity as a Function of Price}
\label{\detokenize{content/01-demand/02-example:demand-with-quantity-as-a-function-of-price}}
\sphinxAtStartPar
Our interpretation of the demand curve and its slope above was probably not quite intuitive: changes in quantity demanded likely do not trigger changes in price, but instead it is the other way around. In addition, the slope was tiny: the marginal increase of one additional avocado sold had very little effect from the change in price.

\sphinxAtStartPar
Thus, it is more intuitive to think the effect a one dollar change in price has on the quantity demanded, and to flip our axes:
\begin{equation*}
\begin{split}D(P) = Q(P) = m\cdot P + b\end{split}
\end{equation*}
\sphinxAtStartPar
In this course, we will write \(Q(P)\) and \(D(P)\) fairly interchangeably when referencing demand.

\sphinxAtStartPar
One key thing to remember: our axes are flipped for this demand curve! If you want to plot it, note that the left hand side (dependent variable) is actually the x\sphinxhyphen{}axis variable, while the independent variable is the y\sphinxhyphen{}axis variable.

\sphinxAtStartPar
Fitting our data using this function, we get:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{slope}\PYG{p}{,} \PYG{n}{intercept} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{polyfit}\PYG{p}{(}\PYG{n}{avocados}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Average Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{avocados}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Total Volume}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The slope is:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{slope}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The intercept is:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{intercept}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
The slope is: \PYGZhy{}476412.7189820772
The intercept is: 1446951.6408050181
\end{sphinxVerbatim}

\sphinxAtStartPar
Here, our demand curve is roughly \(Q(P) = -476413P+ 1446952\); the slope is \sphinxhyphen{}476413 and \(y\)\sphinxhyphen{}intercept is 1446952. This means that as the price increases by 1 unit (in this case, \$1), we would expect to see quantity demanded to decrease by 476413 units (in this case, 476413 avocados).

\sphinxAtStartPar
Note that this demand curve is not the same as the previous demand curve! It is not simply the inverse of the previous demand curve.

\sphinxAtStartPar
Plotting this line on a graph, we see a slightly different demand curve: can you see what is different between the two?

\noindent\sphinxincludegraphics{{02-example_18_0}.png}


\subsection{Log\sphinxhyphen{}log and Semi\sphinxhyphen{}log Demand Curves}
\label{\detokenize{content/01-demand/03-log-log:log-log-and-semi-log-demand-curves}}\label{\detokenize{content/01-demand/03-log-log::doc}}
\sphinxAtStartPar
So far, we have examined demand curves assuming that they were linear. Specifically, we’ve assumed that the relationship between quantity demanded and price was linear: for a \$1 change in price, we can expect a fixed change in units demanded at any price level.

\sphinxAtStartPar
Is this intuitively true? Probably not. For example, a \$1 decrease from \$100 is trivial compared to a \$1 decrease from an original price of \$2. As humans, we think about changes as proportions, and this fact should be reflected in the supply and demand curves. What this implies is that these curves should be exponential in nature: at higher prices, a larger change in price will yield the same change quantity as compared to that in lower prices.

\sphinxAtStartPar
Perhaps a better model for demand, then, is that a 1\% change in price will lead to a fixed absolute change in units demanded, or a fixed percentage change in units demanded. To model this, we turn to log\sphinxhyphen{}log and semi\sphinxhyphen{}log demand curves, respectively.


\subsubsection{Using Logarithms for Proportional Changes}
\label{\detokenize{content/01-demand/03-log-log:using-logarithms-for-proportional-changes}}
\sphinxAtStartPar
Before we jump into our new demand models, we must first go over measuring proportional changes.
To highlight this fact, let’s actually consider how the variable GDP behaves. GDP tends to grow by a certain percent each year; no one is particularly interested in how \sphinxstyleemphasis{much} GDP changes from one year to the next, or from one country to another, but rather by \sphinxstyleemphasis{what percent} it changes.

\sphinxAtStartPar
If you were to plot GDP over time for a country, it might look something like this:

\noindent\sphinxincludegraphics{{03-log-log_5_0}.png}

\sphinxAtStartPar
The starting value for GDP is 100, and GDP grows by 5 percent each year. Look at how how much GDP grows in the later years!

\sphinxAtStartPar
While this phenomenon is impressive, it is misleading. At surface level, it seems to imply that something different happened at around year 50 or so that caused GDP to increase considerably in subsequent years. We know that this isn’t true, and that this is just a consequence of exponential growth.

\sphinxAtStartPar
To counter this effect, \sphinxstylestrong{for variables that tend to vary from one observation to the next by proportions rather than absolute amounts, we take the natural log of these variables}. Let’s do that for GDP:

\noindent\sphinxincludegraphics{{03-log-log_7_0}.png}

\sphinxAtStartPar
We’ve now uncovered a linear relationship between years and GDP! You can interpret the slope of this line as the approximate \sphinxstyleemphasis{percent change} in GDP for an increase in one year (you will later see why the slope is not exactly 0.05). To verify:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Slope between years 0 and 1: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{ln\PYGZus{}GDPs}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{\PYGZhy{}} \PYG{n}{ln\PYGZus{}GDPs}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Slope between years 0 and 1:  0.04879016416943127
\end{sphinxVerbatim}

\sphinxAtStartPar
To generalize our results, taking the natural log of a variable allows us to interpret its change as a percentage change instead of an absolute change. Using our GDP example from above, the slope after taking the natural log of GDP is now roughly equal to:
\begin{equation*}
\begin{split}\text{slope} = \frac{\text{Change in GDP \%}}{\text{Change in year}} \approx \frac{\text{Change in log-GDP} \times 100}{\text{Change in year}} \end{split}
\end{equation*}

\subsubsection{Semi\sphinxhyphen{}log Demand Curves}
\label{\detokenize{content/01-demand/03-log-log:semi-log-demand-curves}}
\sphinxAtStartPar
Revisiting demand curves, suppose that a change in price by \$1 leads to a m\% change in quantity demanded. This means that our slope would be:
\begin{equation*}
\begin{split}\text{slope} = \frac{m \text{\% change in quantity}}{ \text{ \$1 change in price}} \approx \frac{m \times 0.01 \text{ change in log-quantity}}{ \text{\$1 change in price}}\end{split}
\end{equation*}
\sphinxAtStartPar
Using our intuition from above, we simply have to log transform our quantity\sphinxhyphen{}demanded variable to capture the above relationship. This is known as the semi\sphinxhyphen{}log demand curve, in which the price and log\sphinxhyphen{}quantity are linearly related:
\begin{equation*}
\begin{split}\ln{D(P)} = m\cdot P + b\end{split}
\end{equation*}
\sphinxAtStartPar
Let’s gain some more intuition of this relationship. By exponentiating both sides, this is equivalent to:
\begin{equation*}
\begin{split}\begin{align*}
D(P) &= e^{m\cdot P + b}\\
&= e^be^{m\cdot P } \\
\end{align*}\end{split}
\end{equation*}
\sphinxAtStartPar
This rewriting provides us some intuition on the interpretation of \(m\) and \(b\), the slope and intercept terms in the semi\sphinxhyphen{}log relationship. \(b\) (specifically \(e^b\)) corresponds to the ‘baseline’ quantity demanded when price is 0, since \(e^{m \cdot P} = e^0 = 1\).

\sphinxAtStartPar
\(m\) corresponds roughly to how much a one dollar change in price will lead to a percentage change in quantity demanded. To see this, imagine that P goes up by one dollar such that we have:
\begin{equation*}
\begin{split}
\begin{align*}
D(P+1) &= e^be^{m \cdot (P+1) }  \\
&= e^be^{m + m \cdot P }\\
&= e^be^me^{m \cdot P }\\
&= e^mD(P) \\
&\approx (1+m)D(P)
\end{align*}\end{split}
\end{equation*}
\sphinxAtStartPar
The last line relies on the fact \(e^{x} \approx (1+x)\) when \(x\) is small. This is why in our GDP example, our slope was not exactly 0.05. Thus, our results leads to the caveat that our transformation is only approximate and only valid when our \(m\) is small. Typically, we do not want \(m\) to be larger than \(0.2\), or else the approximation will start to diverge.


\paragraph{Visualizing the semi\sphinxhyphen{}log relationship}
\label{\detokenize{content/01-demand/03-log-log:visualizing-the-semi-log-relationship}}
\sphinxAtStartPar
From above, we can convert the linear semi\sphinxhyphen{}log relationship into non\sphinxhyphen{}log terms for price and quantity, ultimately getting \(D(P) = e^be^{m\cdot P}\). Plotting this relationship, we get:

\noindent\sphinxincludegraphics{{03-log-log_15_0}.png}


\subsubsection{Log\sphinxhyphen{}log Demand Curves}
\label{\detokenize{content/01-demand/03-log-log:log-log-demand-curves}}
\sphinxAtStartPar
Now suppose that a 1\% change in price leads to a m\% change in quantity demanded. This means that our slope would be:
\begin{equation*}
\begin{split}\text{slope} = \frac{m \text{\% change in quantity}}{1 \text{\% change in price}} \approx \frac{m \times 0.01 \text{ change in log-quantity}}{ 0.01 \text{ change in log-price}} = \frac{\text{change by } m  \text{ in log-quantity}}{\text{ change by 1 in log-price}}\end{split}
\end{equation*}
\sphinxAtStartPar
In this case, we have to log transform both our quantity\sphinxhyphen{}demanded variable as well as price variable to capture the above relationship. This is known as the log\sphinxhyphen{}log demand curve, in which the log\sphinxhyphen{}price and log\sphinxhyphen{}quantity are linearly related:
\begin{equation*}
\begin{split}\ln{D(P)} = m\cdot\ln{P} + b\end{split}
\end{equation*}
\sphinxAtStartPar
Let’s gain some more intuition of this relationship. By exponentiating both sides, this is equivalent to:
\begin{equation*}
\begin{split}\begin{align*}
D(P) &= e^{m\cdot\ln{P} + b}\\
&= e^be^{m\cdot\ln{P}} \\
&= e^b(e^{\ln{P}})^m \\
&= e^bP^m \\
\end{align*}\end{split}
\end{equation*}
\sphinxAtStartPar
In this setup, \(b\) does not have as clear a meaning. For \(m\), we can suppose that \(P\) goes up by one percent:
\begin{equation*}
\begin{split}\begin{align*}
D(1.01P) &= e^b(1.01P)^m \\
&= e^b 1.01^m P^m\\
&= 1.01^m D(P) \\
&\approx (1+m) D(P) 
\end{align*}\end{split}
\end{equation*}
\sphinxAtStartPar
Where we utilize the approximation that \(1.01^m \approx 1+m\). Our caveat from the previous section about \(m\) not being large continues to be in place here: typically, we do not want our \(m\) to be larger than 30 (where \(1.01^{30}\approx 1.35\)), or else the approximation will fall apart.


\paragraph{Visualizing the log\sphinxhyphen{}log relationship}
\label{\detokenize{content/01-demand/03-log-log:visualizing-the-log-log-relationship}}
\sphinxAtStartPar
From above, we can convert the linear log\sphinxhyphen{}log relationship into non\sphinxhyphen{}log terms for price and quantity, ultimately getting \(D(P) = e^bP^m\). Plotting this relationship, we can see a demand curve that looks somewhat like an exponential decay curve:

\noindent\sphinxincludegraphics{{03-log-log_20_0}.png}

\sphinxAtStartPar
A caveat about our model: since our model is ultimately linear between log\sphinxhyphen{}price and log\sphinxhyphen{}quantity, the slope is always the same. This means that at any price level, we assume a 1\% change in price will yield the same percentage change in quantity. This is also known as fixed elasticities – a topic we will dive in on the next page.


\subsubsection{Revisiting Avocados}
\label{\detokenize{content/01-demand/03-log-log:revisiting-avocados}}
\sphinxAtStartPar
We will revisit the avocados dataset from the previous page, which features historical data on non\sphinxhyphen{}organic avocado prices and sales volumes in San Francisco from 2015 to 2018.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{avocados} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{avocados.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} is it avocados or avocadoes?}
\PYG{n}{avocados}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Date       | Average Price | Total Volume
2015\PYGZhy{}12\PYGZhy{}27 | 1.05          | 692206
2015\PYGZhy{}12\PYGZhy{}20 | 1.15          | 637091
2015\PYGZhy{}12\PYGZhy{}13 | 1.22          | 616016
2015\PYGZhy{}12\PYGZhy{}06 | 1.06          | 694982
2015\PYGZhy{}11\PYGZhy{}29 | 1.05          | 651639
2015\PYGZhy{}11\PYGZhy{}22 | 1.04          | 709444
2015\PYGZhy{}11\PYGZhy{}15 | 0.99          | 775849
2015\PYGZhy{}11\PYGZhy{}08 | 1.4           | 599884
2015\PYGZhy{}11\PYGZhy{}01 | 0.97          | 869927
2015\PYGZhy{}10\PYGZhy{}25 | 1.55          | 561342
... (159 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
Taking a look at the natural relationship between price and volume sold, we see a possible exponentially decaying relationship between volume and price. We will try using both semi\sphinxhyphen{}log and log\sphinxhyphen{}log transformations on the data.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{avocados}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Total Volume}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Average Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-log-log_25_0}.png}


\paragraph{Semi\sphinxhyphen{}log}
\label{\detokenize{content/01-demand/03-log-log:semi-log}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{log\PYGZus{}quantity} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{avocados}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Total Volume}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{slope}\PYG{p}{,} \PYG{n}{intercept} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{polyfit}\PYG{p}{(}\PYG{n}{avocados}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Average Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{log\PYGZus{}quantity}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The slope is: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{slope}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The intercept is: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{intercept}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
The slope is:  \PYGZhy{}0.5792670374517227
The intercept is:  14.352506861683818
\end{sphinxVerbatim}

\sphinxAtStartPar
Interpreting the slope, we get that for every one dollar change in price of avocados, we would expect the change in quantity demanded to decrease by 57\%. Take this result with a grain of salt – recall that our approximation typically is valid for small values of \(m\), and here our \(m=-0.57\).

\sphinxAtStartPar
Now, let’s plot our semi\sphinxhyphen{}log demand curve. First, we will plot it on an axes in which the quantity is log\sphinxhyphen{}transformed, exhibiting a linear demand curve:

\noindent\sphinxincludegraphics{{03-log-log_29_0}.png}

\sphinxAtStartPar
Next, let’s plot our semi\sphinxhyphen{}log demand curve in which neither axis is log\sphinxhyphen{}transformed:

\noindent\sphinxincludegraphics{{03-log-log_31_0}.png}


\paragraph{Log\sphinxhyphen{}log}
\label{\detokenize{content/01-demand/03-log-log:log-log}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{log\PYGZus{}quantity} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{avocados}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Total Volume}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{log\PYGZus{}price} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{avocados}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Average Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{slope}\PYG{p}{,} \PYG{n}{intercept} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{polyfit}\PYG{p}{(}\PYG{n}{log\PYGZus{}price}\PYG{p}{,} \PYG{n}{log\PYGZus{}quantity}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The slope is: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{slope}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The intercept is: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{intercept}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
The slope is:  \PYGZhy{}0.8157285894758461
The intercept is:  13.798460905495737
\end{sphinxVerbatim}

\sphinxAtStartPar
Interpreting the slope, we get that for every 1\% change in price of avocados, we would expect the change in quantity demanded to decrease by \(-0.816\%\). Once again, keep in mind that our approximation typically is valid for small values of \(m\), and here our \(m=-0.816\).

\sphinxAtStartPar
Plotting our log\sphinxhyphen{}log demand curve with both axes log\sphinxhyphen{}transformed, we observe a linear demand curve:

\noindent\sphinxincludegraphics{{03-log-log_35_0}.png}

\sphinxAtStartPar
Finally, let’s plot our log\sphinxhyphen{}log demand curve in which neither axis is log\sphinxhyphen{}transformed:

\noindent\sphinxincludegraphics{{03-log-log_37_0}.png}

\sphinxAtStartPar
Which model is better: semi\sphinxhyphen{}log or log\sphinxhyphen{}log? There is no correct answer here, in fact justifying one approach over another is surprisingly profound. One way to approach this is to look at the graphs produced above and which red line goes through our data points “best” (but what does “best” mean? We’ll save this for another day…). Another approach is to utilize our real\sphinxhyphen{}world knowledge to conclude which relationship is more accurate: do consumers react similarly to price changes that are in a proportion manner or in a absolute manner? This may also depend on the price, the promotion around it, the product itself, and many other factors.

\sphinxAtStartPar
This example highlights how ambiguity is a big part of doing data science. We can approach ambiguity with statistical methods and with domain knowledge. Either way, as long as you can ultimately justify your approach, that is what is key in conducting robust data science.


\subsection{Elasticity}
\label{\detokenize{content/01-demand/04-elasticity:elasticity}}\label{\detokenize{content/01-demand/04-elasticity::doc}}
\sphinxAtStartPar
Suppose you own a business but you find yourself struggling to make a profit lately. How would you resolve this? You might consider raising your prices. But surely if you were to raise your prices too much you might lose some of your customers. To relate to our discussions above regarding surplus, maybe some of your customers are already at their highest willingness to pay, and raising prices would push them away from your business. Depending on the situation, you might lose so many customers that the increased revenue from raising your prices are completely offset by a decline in customers. This is a problem. To answer the question of how much to raise prices without losing too many customers and therefore losing revenue, we would like a way to measure this concept of customers’ responsiveness to prices. We call this concept \sphinxstyleemphasis{elasticity}.

\sphinxAtStartPar
How would we measure elasticity? In the above context, we want to see how much quantity demanded of your business’s goods or services changes in response to a change in price. It seems like a good place to start would be to define elasticity as the percent change in quantity over percent change in price. Let’s use the demand curve, assuming linear non\sphinxhyphen{}log demand curves, depicted below as an example.

\noindent\sphinxincludegraphics{{04-elasticity_4_0}.png}

\sphinxAtStartPar
Now let’s say our current price is 5, and we would like to increase the price to 6. We can see from the curve that this causes demand to drop from 5 to 4.

\noindent\sphinxincludegraphics{{04-elasticity_6_0}.png}

\sphinxAtStartPar
Using our definition from above, we can calculate the elasticity.
\begin{equation*}
\begin{split}
\begin{align}
\frac{\%\Delta Q}{\%\Delta P} &= \frac{\frac{4-5}{5}\times100\%}{\frac{6-5}{5}\times100\%} \\
&= \frac{-20\%}{20\%} \\
&= 1
\end{align}
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstyleemphasis{Note that we take the absolute value for elasticity.}

\sphinxAtStartPar
This tells us that in this specific example, the percent change in price is met with an equal percent change in quantity. But what happens if we start at a price of 6 and go down to a price of 5? This movement is just the opposite of what we did above, so is the elasticity also 1? Let’s see.

\noindent\sphinxincludegraphics{{04-elasticity_8_0}.png}
\begin{equation*}
\begin{split}
\begin{align}
\frac{\%\Delta Q}{\%\Delta P} &= \frac{\frac{5-4}{4}\times100\%}{\frac{5-6}{6}\times100\%} \\
&= \frac{25\%}{-16.67\%} \\
&\approx 1.5
\end{align}
\end{split}
\end{equation*}
\sphinxAtStartPar
We get a different number! This is of course a property of percentages. In both scenarios we moved price by 1, but we started at different prices, and increasing price by 1 starting from 5 is different percentage\sphinxhyphen{}wise from starting at 6 and decreasing by 1.

\sphinxAtStartPar
If we want to find a unique value for elasticity between the price points of 5 and 6, independent of price movement, we can use something called the \sphinxstylestrong{mid\sphinxhyphen{}point method}. It looks like this:
\begin{equation*}
\begin{split}\frac{\frac{Q_2 - Q_1}{(Q_2 + Q_1)\times0.5}\times100\%}{\frac{P_2 - P_1}{(P_2 + P_1)\times0.5}\times100\%}\end{split}
\end{equation*}
\sphinxAtStartPar
What this does is it essentially finds the elasticity of the point between the two given points.

\sphinxAtStartPar
It is also useful, however, to think of elasticity as a property of a single point. For example, we might want the price point of 5 in the example above to have a set elasticity of 1 irrespective of what other point we are going to or coming from. For this, we can use the \sphinxstylestrong{point\sphinxhyphen{}slope formula}.
\begin{equation*}
\begin{split}\frac{\Delta Q}{\Delta P}\frac{P}{Q}\end{split}
\end{equation*}
\sphinxAtStartPar
or
\begin{equation*}
\begin{split}\frac{dQ}{dP}\Bigr|_{P,Q}\times\frac{P}{Q}\end{split}
\end{equation*}
\sphinxAtStartPar
where the left fraction is the inverse slope at that particular point.

\sphinxAtStartPar
It turns out that in our example above, we can think of the very first formula for elasticity (percent change in quantity over percent change in price) as the point\sphinxhyphen{}slope elasticity of the starting point. To verify this, find the elasticity from a price of 5 to 6, from a price of 5 to 4, and at the price of 5 using the point\sphinxhyphen{}slope formula. You should get the same answer all three times. This does not hold in general for all curves, but using the base formula that was first introduced should be fine for our examples and other situations.


\subsubsection{Other Elasticities}
\label{\detokenize{content/01-demand/04-elasticity:other-elasticities}}
\sphinxAtStartPar
We can measure elasticity in different contexts as well. Naturally, if we have an elasticity of demand, it follows that we should have an elasticity of supply. Just like consumers make adjustments to their quantity demanded based on changes in the market price, producers respond to market prices as well. Elasticity of supply can be calculated similarly to elasticity of demand.

\sphinxAtStartPar
Imagine that there are two fast food locations next to each other on campus competing for students’ business. Let’s call them Railway and Bear Express. Initially, their food is priced such that they get equal amounts of business from the students, and students on average don’t prefer one over the other; they just want a good and affordable place to eat. Now, imagine that Bear Express raises the prices of their food, while Railway holds their prices steady. In this scenario, one can imagine that students would begin eating more frequently at Railway as opposed to Bear Express due to it being relatively cheaper out of the two options. Now, if Railway in turn increases their prices, the flow of students would shift back to Bear Express by a certain amount. These two restaurants are said to offer goods that are \sphinxstyleemphasis{substitutes} to each other. That is, a consumer will want one or the other, but usually not both. Furthermore, it would seem that just like the price of a good affects its quantity demanded, for substitutes the price of one good can affect the quantity demanded of the other. This is called \sphinxstyleemphasis{cross\sphinxhyphen{}price elasticity of demand} (as opposed to \sphinxstyleemphasis{own\sphinxhyphen{}price elasticity} that we just learned earlier). It can be defined as follows:
\begin{equation*}
\begin{split}\frac{\%\Delta Q_{Good A}}{\%\Delta P_{Good B}}\end{split}
\end{equation*}
\sphinxAtStartPar
Notice that here there is a notion of positive and negative elasticity. Substitutes will have positive cross\sphinxhyphen{}price elasticity, because we expect that an increase in the price of one good will lead to an increase in the quantity demanded of its substitute. But what about when cross\sphinxhyphen{}price elasticity is negative? In other words, are there goods where an increase in the price of one leads to a decrease in the quantity demanded of the other? Of course; these are called \sphinxstyleemphasis{complements}. Examples of complementary goods could be cars and gasoline, hot dogs and hot dog buns, or peanut butter and jelly.

\sphinxAtStartPar
There is one more type of elasticity that we will briefly discuss, and that is \sphinxstyleemphasis{income elasticity of demand}. For most goods, the more disposable income consumers have the more they will demand these goods. Almost all goods follow this pattern, and thus there are countless examples. These goods are called \sphinxstyleemphasis{normal goods}. More interestingly, there are some goods, called \sphinxstyleemphasis{inferior goods}, for which we see quantity demanded decrease as income increases. An example of this might be frozen, microwaveable food. As consumers grow wealthier and their palates grow more discerning, their consumption of frozen food might decrease in place of more cooked meals. To calculate this elasticity we would use the following:
\begin{equation*}
\begin{split}\frac{\%\Delta Q}{\%\Delta Income}\end{split}
\end{equation*}

\subsubsection{Elasticity and Revenue}
\label{\detokenize{content/01-demand/04-elasticity:elasticity-and-revenue}}
\sphinxAtStartPar
Let’s take a closer look at own\sphinxhyphen{}price elasticity of demand. Below we’ve defined a function using our first definition. Let’s see what happens as we increase price. Note that is this percent change in quantity over \% change in price. While this is negative quantity usually, we still denote it as a positive number.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{elasticity}\PYG{p}{(}\PYG{n}{P1}\PYG{p}{,}\PYG{n}{P2}\PYG{p}{,}\PYG{n}{Q1}\PYG{p}{,}\PYG{n}{Q2}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{p}{(}\PYG{p}{(}\PYG{n}{Q2}\PYG{o}{\PYGZhy{}}\PYG{n}{Q1}\PYG{p}{)}\PYG{o}{/}\PYG{n}{Q1}\PYG{p}{)}\PYG{o}{/}\PYG{p}{(}\PYG{p}{(}\PYG{n}{P2}\PYG{o}{\PYGZhy{}}\PYG{n}{P1}\PYG{p}{)}\PYG{o}{/}\PYG{n}{P1}\PYG{p}{)}

\PYG{n}{p} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{p}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{demand\PYGZus{}equation} \PYG{o}{=} \PYG{l+m+mi}{10}\PYG{o}{\PYGZhy{}}\PYG{n}{p}
\PYG{n}{prices} \PYG{o}{=} \PYG{p}{[}\PYG{n}{i} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{]}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Price: Elasticity}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{p}{)}

\PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{prices}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{o}{+}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{abs}\PYG{p}{(}\PYG{n}{elasticity}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{x}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{n}{demand\PYGZus{}equation}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{p}\PYG{p}{,}\PYG{n}{x}\PYG{p}{)}\PYG{p}{,}\PYG{n}{demand\PYGZus{}equation}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{p}\PYG{p}{,}\PYG{n}{x}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Price: Elasticity

1: 0.111111111111111
2: 0.250000000000000
3: 0.428571428571429
4: 0.666666666666667
5: 1.00000000000000
6: 1.50000000000000
7: 2.33333333333333
8: 4.00000000000000
9: 9.00000000000000
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice how a price increase will increase revenue until a certain point, at which point revenue decreases again. Intuitively this makes sense. A firm can only increase its prices so much until it starts losing too many of its customers for the increase to be worthwhile. Let’s try and find when this happens in general. First let’s plot revenue as a function of price.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{elast} \PYG{o}{=} \PYG{p}{[}\PYG{n+nb}{abs}\PYG{p}{(}\PYG{n}{elasticity}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{x}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{n}{demand\PYGZus{}equation}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{p}\PYG{p}{,}\PYG{n}{x}\PYG{p}{)}\PYG{p}{,}\PYG{n}{demand\PYGZus{}equation}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{p}\PYG{p}{,}\PYG{n}{x}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{]}
\PYG{n}{revenue} \PYG{o}{=} \PYG{p}{[}\PYG{n}{demand\PYGZus{}equation}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{p}\PYG{p}{,}\PYG{n}{x}\PYG{p}{)}\PYG{o}{*}\PYG{n}{x} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{]}
\PYG{n}{prices} \PYG{o}{=} \PYG{p}{[}\PYG{n}{x} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{]}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{9}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{prices}\PYG{p}{,}\PYG{n}{revenue}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Revenue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Revenue vs Price for Given Demand Curve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-elasticity_18_0}.png}

\sphinxAtStartPar
We notice that revenue reaches a maximun at a price of 5. What elasticity does this price point have?

\noindent\sphinxincludegraphics{{04-elasticity_20_0}.png}

\sphinxAtStartPar
Revenue is maximized when elasticity is 1! To further reinforce this, let’s plot revenue vs elasticity.

\noindent\sphinxincludegraphics{{04-elasticity_23_0}.png}

\sphinxAtStartPar
Before we continue to the final section let’s make sure we have a solid intuitive grasp of the significance of our findings. Near low price points, a firm deciding how to raise prices will tend to face inelastic demand. You can imagine that if there were some market where let’s say laptops cost only a few dollars, doubling the price of laptops would proabalby not decrease demand for laptops at all, since the price of laptops is still very low. Here, demand is inelastic, or in other words, it is less than 1, because a unit change in price is not met by the same change in quantity. Alternatively, if laptops were to cost as much as a house, and then the price for laptops doubled, the few people who were still in the market for laptops would probably be very discouraged from continuing to buy laptops. It wouldn’t be unreasonable to assume that nearly all of the demand would be lost. Here, demand is elastic, or greater than 1, because a unit change in price is met by an even greater change in quantity. The point of the above exercise is to illustrate that there is some middle ground between these two extremes, where a firm with a good pulse on market demand should be pricing its products.

\sphinxAtStartPar
It’s important to remember that while we have so far been discussing elasticity from a demand perspective, supply also has the property of elasticity.


\subsubsection{Relative Elasticity}
\label{\detokenize{content/01-demand/04-elasticity:relative-elasticity}}
\sphinxAtStartPar
Suppose that you are hiking in the mountains when a venomous snake bites you. Fortunately there is a hospital nearby. Unfortunately, it seems that their antivenom is very expensive. If the antivenom costs \textbackslash{}\(1000, would you pay? What if the price doubled to \\\)2000? What is your max willingness to pay for this antivenom? In the moment, you would likely be willing to pay anything and everything for the antivenom, as any money you refuse to pay won’t be of much use to you if you’re dead.

\sphinxAtStartPar
Contrast this with your demand for pizza. Imagine a pizza chain close to where you live doubles their prices from \textbackslash{}\(3 a slice to \\\)6 a slice. Most people would be disuaded from buying pizza by this price increase, assuming that there are many alternatives to pizza close to where you live. Since pizza is not a very essential good, and there are plenty of other places to eat close to where you live, most wouldn’t see the point in getting pizza anymore.

\sphinxAtStartPar
We can easily see that any change in price is unlikely to change the demand for antivenom in our example, and thus we say the demand for antivenom is inelastic. But this is a different kind of elasticity. We are not measuring the marginal change in quantity demanded at a given price point or interval, we are saying that in general, on the demand curve for antivenom the elasticity at any price is more inelastic than some other typical demand curve. Similarly, in our example we can say that the demand for pizza is relatively elastic, as the pizza chain cannot change their prices too much without significantly altering the quantity demanded for their pizza. The keyword in this concept is \sphinxstyleemphasis{relative}. It doesn’t really make much sense to say that the demand for antivenom is inelastic without there being at least one other kind of demand that is comparatively elastic.

\sphinxAtStartPar
More specifically, our example of antivenom likely exhibits \sphinxstyleemphasis{perfect inelasticity}, meaning that demand for antivenom is the same at absolutely any price; the hospital can charge any price it wants for antivenom. Contrast this with our nearby pizza chain. If we make some further assumptions and say that the market for food around your house or apartment is perfectly competitive, such that any marginal increase in price of one food chain will cause them to lose all of their customers to other food chains, then the demand for the specific food of that chain is \sphinxstyleemphasis{perfectly elastic}. The chain cannot increase its prices or else it will lose all demand. These two extreme scenarios are depicted below.

\noindent\sphinxincludegraphics{{04-elasticity_28_0}.png}

\noindent\sphinxincludegraphics{{04-elasticity_29_0}.png}


\section{Supply and Market Equilibrium}
\label{\detokenize{content/02-supply/index:supply-and-market-equilibrium}}\label{\detokenize{content/02-supply/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{Student Learning Outcomes:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Know how a supply curve is formed

\item {} 
\sphinxAtStartPar
Understand when and how much a firm decided to produce

\item {} 
\sphinxAtStartPar
Understand demand and price elasticities of goods

\item {} 
\sphinxAtStartPar
Use SymPy to solve systems of supply and demand equations

\item {} 
\sphinxAtStartPar
Calculate the price equilibrium

\end{itemize}


\subsection{The Supply Curve}
\label{\detokenize{content/02-supply/01-supply:the-supply-curve}}\label{\detokenize{content/02-supply/01-supply::doc}}
\sphinxAtStartPar
The supply of a commodity refers to the quantity for which producers or sellers are willing to produce and offer for sale, at a particular price in some given period of time. To answer questions like \sphinxstyleemphasis{“at a given price, what will be the supply of a good in the market?”}, we need to know the market supply curve. A supply curve is simply a curve (or graph) which shows the quantites of a good that can be produced and the prices they will be sold at.

\sphinxAtStartPar
It is good to discern between individual and market supply. \sphinxstylestrong{Individual supply} refers to the supply offered by a single firm or producer, while \sphinxstylestrong{market supply} refers to the supply offered by all the firms or producers in a market. It is the horizontal summation of the individual supply curves in the market.

\sphinxAtStartPar
The following table and graph will give an example of a market with two firms: A and B.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{market\PYGZus{}supply} \PYG{o}{=} \PYG{n}{Table}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}columns}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Quantity supplied by A}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{l+m+mi}{30}\PYG{p}{,} \PYG{l+m+mi}{40}\PYG{p}{)}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Quantity supplied by B}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+m+mi}{30}\PYG{p}{,} \PYG{l+m+mi}{40}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{)}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Market Supply}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+m+mi}{50}\PYG{p}{,} \PYG{l+m+mi}{70}\PYG{p}{,} \PYG{l+m+mi}{90}\PYG{p}{)}
\PYG{p}{)}
\PYG{n}{market\PYGZus{}supply}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Price | Quantity supplied by A | Quantity supplied by B | Market Supply
2     | 20                     | 30                     | 50
3     | 30                     | 40                     | 70
4     | 40                     | 50                     | 90
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{01-supply_3_0}.png}

\sphinxAtStartPar
Market behavior relating to supply is based on the behavior of the individual firms that comprise it. Now, how does an individual firm make its decision about production? It does so based on the costs associated with production. If the price of a good is enough to recover the costs, the firm produces. Generally, costs increase with the quantity of production. So, to induce producers to increase the quantity supplied, the market prices need to be high enough to compensate for the increased costs.


\subsubsection{Costs}
\label{\detokenize{content/02-supply/01-supply:costs}}
\sphinxAtStartPar
We will split costs into two categories: fixed costs and variable costs.

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\sphinxstylestrong{Fixed costs} are costs associated with fixed factors (or inputs) of production. For example, land for a factory, capital equipment like machinery, etc. The quantity of these inputs cannot be changed quickly in the short term. A factory owner cannot purchase land quickly enough to ramp up production in a week. A key point to note is that fixed costs are irrespective of the quantity, i.e., they do not change with the quantity produced.

\sphinxAtStartPar
\sphinxstylestrong{Variable costs} are costs associated with variable factors (or inputs) of production. For example, labor, raw materials, etc. The quantity of these inputs can be changed quickly in the short term to adjust supply. A factory owner can hire more laborers or purchase more raw material to increase output. Variable costs change as the supply changes.
\end{sphinxadmonition}

\sphinxAtStartPar
Another important cost calculation to consider is the marginal cost.

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstylestrong{marginal cost} is the additional cost to produce one more unit of output. It can be calculated as the difference between the total cost and the current level of output and the total cost at the previous level of output.
\end{sphinxadmonition}

\sphinxAtStartPar
Below is a table with the following costs incurred by the firm:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Output:} Units produced and supplied

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Total Fixed Cost (TFC):} Cost incurred by firm on usage of all fixed factors.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Total Variable Cost (TVC):} Cost incurred by firm on usage of all variable factors.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Total Cost (TC):} Sum of the total fixed and variable costs.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Marginal Cost (MC)}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Average Fixed Cost (AFC):} Cost per unit of fixed factors. It can be calculated as the Total Fixed Cost divided by the corresponding output level.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Average Variable Cost (AVC):} Cost per unit of variable factors. It can be calculated as the Total Variable Cost divided by the corresponding output level.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Average Total Cost (ATC):} Total cost per unit. This is the sum of the Average Fixed Cost and the Average Variable Cost.

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{individual\PYGZus{}firm\PYGZus{}costs} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{supply\PYGZus{}textbook.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{individual\PYGZus{}firm\PYGZus{}costs}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Let’s create some visualizations to understand the relationships of the different cost curves.

\noindent\sphinxincludegraphics{{01-supply_12_0}.png}

\sphinxAtStartPar
There are two important things to notice about the graph above. First, the total fixed cost is flat. This is because the fixed cost does not change regardless of quantity produced. Second, the vertical difference between the total variable cost and total cost is the TFC. This is because \(\text{TC} = \text{TVC} + \text{TFC}\).

\noindent\sphinxincludegraphics{{01-supply_14_0}.png}

\sphinxAtStartPar
From the graph above, note that:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The average fixed cost is decreasing throughout. This is because at higher levels of production, the fixed cost is divided across more units. This implies that the difference between the ATC and AVC decreases as we increase production, since \(\text{ATC} = \text{AVC} + \text{AFC}\).

\item {} 
\sphinxAtStartPar
The AVC and ATC slope down initially and then slope up. This represents decreasing and then increasing marginal cost. Marginal cost initially decreases due to efficiencies in producing at scale, but then increases due to the law of variable proportions.

\end{itemize}

\sphinxAtStartPar
Now let’s introduce the marginal cost curve:

\noindent\sphinxincludegraphics{{01-supply_16_0}.png}

\sphinxAtStartPar
Notice that the MC curve intersects the ATC and AVC curves at their minima. This is because when MC is below the AVC and ATC, it brings down the average since it costs less to produce an additional unit. But as MC begins to increase and surpasses the ATC and AVC cost curves, it will surpass the intersection, and pulls up the AVC and ATC curves. Therefore, it intersects at the minima.


\subsubsection{Production and Firm Behavior}
\label{\detokenize{content/02-supply/01-supply:production-and-firm-behavior}}
\sphinxAtStartPar
A company decides to produce if the price is greater than or equal to its average variable cost. There are 3 different scenarios:
\begin{itemize}
\item {} 
\sphinxAtStartPar
A firm does not produce at all

\item {} 
\sphinxAtStartPar
It produces at a loss\sphinxhyphen{}minimizing quantity

\item {} 
\sphinxAtStartPar
It produces at a profit

\end{itemize}

\sphinxAtStartPar
Profits are calculated as total revenue minus total costs, where total revenue is price times quantity. For any price that is less than AVC, the firm will not produce at all. This is because for any amount of production, they will lose money. In this case, they shut down and the loss is limited to its fixed costs. In this example, we can see this for prices 24 and below.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{firm\PYGZus{}behaviour}\PYG{p}{(}\PYG{l+m+mi}{24}\PYG{p}{,} \PYG{n}{individual\PYGZus{}firm\PYGZus{}costs}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
No production
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{01-supply_19_1}.png}

\sphinxAtStartPar
For any price that lies above the AVC curve but below the ATC curve, the firm will produce at a loss\sphinxhyphen{}minimising quantity. This is because for some levels of production, they will make revenue that is more than the total variable cost of production but is still less than the total cost, which includes the fixed cost. While they still lose money, they have offset some of the losses they would have incurred from the fixed cost. In our example, we see this for prices between 25 and 31. The red patch in the plot shows the loss.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{firm\PYGZus{}behaviour}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,} \PYG{n}{individual\PYGZus{}firm\PYGZus{}costs}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Production at loss minimising quantity
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{01-supply_21_1}.png}

\sphinxAtStartPar
If the price is above the ATC curve, the firm produces at a profit. In this example, it is at prices 32 and above. The green patch shows the profit.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{firm\PYGZus{}behaviour}\PYG{p}{(}\PYG{l+m+mi}{36}\PYG{p}{,} \PYG{n}{individual\PYGZus{}firm\PYGZus{}costs}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Production at a profit
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{01-supply_23_1}.png}

\sphinxAtStartPar
So, we have seen that a firm produces if the price is above the AVC. The question now is: what is the level of production?

\sphinxAtStartPar
A profit\sphinxhyphen{}maximising firm will produce until price is less than or equal to marginal cost. In the above example, the firm produces 8 units. At the 8th unit, the marginal cost to produce that unit is 28, which is less than the price of 36. Thus the firm gets more revenue for the 8th unit than the cost to produce that unit. But the 9th unit costs an additional 38 to produce. The price of 36 is not enough to cover it. Thus it does not produce the 9th unit.

\sphinxAtStartPar
Therefore, based on the price, each firm looks at its costs and makes a decision to produce. At low prices, only the firms with the lowest production costs produce. As the price increases, firms with higher production costs find it feasible to produce and begin to supply. Thus, the market supply rises with higher prices. Firms with lower costs make extra profits.


\subsection{An Empirical Example from EEP 147}
\label{\detokenize{content/02-supply/02-eep147-example:an-empirical-example-from-eep-147}}\label{\detokenize{content/02-supply/02-eep147-example::doc}}
\sphinxAtStartPar
Let’s take a look at an empirical example of production. The dataset for this section comes from EEP 147: Regulation of Energy and the Environment.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ESG\PYGZus{}table} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ESGPorfolios\PYGZus{}forcsv.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Group}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Group\PYGZus{}num}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{UNIT NAME}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Capacity\PYGZus{}MW}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Total\PYGZus{}Var\PYGZus{}Cost\PYGZus{}USDperMWH}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}\PYG{o}{.}\PYG{n}{sort}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Total\PYGZus{}Var\PYGZus{}Cost\PYGZus{}USDperMWH}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{descending} \PYG{o}{=} \PYG{k+kc}{False}\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabel}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Average Variable Cost}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{ESG\PYGZus{}table}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Group        | Group\PYGZus{}num | UNIT NAME       | Capacity\PYGZus{}MW | Average Variable Cost
Old Timers   | 7         | BIG CREEK       | 1000        | 0
Fossil Light | 8         | HELMS           | 800         | 0.5
Fossil Light | 8         | DIABLO CANYON 1 | 1000        | 11.5
Bay Views    | 4         | MOSS LANDING 6  | 750         | 32.56
Bay Views    | 4         | MOSS LANDING 7  | 750         | 32.56
Old Timers   | 7         | MOHAVE 1        | 750         | 34.5
Old Timers   | 7         | MOHAVE 2        | 750         | 34.5
Big Coal     | 1         | FOUR CORNERS    | 1900        | 36.5
Bay Views    | 4         | MORRO BAY 3\PYGZam{}4   | 665         | 36.61
East Bay     | 6         | PITTSBURGH 5\PYGZam{}6  | 650         | 36.61
... (32 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
This table shows some electricity generation plants in California and their costs. The \sphinxcode{\sphinxupquote{Capacity}} is the output the firm is capable of producing. The \sphinxcode{\sphinxupquote{Average Variable Cost}} shows the minimum variable cost per megawatt (MW) produced. At a price below AVC, the firm supplies nothing. At a price above the AVC, the firm can supply up to its capacity. Being a profit\sphinxhyphen{}maximising firm, it will try to supply its full capacity.

\sphinxAtStartPar
First, lets look at just the Big Coal producers and understand this firm’s particular behavior.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{selection} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Big Coal}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{Group} \PYG{o}{=} \PYG{n}{ESG\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Group}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{equal\PYGZus{}to}\PYG{p}{(}\PYG{n}{selection}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{Group}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Group    | Group\PYGZus{}num | UNIT NAME            | Capacity\PYGZus{}MW | Average Variable Cost
Big Coal | 1         | FOUR CORNERS         | 1900        | 36.5
Big Coal | 1         | HUNTINGTON BEACH 1\PYGZam{}2 | 300         | 40.5
Big Coal | 1         | REDONDO 5\PYGZam{}6          | 350         | 41.94
Big Coal | 1         | REDONDO 7\PYGZam{}8          | 950         | 41.94
Big Coal | 1         | HUNTINGTON BEACH 5   | 150         | 66.5
Big Coal | 1         | ALAMITOS 7           | 250         | 73.72
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{02-eep147-example_5_0}.png}

\sphinxAtStartPar
We have created the Big Coal supply curve. It shows the price of electricity, and the quantity supplied at those prices, which depends on variable cost. For example, at any variable cost equal to or above 36.5, the producer \sphinxcode{\sphinxupquote{FOUR CORNERS}} (the one with the lowest production costs) will supply, and so on. Notably, we observe that the supply curve is also upward sloping since we need higher prices to entice producers with higher variasble costs to produce.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Price: \PYGZdl{}30
No production
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{02-eep147-example_7_1}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Price: \PYGZdl{}37
Total Production/Market Supply:  1900

Suppliers:  [\PYGZsq{}FOUR CORNERS\PYGZsq{}]
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{02-eep147-example_8_1}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Price: \PYGZdl{}50
Total Production/Market Supply:  3500

Suppliers:  [\PYGZsq{}FOUR CORNERS\PYGZsq{} \PYGZsq{}HUNTINGTON BEACH 1\PYGZam{}2\PYGZsq{} \PYGZsq{}REDONDO 5\PYGZam{}6\PYGZsq{} \PYGZsq{}REDONDO 7\PYGZam{}8\PYGZsq{}]
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{02-eep147-example_9_1}.png}

\sphinxAtStartPar
Now we will look at all the energy sources. They have been colored according to source for reference.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Price: \PYGZdl{}30
Total Production/Market Supply:  2800

Suppliers:  [\PYGZsq{}BIG CREEK\PYGZsq{} \PYGZsq{}HELMS\PYGZsq{} \PYGZsq{}DIABLO CANYON 1\PYGZsq{}]
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{02-eep147-example_11_1}.png}

\noindent\sphinxincludegraphics{{02-eep147-example_11_2}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Price: \PYGZdl{}50
Total Production/Market Supply:  18650

Suppliers:  [\PYGZsq{}BIG CREEK\PYGZsq{} \PYGZsq{}HELMS\PYGZsq{} \PYGZsq{}DIABLO CANYON 1\PYGZsq{} \PYGZsq{}MOSS LANDING 6\PYGZsq{} \PYGZsq{}MOSS LANDING 7\PYGZsq{}
 \PYGZsq{}MOHAVE 1\PYGZsq{} \PYGZsq{}MOHAVE 2\PYGZsq{} \PYGZsq{}FOUR CORNERS\PYGZsq{} \PYGZsq{}MORRO BAY 3\PYGZam{}4\PYGZsq{} \PYGZsq{}PITTSBURGH 5\PYGZam{}6\PYGZsq{}
 \PYGZsq{}ORMOND BEACH 1\PYGZsq{} \PYGZsq{}ORMOND BEACH 2\PYGZsq{} \PYGZsq{}MORRO BAY 1\PYGZam{}2\PYGZsq{} \PYGZsq{}MANDALAY 1\PYGZam{}2\PYGZsq{}
 \PYGZsq{}CONTRA COSTA 6\PYGZam{}7\PYGZsq{} \PYGZsq{}HUNTINGTON BEACH 1\PYGZam{}2\PYGZsq{} \PYGZsq{}PITTSBURGH 1\PYGZhy{}4\PYGZsq{}
 \PYGZsq{}EL SEGUNDO 3\PYGZam{}4\PYGZsq{} \PYGZsq{}ENCINA\PYGZsq{} \PYGZsq{}REDONDO 5\PYGZam{}6\PYGZsq{} \PYGZsq{}REDONDO 7\PYGZam{}8\PYGZsq{} \PYGZsq{}COOLWATER\PYGZsq{}
 \PYGZsq{}ETIWANDA 1\PYGZhy{}4\PYGZsq{} \PYGZsq{}SOUTH BAY\PYGZsq{} \PYGZsq{}EL SEGUNDO 1\PYGZam{}2\PYGZsq{} \PYGZsq{}HUMBOLDT\PYGZsq{}
 \PYGZsq{}HUNTERS POINT 1\PYGZam{}2\PYGZsq{} \PYGZsq{}HIGHGROVE\PYGZsq{}]
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{02-eep147-example_12_1}.png}

\noindent\sphinxincludegraphics{{02-eep147-example_12_2}.png}

\sphinxAtStartPar
Look at the thin bars concentrated on the right end of the plot. These are plants with small capacities and high variable costs. Conversely, plants with larger capacities tend to have lower variable costs. Why might this be the case? Electricity production typically benefits from economies of scale: it is cheaper per unit when producing more units. Perhaps the high fixed cost required for electricity production, such as for equipment and land, is the reason behind this phenomenon.


\subsection{Market Equilibria}
\label{\detokenize{content/02-supply/03-market-equilibria:market-equilibria}}\label{\detokenize{content/02-supply/03-market-equilibria::doc}}
\sphinxAtStartPar
We will now explore the relationship between price and quantity of oranges produced between 1924 and 1938. Since the data {[}\hyperlink{cite.content/references:id3}{Hoo41}{]} is from the 1920s and 1930s, it is important to remember that the prices are much lower than what they would be today because of inflation, competition, innovations, and other factors. For example, in 1924, a ton of oranges would have costed \$6.63; that same amount in 2019 is \$100.78.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fruitprice} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fruitprice.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{fruitprice}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Year | Pear Price | Pear Unloads (Tons) | Plum Price | Plum Unloads | Peach Price | Peach Unloads | Orange Price | Orange Unloads | NY Factory Wages
1924 | 8.04       | 18489               | 8.86       | 6582         | 4.96        | 41880         | 6.63         | 21258          | 27.22
1925 | 5.67       | 21919               | 7.27       | 5526         | 4.87        | 38772         | 9.19         | 15426          | 28.03
1926 | 5.44       | 29328               | 6.68       | 5742         | 3.35        | 46516         | 7.2          | 24762          | 28.89
1927 | 7.15       | 17082               | 8.09       | 5758         | 5.7         | 32500         | 8.63         | 22766          | 29.14
1928 | 5.81       | 20708               | 7.41       | 6000         | 4.13        | 46820         | 10.71        | 18766          | 29.34
1929 | 7.6        | 13071               | 10.86      | 3504         | 6.7         | 36990         | 6.36         | 35702          | 29.97
1930 | 5.06       | 22068               | 6.23       | 7998         | 6.35        | 29680         | 10.5         | 23718          | 28.68
1931 | 5.4        | 19255               | 6.86       | 5638         | 3.91        | 50940         | 5.81         | 39263          | 26.35
1932 | 4.06       | 17293               | 6.09       | 7364         | 4.57        | 27642         | 4.71         | 38553          | 21.98
1933 | 4.78       | 11063               | 5.86       | 8136         | 3.57        | 35560         | 4.6          | 36540          | 22.26
... (5 rows omitted)
\end{sphinxVerbatim}


\subsubsection{Finding the Equilibrium}
\label{\detokenize{content/02-supply/03-market-equilibria:finding-the-equilibrium}}
\sphinxAtStartPar
An important concept in econmics is the market equilibrium. This is the point at which the demand and supply curves meet and represents the “optimal” level of production and price in that market.

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstylestrong{market equilibrium} is the price and quantity at which the demand and supply curves intersect. The price and resulting transaction quantity at the equilibrium is what we would predict to observe in the market.
\end{sphinxadmonition}

\sphinxAtStartPar
Let’s walk through how to the market equilibrium using the market for oranges as an example.


\paragraph{Data Preprocessing}
\label{\detokenize{content/02-supply/03-market-equilibria:data-preprocessing}}
\sphinxAtStartPar
Because we are only examining the relationship between prices and quantity for oranges, we can create a new table with the relevant columns: \sphinxcode{\sphinxupquote{Year}}, \sphinxcode{\sphinxupquote{Orange Price}}, and \sphinxcode{\sphinxupquote{Orange Unloads}}. Here, \sphinxcode{\sphinxupquote{Orange Price}} is measured in dollars, while \sphinxcode{\sphinxupquote{Orange Unloads}} is measured in tons.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{oranges\PYGZus{}raw} \PYG{o}{=} \PYG{n}{fruitprice}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Year}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Orange Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Orange Unloads}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{oranges\PYGZus{}raw}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Year | Orange Price | Orange Unloads
1924 | 6.63         | 21258
1925 | 9.19         | 15426
1926 | 7.2          | 24762
1927 | 8.63         | 22766
1928 | 10.71        | 18766
1929 | 6.36         | 35702
1930 | 10.5         | 23718
1931 | 5.81         | 39263
1932 | 4.71         | 38553
1933 | 4.6          | 36540
... (5 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
Next, we will rename our columns. In this case, let’s rename \sphinxcode{\sphinxupquote{Orange Unloads}} to \sphinxcode{\sphinxupquote{Quantity}} and \sphinxcode{\sphinxupquote{Orange Price}} to \sphinxcode{\sphinxupquote{Price}} for brevity and understandability.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{oranges} \PYG{o}{=} \PYG{n}{oranges\PYGZus{}raw}\PYG{o}{.}\PYG{n}{relabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Orange Unloads}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Quantity}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Orange Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{oranges}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Year | Price | Quantity
1924 | 6.63  | 21258
1925 | 9.19  | 15426
1926 | 7.2   | 24762
1927 | 8.63  | 22766
1928 | 10.71 | 18766
1929 | 6.36  | 35702
1930 | 10.5  | 23718
1931 | 5.81  | 39263
1932 | 4.71  | 38553
1933 | 4.6   | 36540
... (5 rows omitted)
\end{sphinxVerbatim}


\paragraph{Visualize the  Relationship}
\label{\detokenize{content/02-supply/03-market-equilibria:visualize-the-relationship}}
\sphinxAtStartPar
Let’s first take a look to see what the relationship between price and quantity is. We would expect to see a downward\sphinxhyphen{}sloping relationship between price and quantity; if a product’s price increases, consumers will purchase less, and if a product’s price decreases, then consumers will purchase more.

\sphinxAtStartPar
We will create a scatterplot between the points.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{oranges}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Quantity}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{width}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{height}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Demand Curve for Oranges}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{fontsize} \PYG{o}{=} \PYG{l+m+mi}{16}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-market-equilibria_11_0}.png}

\sphinxAtStartPar
The visualization shows a negative relationship between quantity and price, which is in line with our expectations: as the price increases, fewer consumers will purchase oranges, so the quantity demanded will decrease. This corresponds to a leftward movement along the demand curve. Alternatively, as the price decreases, the quantity sold will increase because consumers want to maximize their purchasing power and buy more oranges; this is shown by a rightward movement along the curve.


\paragraph{Fit a Polynomial}
\label{\detokenize{content/02-supply/03-market-equilibria:fit-a-polynomial}}
\sphinxAtStartPar
We will now quantify our demand curve using NumPy’s \sphinxhref{https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html}{\sphinxcode{\sphinxupquote{np.polyfit}} function}. Recall that \sphinxcode{\sphinxupquote{np.polyfit}} returns an array of size 2, where the first element is the slope and the second is the \(y\)\sphinxhyphen{}intercept.

\sphinxAtStartPar
For this exercise, we will be expressing demand and supply as quantities in terms of price.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{np}\PYG{o}{.}\PYG{n}{polyfit}\PYG{p}{(}\PYG{n}{oranges}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{oranges}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Quantity}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([\PYGZhy{}3432.84670093, 53625.8748401 ])
\end{sphinxVerbatim}

\sphinxAtStartPar
This shows that the demand curve is \(D(P) = -3433 P+ 53626\). The slope is \sphinxhyphen{}3433 and \(y\)\sphinxhyphen{}intercept is 53626. That means that as price increases by 1 unit (in this case, \$1), quantity decreases by 3433 units (in this case, 3433 tons).


\paragraph{Create the Demand Curve}
\label{\detokenize{content/02-supply/03-market-equilibria:create-the-demand-curve}}
\sphinxAtStartPar
We will now use SymPy to write out this demand curve. To do so, we start by creating a symbol \sphinxcode{\sphinxupquote{P}} that we can use to create the equation.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{P} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{P}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{demand} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{3432.846} \PYG{o}{*} \PYG{n}{P} \PYG{o}{+} \PYG{l+m+mf}{53625.87}
\PYG{n}{demand}
\end{sphinxVerbatim}
\begin{equation*}
\begin{split}\displaystyle 53625.87 - 3432.846 P\end{split}
\end{equation*}

\paragraph{Create the Supply Curve}
\label{\detokenize{content/02-supply/03-market-equilibria:create-the-supply-curve}}
\sphinxAtStartPar
As you’ve learned, the supply curve is the relationship between the price of a good or service and the quantity of that good or service that the seller is willing to supply. It shows how much of a good suppliers are willing and able to supply at different prices. In this case, as the price of the oranges increases, the quantity of oranges that orange manufacturers are willing to supply increases. They capture the producer’s side of market decisions and are upward\sphinxhyphen{}sloping.

\sphinxAtStartPar
Let’s now assume that the supply curve is given by \(S(P) = 4348P\). (Note that this supply curve is not based on data.)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{supply} \PYG{o}{=} \PYG{l+m+mi}{4348} \PYG{o}{*} \PYG{n}{P}
\PYG{n}{supply}
\end{sphinxVerbatim}
\begin{equation*}
\begin{split}\displaystyle 4348 P\end{split}
\end{equation*}
\sphinxAtStartPar
This means that as the price of oranges increases by 1, the quantity supplied increases by 4348. At a price of 0, no oranges are supplied.


\paragraph{Find the Price Equilibrium}
\label{\detokenize{content/02-supply/03-market-equilibria:find-the-price-equilibrium}}
\sphinxAtStartPar
With the supply and demand curves known, we can solve the for equilibrium.
The equilibrium is the point where the supply curve and demand curve intersect, and denotes the price and quantity of the good transacted in the market.

\sphinxAtStartPar
The equilbrium consists of 2 components: the quantity equilbrium and price equilbrium.
The price equilibrium is the price at which the supply curve and demand curve intersect: the price of the good that consumers desire to purchase at is equivalent to the price of the good that producers want to sell at. There is no shortage of surplus of the product at this price.

\sphinxAtStartPar
Let’s find the price equilibrium. To do this, we will use the provided \sphinxcode{\sphinxupquote{solve}} function. This is a custom function that leverages some SymPy magic and will be provided to you in assignments.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{P\PYGZus{}star} \PYG{o}{=} \PYG{n}{solve}\PYG{p}{(}\PYG{n}{demand}\PYG{p}{,} \PYG{n}{supply}\PYG{p}{)}
\PYG{n}{P\PYGZus{}star}
\end{sphinxVerbatim}
\begin{equation*}
\begin{split}\displaystyle 6.89203590457901\end{split}
\end{equation*}
\sphinxAtStartPar
This means that the price of oranges that consumers want to purchase at and producers want to provide is about \$6.89.


\paragraph{Find the Quantity Equilibrium}
\label{\detokenize{content/02-supply/03-market-equilibria:find-the-quantity-equilibrium}}
\sphinxAtStartPar
Similarly, the quantity equilibrium is the quantity of the good that consumers desire to purchase is equivalent to the quantity of the good that producers supply; there is no shortage or surplus of the good at this quantity.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{demand}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{P}\PYG{p}{,} \PYG{n}{P\PYGZus{}star}\PYG{p}{)}
\PYG{n}{supply}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{P}\PYG{p}{,} \PYG{n}{P\PYGZus{}star}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{equation*}
\begin{split}\displaystyle 29966.5721131095\end{split}
\end{equation*}
\sphinxAtStartPar
This means that the number of tons of oranges that consumers want to purchase and producers want to provide in this market is about 29,967 tons of oranges.


\paragraph{Visualize the Market Equilibrium}
\label{\detokenize{content/02-supply/03-market-equilibria:visualize-the-market-equilibrium}}
\sphinxAtStartPar
Now that we have our demand and supply curves and price and quantity equilibria, we can visualize them on a graph to see what they look like.

\sphinxAtStartPar
There are 2 pre\sphinxhyphen{}made functions we will use: \sphinxcode{\sphinxupquote{plot\_equation}} and \sphinxcode{\sphinxupquote{plot\_intercept}}.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{plot\_equation}}: It takes in the equation we made previously (either demand or supply) and visualizes the equations between the different prices we give it

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{plot\_intercept}}: It takes in two different equations (demand and supply), finds the point at which the two intersect, and creates a scatter plot of the result

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{plot\PYGZus{}equation}\PYG{p}{(}\PYG{n}{equation}\PYG{p}{,} \PYG{n}{price\PYGZus{}start}\PYG{p}{,} \PYG{n}{price\PYGZus{}end}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{plot\PYGZus{}prices} \PYG{o}{=} \PYG{p}{[}\PYG{n}{price\PYGZus{}start}\PYG{p}{,} \PYG{n}{price\PYGZus{}end}\PYG{p}{]}
    \PYG{n}{plot\PYGZus{}quantities} \PYG{o}{=} \PYG{p}{[}\PYG{n}{equation}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{equation}\PYG{o}{.}\PYG{n}{free\PYGZus{}symbols}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{c}\PYG{p}{)} \PYG{k}{for} \PYG{n}{c} \PYG{o+ow}{in} \PYG{n}{plot\PYGZus{}prices}\PYG{p}{]}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plot\PYGZus{}quantities}\PYG{p}{,} \PYG{n}{plot\PYGZus{}prices}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{n}{label}\PYG{p}{)}
    
\PYG{k}{def} \PYG{n+nf}{plot\PYGZus{}intercept}\PYG{p}{(}\PYG{n}{eq1}\PYG{p}{,} \PYG{n}{eq2}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{ex} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{solve}\PYG{p}{(}\PYG{n}{eq1}\PYG{o}{\PYGZhy{}}\PYG{n}{eq2}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{n}{why} \PYG{o}{=} \PYG{n}{eq1}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{eq1}\PYG{o}{.}\PYG{n}{free\PYGZus{}symbols}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{ex}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{p}{[}\PYG{n}{why}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{n}{ex}\PYG{p}{]}\PYG{p}{,} \PYG{n}{zorder}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{tab:orange}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{(}\PYG{n}{ex}\PYG{p}{,} \PYG{n}{why}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can leverage these functions and the equations we made earlier to create a graph that shows the market equilibrium.

\noindent\sphinxincludegraphics{{03-market-equilibria_30_0}.png}

\sphinxAtStartPar
You can also practice on your own and download additional data sets \sphinxhref{http://users.stat.ufl.edu/~winner/datasets.html}{here}, courtesy of the University of Flordia’s Statistics Department.


\subsubsection{Movements Away from Equilibrium}
\label{\detokenize{content/02-supply/03-market-equilibria:movements-away-from-equilibrium}}
\sphinxAtStartPar
What happens to market equilibrium when either supply or demand shifts due to an exogenous shock?

\sphinxAtStartPar
Let’s assume that consumers now prefer Green Tea as their hot beverage of choice moreso than before. We have an outward shift of the demand curve \sphinxhyphen{} quantity demanded is greater at every price. The market is no longer in equilibrium.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{fig1-demand}.png}
\caption{A shift in the demand curve}\label{\detokenize{content/02-supply/03-market-equilibria:demand-shift}}\end{figure}

\sphinxAtStartPar
At the same price level (the former equilibrium price), there is a shortage of Green Tea. The amount demanded by consumers exceeds that supplied by producers: \(Q_D > Q_S\). This is a seller’s market, as the excess quantity demanded gives producers leverage (or market power) over consumers. They are able to increase the price of Green Tea to clear the shortage. As prices increase, consumers who were willing and able to purchase tea at the previous equilibrium price would leave the market, reducing quantity demanded. \(Q_S\) and \(Q_D\) move up along their respective curves until the new equilibrium is achieved where \(Q_S = Q_D\).

\sphinxAtStartPar
This dual effect of increasing \(Q_S\) and \(Q_D\) is sometimes referred to as the “invisible hand”. Sans government intervention, it clears out the shortage or surplus in the market, resulting in the eventual convergence to a new equilibrium level of quantity \(Q^*\) and price \(P^*\).


\subsection{SymPy}
\label{\detokenize{content/02-supply/04-sympy:sympy}}\label{\detokenize{content/02-supply/04-sympy::doc}}
\sphinxAtStartPar
Python has many tools, such as the \sphinxhref{https://docs.sympy.org/latest/tutorial/index.html}{SymPy library} that we can use for expressing and evaluating formulas and functions in economics.

\sphinxAtStartPar
Since SymPy helps with symbolic math, we start out by create a symbol using \sphinxcode{\sphinxupquote{Symbol}}, which we assign to a variable name. Then, we can use the symbols to construct symbolic expressions.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{x} \PYG{o}{=} \PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{x}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_3_0}.png}

\sphinxAtStartPar
Now let’s try using SymPy to create a symbolic expression for some hypothetical supply and demand curves.

\sphinxAtStartPar
To define an upward sloping supply curve with price expressed as a function of quantity, we start off defining the symbol \(Q\), which represents quantity. Then, we set up a negative relationship expressing \(P_S\), which denotes the price of the supplied good (how much the producer earns), in terms of \(Q\).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Q} \PYG{o}{=} \PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Q}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{P\PYGZus{}S} \PYG{o}{=} \PYG{l+m+mi}{2} \PYG{o}{*} \PYG{n}{Q} \PYG{o}{\PYGZhy{}} \PYG{l+m+mi}{3}
\PYG{n}{P\PYGZus{}S}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_5_0}.png}

\sphinxAtStartPar
Similarly, we will also use \(Q\) to express a relationship with \(P_D\), the price of the good purchased (how much the consumer pays), creating a downward sloping demand curve.

\sphinxAtStartPar
Note that both functions are of the variable \(Q\); this will be important in allowing us to solve for the equilibrium.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{P\PYGZus{}D} \PYG{o}{=} \PYG{l+m+mi}{2} \PYG{o}{\PYGZhy{}} \PYG{n}{Q}
\PYG{n}{P\PYGZus{}D}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_7_0}.png}

\sphinxAtStartPar
To solve for the equilibrium given the supply and demand curve, we know that the price paid by consumers must equal to the price earned by suppliers. Thus, \(P_D = P_S\), allowing us to set the two equations equal to each other and solve for the equilibrium quantity and thus equilibrium price. To solve this by hand, we would set up the following equation to solve for \(Q\):
\begin{equation*}
\begin{split}
P_D = P_S\\
2-Q = 2Q-3
\end{split}
\end{equation*}
\sphinxAtStartPar
Using SymPy, we call \sphinxcode{\sphinxupquote{solve}}, which takes in 2 arguments that represent the 2 sides of an equation and solves for the underlying variable such that the equation holds. Here, we pass in \(P_D\) and \(P_S\), both represented in terms of \(Q\), to solve for the value of \(Q\) such that \(P_D=P_S\). It’s good to know that \sphinxcode{\sphinxupquote{solve}} is a custom function built for this class, and will be provided in the notebooks for you.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Q\PYGZus{}star} \PYG{o}{=} \PYG{n}{solve}\PYG{p}{(}\PYG{n}{P\PYGZus{}D}\PYG{p}{,} \PYG{n}{P\PYGZus{}S}\PYG{p}{)}
\PYG{n}{Q\PYGZus{}star}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_9_0}.png}

\sphinxAtStartPar
The value of \(Q\) that equates \(P_D\) and \(P_S\) is known as the market equilibrium quantity, and we denote it as \(Q^*\). Here, \(Q^* = \frac{5}{3}\).

\sphinxAtStartPar
With \(Q^*\) determined, we can substitute this value as \(Q\) to thus calculate \(P_D\) or \(P_S\). We substitute values using the \sphinxcode{\sphinxupquote{subs}} function, which follows the syntax \sphinxcode{\sphinxupquote{expression.subs(symbol\_we\_want\_to\_substitute, value\_to\_substitute\_with)}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{P\PYGZus{}D}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{Q}\PYG{p}{,} \PYG{n}{Q\PYGZus{}star}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_11_0}.png}

\sphinxAtStartPar
We can also substitute \(Q^*\) into \(P_S\), and should get the same results.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{P\PYGZus{}S}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{Q}\PYG{p}{,} \PYG{n}{Q\PYGZus{}star}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_13_0}.png}

\sphinxAtStartPar
Thus, the equilibrium price and quantity are \$0.33 and \(\frac{5}{3}\), respectively.

\sphinxAtStartPar
Let’s try another example. Suppose our demand function is \(\text{Price}_{D}=-2 \cdot \text{Quantity} + 10\). Using SymPy, this would be

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{demand} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2} \PYG{o}{*} \PYG{n}{Q} \PYG{o}{+} \PYG{l+m+mi}{10}
\PYG{n}{demand}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_15_0}.png}

\sphinxAtStartPar
In addition, let the supply function be \(\text{Price}_{S}=3 \cdot \text{Quantity} + 1\). Using SymPy, this would be

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{supply} \PYG{o}{=} \PYG{l+m+mi}{3} \PYG{o}{*} \PYG{n}{Q} \PYG{o}{+} \PYG{l+m+mi}{1}
\PYG{n}{supply}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_17_0}.png}

\sphinxAtStartPar
We will now try to find the market equilibrium. The market price equilibrium \(P^*\) is the price at which the quantity supplied and quantity demanded of a good or service are equal to each other. Similarly, the market quantity equilibrium \(Q^*\) is the quantity at which the price paid by consumers is equal to the price received by producers.

\sphinxAtStartPar
Combined, the price equilibrium and quantity equilibrium form a point on the graph with quantity and price as its axes, called the equilibrium point. This point is the point at which the demand and supply curves intersect.

\sphinxAtStartPar
First, we solve for the quantity equilibrium.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Q\PYGZus{}star} \PYG{o}{=} \PYG{n}{solve}\PYG{p}{(}\PYG{n}{demand}\PYG{p}{,} \PYG{n}{supply}\PYG{p}{)}
\PYG{n}{Q\PYGZus{}star}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_19_0}.png}

\sphinxAtStartPar
Next, we plug the quantity equilibrium into our demand or supply expression to get the price equilibrium:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{demand}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{Q}\PYG{p}{,} \PYG{l+m+mi}{9}\PYG{o}{/}\PYG{l+m+mi}{5}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_21_0}.png}

\sphinxAtStartPar
Graphically, we can plot the supply and demand curves with quantity on the \(x\) axis and price on the \(y\) axis. The point at which they intersect is the equilibrium point.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{plot\PYGZus{}equation}\PYG{p}{(}\PYG{n}{equation}\PYG{p}{,} \PYG{n}{price\PYGZus{}start}\PYG{p}{,} \PYG{n}{price\PYGZus{}end}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{plot\PYGZus{}prices} \PYG{o}{=} \PYG{p}{[}\PYG{n}{price\PYGZus{}start}\PYG{p}{,} \PYG{n}{price\PYGZus{}end}\PYG{p}{]}
    \PYG{n}{plot\PYGZus{}quantities} \PYG{o}{=} \PYG{p}{[}\PYG{n}{equation}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{equation}\PYG{o}{.}\PYG{n}{free\PYGZus{}symbols}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{c}\PYG{p}{)} \PYG{k}{for} \PYG{n}{c} \PYG{o+ow}{in} \PYG{n}{plot\PYGZus{}prices}\PYG{p}{]}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plot\PYGZus{}prices}\PYG{p}{,} \PYG{n}{plot\PYGZus{}quantities}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{n}{label}\PYG{p}{)}
    
\PYG{k}{def} \PYG{n+nf}{plot\PYGZus{}intercept}\PYG{p}{(}\PYG{n}{eq1}\PYG{p}{,} \PYG{n}{eq2}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{ex} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{solve}\PYG{p}{(}\PYG{n}{eq1}\PYG{o}{\PYGZhy{}}\PYG{n}{eq2}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{n}{why} \PYG{o}{=} \PYG{n}{eq1}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{eq1}\PYG{o}{.}\PYG{n}{free\PYGZus{}symbols}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{ex}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{p}{[}\PYG{n}{ex}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{n}{why}\PYG{p}{]}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{(}\PYG{n}{ex}\PYG{p}{,} \PYG{n}{why}\PYG{p}{)}
    
\PYG{n}{plot\PYGZus{}equation}\PYG{p}{(}\PYG{n}{demand}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{n}{plot\PYGZus{}equation}\PYG{p}{(}\PYG{n}{supply}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylim}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{20}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Quantity}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plot\PYGZus{}intercept}\PYG{p}{(}\PYG{n}{supply}\PYG{p}{,} \PYG{n}{demand}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{04-sympy_23_0}.png}


\section{Public Economics}
\label{\detokenize{content/03-public/index:public-economics}}\label{\detokenize{content/03-public/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{Public economics} deals with the different methods government policy affect market equilibria, and studies these through the lens of economic efficiency and equity. This chapter begins with a graphical and mathematical overview of market equilibrium. It follows with a discussion of consumer and producer surplus \sphinxhyphen{} specifically how these concepts underscore the competing forces of supply and demand. Last, it covers the different ways in which governments intervene: taxes, subsidies and price controls. It discusses their effects on welfare and how intervention changes market participation


\subsection{Taxes and Subsidies}
\label{\detokenize{content/03-public/taxes-subsidies:taxes-and-subsidies}}\label{\detokenize{content/03-public/taxes-subsidies::doc}}
\sphinxAtStartPar
Now that we have discussed cases of market equilibrium with just demand and supply, also known as free market cases, we will examine what happens when the government intervenes. In all of these cases, the market is pushed from equilibrium to a state of disequilibrium. This causes the price to change and, as a result, the quantity transacted in the market.

\sphinxAtStartPar
Broadly, a tax is any type of financial charge imposed by the government, such as income tax, property tax, or excise tax. In this course, and for this section in particular, we will consider only taxes levied on consumption. These taxes are typically enforced on a state level in the US, and can take 2 forms:
\begin{itemize}
\item {} 
\sphinxAtStartPar
An \sphinxstyleemphasis{excise tax} levies a fixed dollar amount on a particular good or service. A flat \$1 tax per packet of cigarette sold is an example of an excise tax.

\item {} 
\sphinxAtStartPar
An \sphinxstyleemphasis{ad valorem tax} levies a percentage amount on the purchase of a particular good or service. For example the sales tax is an ad valorem tax.

\end{itemize}

\sphinxAtStartPar
Notably, consumption taxes can be levied on either the producer or the consumer. The side that pays for the tax \sphinxstyleemphasis{upfront} (when a transaction occurs) is known as the party that bears the \sphinxstylestrong{statutory incidence} of the tax. However, as you’ll soon learn, this does not mean that the party paying for the tax upfront bears the entire \sphinxstylestrong{economic incidence} of the tax.

\sphinxAtStartPar
A subsidy is the opposite of a tax; it involves either a monetary benefit given by the government or a reduction in taxes granted to individual businesses or whole industries.


\subsubsection{Why Tax or Subsidize?}
\label{\detokenize{content/03-public/taxes-subsidies:why-tax-or-subsidize}}
\sphinxAtStartPar
The supply and demand models that we’ve examined so far do not necessarily reflect the entire picture; often, there are additional social costs or benefits associated with producing or consuming a good that is not paid for by a firm or considered by consumers.

\sphinxAtStartPar
For example, take a factory producing dyed color T\sphinxhyphen{}shirts that pollute a nearby river. In a world without government intervention, the firm would not have to clean up the river even though they should include factor that into their costs. This is an example of a \sphinxstylestrong{negative externality}, in which the \sphinxstyleemphasis{private cost} faced in production by a firm or consumption by a consumer is lower than the actual \sphinxstyleemphasis{social cost}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{fig1-negative-externality}.png}
\caption{A supply\sphinxhyphen{}side negative externality in which the marginal social cost is greater than the marginal private cost}\label{\detokenize{content/03-public/taxes-subsidies:negative-externality}}\end{figure}

\sphinxAtStartPar
Take another example: vaccines. By consuming a vaccine shot, a consumer benefits their communities to overall reduce transmission of a disease. However, chances are the consumer probably did not consider the social benefits when making a decision on whether to vaccinate. This is an example of a \sphinxstylestrong{positive externality}, in which the \sphinxstyleemphasis{private benefit} faced in production by a firm or consumption by a consumer is lower than the actual \sphinxstyleemphasis{social benefit} (alternatively, in some cases it may be more intuitive to think about it as the \sphinxstyleemphasis{private cost} is greater than the \sphinxstyleemphasis{social cost}. Similarly, the opposite holds true for negative externalities).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{fig1-positive-externality}.png}
\caption{A demand\sphinxhyphen{}side positive externality in which the marginal social benefit is greater than the marginal private benefit}\label{\detokenize{content/03-public/taxes-subsidies:positive-externality}}\end{figure}

\sphinxAtStartPar
In this case, a \sphinxstylestrong{market failure} occurs, in which the true quantity demanded by society does not match what would occur in a free market without government intervention. This is where taxes and interventions come in: they can correct for externalities and thus resolve consequent market failures.


\subsubsection{Effects of Taxation}
\label{\detokenize{content/03-public/taxes-subsidies:effects-of-taxation}}
\sphinxAtStartPar
The primary method that governments use to intervene in markets to address negative externalities is taxation.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{fig2-supply-tax}.png}
\caption{A shift in supply due to a tax levied on producers}\label{\detokenize{content/03-public/taxes-subsidies:supply-tax}}\end{figure}

\sphinxAtStartPar
If a tax is levied on producers, this decreases the quantity of goods they can supply at each price as the tax is effectively acting as an additional cost of production. This shifts the supply curve leftward. Compared to negative externality graph above, we can see that the tax essentially ‘corrects’ the supply curve based on the marginal private cost to instead mirror the supply curve based on the marginal social cost.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{fig3-demand-tax}.png}
\caption{A shift in demand due to a tax levied on consumers}\label{\detokenize{content/03-public/taxes-subsidies:demand-tax}}\end{figure}

\sphinxAtStartPar
If the tax is levied on consumers, this increases the price per unit they must pay, thereby reducing quantity demanded at every price. This shifts the demand curve leftward.


\subsubsection{Effects of Subsidies}
\label{\detokenize{content/03-public/taxes-subsidies:effects-of-subsidies}}
\sphinxAtStartPar
To account for positive externalities, a popular form of government intervention is a subsidy. They intend to lower production or consumption costs, and thus increase the quantity supplied of goods and services at equilibrium.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{fig5-subsidy}.png}
\caption{A shift in supply due to a new subsidy}\label{\detokenize{content/03-public/taxes-subsidies:subsidy}}\end{figure}

\sphinxAtStartPar
We represent this visually as a rightward shift in the supply curve. As costs are lower, producers are now willing to supply more goods and services at every price. The demand curve remains unchanged as a subsidy goes directly to producers. The resulting equilibrium has a lower price \(P^*\) and higher quantity \(Q^*\). It is assumed that the lower production costs would be passed onto consumers through lower market prices. \(P^*\) is what consumers pay, but producers receive \(P_P = P^* + \text{subsidy}\). This is depicted visually by the price along the new supply curve at quantity \(Q^*\).

\sphinxAtStartPar
Consumer surplus increases as more individuals are able to purchase the good than before. Similarly, producer surplus has increased as the subsidy takes care of part (if not all) of their costs. Overall market surplus has increased.

\sphinxAtStartPar
The welfare gain is depicted in a similar way to that of a tax: a triangle with a vertex at the original market equilibrium and a base along \(Q^*\). The cost of the subsidy to the government is \(\text{per-unit subsidy} \cdot Q^*\).


\subsubsection{Examining the Effects of Taxes}
\label{\detokenize{content/03-public/taxes-subsidies:examining-the-effects-of-taxes}}
\sphinxAtStartPar
For the rest of this section, we will examine the effects of taxes in more detail.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{fig4-dwl-tax-wedge}.png}
\caption{Deadweight loss due to a tax levied on consumers}\label{\detokenize{content/03-public/taxes-subsidies:dwl-tax-wedge}}\end{figure}

\sphinxAtStartPar
The resulting equilibrium \sphinxhyphen{} both price and quantity \sphinxhyphen{} is the same in both cases. However, the prices paid by producers and consumers are different. Let us denote the equilibrium quantity to be \(Q^*\). The price that producers pay \(P_p\) occurs where \(Q^*\) intersects with the supply curve. At the same time, the price that consumers pay \(P_c\) occurs where \(Q^*\) intersects  the demand curve.

\sphinxAtStartPar
You will notice that the vertical distance between \(P_p\) and \(P_c\) will be the value of the tax. That is to say, \(P_c = P_p + \text{tax}\). We call the vertical distance between \(P_p\) and \(P_c\) at quantity \(Q^*\) the tax wedge.


\paragraph{Incidence}
\label{\detokenize{content/03-public/taxes-subsidies:incidence}}
\sphinxAtStartPar
Determining who bears the greater burden, or economic incidence, of the tax depends on the relative producer and consumer price elasticities. A good that consumers are relatively more inelastic towards (such that producers are more elastic) would mean that the burden of paying the tax will fall on consumers moreso than producers. Intuitively, this is because consumers are less sensitive to price changes and thus are ‘more willing’ to pay more to adjust to the tax. The opposite is true if the consumers are relatively more elastic (i.e. the producers are relatively more inelastic). See the figure below for more details.

\sphinxAtStartPar
One can calculate the burden share, or the proportion of the tax paid by consumers or producers:

\sphinxAtStartPar
Consumer’s burden share:
\begin{equation*}
\begin{split}\dfrac{\text{Increase in unit price after the tax paid by consumers} + \text{Increase in price paid per unit by consumers to producers}}{\text{Tax per unit}}\end{split}
\end{equation*}
\sphinxAtStartPar
Producer’s burden share:
\begin{equation*}
\begin{split}\dfrac{\text{Increase in unit price after the tax paid by producers} - \text{Increase in price paid per unit by consumers to producers}}{\text{Tax per unit}}\end{split}
\end{equation*}
\sphinxAtStartPar
Graphically, the total tax burden is the rectangle formed by the tax wedge and the horizontal distance between 0 and \(Q^*\): \(Q^* \cdot \text{tax}\) This is also how you calculate the revenue from the tax earned by the government.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=900\sphinxpxdimen]{{fig6-elasticity-of-taxes}.png}
\caption{Differences in economic incidences of a tax due to elastic and inelastic demand.}\label{\detokenize{content/03-public/taxes-subsidies:elasticity-of-taxes}}\end{figure}


\paragraph{Deadweight Loss}
\label{\detokenize{content/03-public/taxes-subsidies:deadweight-loss}}
\sphinxAtStartPar
Naturally, the introduction of the tax disrupts the economy and pushes it away from equilibrium. For consumers, the higher price they must pay essentially “prices” out some individuals \sphinxhyphen{} they are now unwilling to pay more for the good. This leads them to leave the market that they previously participated in. At the same time, for producers, the introduction of the tax increases production costs and cuts into their revenues. Some of the businesses that were willing to produce at moderately high costs now find themselves unable to make a profit with the introduction of the tax. They too leave the market. There are market actors who are no longer able to purchase or sell the good.

\sphinxAtStartPar
We call this loss of transactions: deadweight welfare loss. It is represented by the triangle with a vertex at the original market equilibrium and a base at the tax wedge. The area of the deadweight loss triangle, also known as Harberger’s triangle, is the size of the welfare loss \sphinxhyphen{} the total value of transactions lost as a result of the tax.

\sphinxAtStartPar
Another way to think about deadweight loss is the change (decrease) in total surplus. Consumer and producer surplus decrease significantly, but this is slightly offset by the revenue earned by the government from the tax.

\sphinxAtStartPar
We can calculate the size of Harberger’s triangle using the following formula: \(\dfrac{1}{2} \cdot \dfrac{\epsilon_s \cdot \epsilon_d}{\epsilon_s - \epsilon_d} \cdot \dfrac{Q^*}{P_p} (\text{tax})^2\) where \(\epsilon_s\) is the price elasticity of supply and  \(\epsilon_d\) is the price elasticity of demand.


\paragraph{Salience}
\label{\detokenize{content/03-public/taxes-subsidies:salience}}
\sphinxAtStartPar
We noted in our discussion about taxes that the equilibrium quantity and price is the same regardless of whether the tax is levied on producers or consumers. This is the traditional theory’s assumption: that individuals, whether they be producers or consumers, are fully aware of the taxes they pay. They decide how much to produce or consume with this in mind.

\sphinxAtStartPar
We call the visibility at which taxes are displayed their salience. As an example, the final price of a food item in a restaurant is not inclusive of sales tax. Traditional economic theory would say that this difference between advertized or poster price and the actual price paid by a consumer has no bearing on the quantity they demand. That is to say taxes are fully salient. However, recent research has suggested that this is not the case.

\sphinxAtStartPar
A number of recent studies, including by Chetty, Looney and Kroft in 2009, found that posting prices that included sales tax actually reduces demand for those goods. Individuals are not fully informed or rational, implying that tax salience does matter.


\subsubsection{Calculating Taxes Algebraically}
\label{\detokenize{content/03-public/taxes-subsidies:calculating-taxes-algebraically}}

\paragraph{Expressing Quantity as a Function of Price}
\label{\detokenize{content/03-public/taxes-subsidies:expressing-quantity-as-a-function-of-price}}
\sphinxAtStartPar
So far, we have expressed our demand and supply curves using prices as a function of quantity, e.g. \(D(Q) = 100 - Q\). This format aligns with the axes of our plots, since quantity is on the x\sphinxhyphen{}axis and price is on the y\sphinxhyphen{}axis. However, it perhaps makes more sense to switch this around, expressing quantity demanded or supplied as a function of price. Intuitively, the price of a good or service causes the quantity supplied or demanded to alter; at high prices, producers would be willing to supply a great deal of units while few consumers would enter the market, while the opposite is true at low prices.

\sphinxAtStartPar
To switch in between the different formats, we simply have to solve for the independent variable and express it in terms of our dependent variable. For
example, if demand is expressed as \(D(Q) = 100 - Q\), then:
\begin{equation*}
\begin{split}
\begin{align*}
P &= 100 - Q \\
P - 100 &= -Q \\
Q &= 100 - P = D(P)
\end{align*}
\end{split}
\end{equation*}

\paragraph{Solving for the new quantity and price equilibria}
\label{\detokenize{content/03-public/taxes-subsidies:solving-for-the-new-quantity-and-price-equilibria}}
\sphinxAtStartPar
In previous weeks where there was no tax in the market, we could equate demand and supply to solve for the market price/quantity:
\begin{equation*}
\begin{split}D(P) = S(P)\end{split}
\end{equation*}
\sphinxAtStartPar
In reality, the demand function is based on the price consumers pay (which we’ll denote \(P_c\)), and the supply function is based on the price producers receive (which we’ll denote \(P_p\)). Hence, the actual demand and supply functions are \(D(P_c)\) and \(S(P_p)\), so we should be equating:
\begin{equation*}
\begin{split}D(P_c) = S(P_p)\end{split}
\end{equation*}
\sphinxAtStartPar
In the no\sphinxhyphen{}tax scenario, the price received by producers is the same as the price paid by consumers. Hence, we are able to get away by expressing them both as \(P\) above, where \(P=P_p=P_c\).

\sphinxAtStartPar
However, in the case of tax, \(P_p\) is no longer equal to \(P_c\). Specifically, \(P_p+\text{tax}=P_c\). As a result, to solve for equilibrium with taxes, we can use substitution to express \(P_c\) as \(P_p+\text{tax}\), or \(P_p\) as \(P_c−\text{tax}\). Hence we actually aim to equate:
\begin{equation*}
\begin{split}D(P_c)=S(P_p)\implies D(P_p+\text{tax})=S(P_p)\quad \text{or} \quad D(P_c)=S(P_c−\text{tax})\end{split}
\end{equation*}
\sphinxAtStartPar
Because there are now 3 unknowns (\(P_c,P_p,Q\)) and 3 equations (\(P_p+\text{tax}=P_c\), supply equation, and demand equation), we conduct this substitution to reduce it to 2 equations and 2 unknowns. Essentially, you’ll find that the tax simply was just a shift in the intercepts, which matches our graphical intuition from the diagrams above!

\sphinxAtStartPar
Once we are able to solve for \(P_p\) or \(P_c\), we can add/subtract the tax to get the other. We can also plug \(P_c\) into \(D(P_c)\) to get the equilibrium quantity, which should be the same as plugging in \(P_p\) into \(S(P_p)\).

\sphinxAtStartPar
Lastly, to calculate the consumer burden, we seek to measure how much more the consumers are now paying due to the tax. Hence, this value is \(P_c−P\), where \(P\) is the original price when there is no tax. Similarly, to calculate the producer burden, we seek to measure how much less the producers are now receiving due to the tax; this value is \(P−P_p\).


\subsubsection{An Example}
\label{\detokenize{content/03-public/taxes-subsidies:an-example}}
\sphinxAtStartPar
\sphinxstylestrong{Part 1:} Suppose the demand for rutabagas is \(D(P_c) = 2000 − 100P_c\). The supply of rutabagas is: \(S(P_p) = −100 + 200P_p\). What is the equilibrium price without the tax?

\begin{sphinxadmonition}{note}{Solution}

\sphinxAtStartPar
Since there is no tax, \(P_p = P_c = P\). Thus:
\begin{equation*}
\begin{split}
\begin{align*}
2000 - 100P &= -100 + 200 P \\
2100 - 100P &= 200 P \\
2100 &= 300 P \\
P &= 7 \\
\end{align*}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Part 2:}
What is the equilibrium price with a per unit \$2 sales tax?

\begin{sphinxadmonition}{note}{Solution}

\sphinxAtStartPar
With a \$2 sales tax, we know that \(P_c = P_p + 2\). Thus:
\begin{equation*}
\begin{split}
\begin{align*}
2000 - 100P_c &= -100 + 200 P_p\\
2000 - 100(P_p+2) &= -100 + 200P_p \\
2000 - 100P_p - 200 &= -100 + 200P_p \\
1900 - 100P_p &= + 200P_p \\
1900 &= 300P_p \\
P_p &= 6.33 \\ 
P_c &= 6.33 + 2 = 8.33
\end{align*}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Part 3:}
What are the tax burdens on the consumer and producer?

\begin{sphinxadmonition}{note}{Solution}

\sphinxAtStartPar
Consumer burden: \(\text{New price paid} - \text{Old price paid} = 8.33 - 7 = 1.33\)

\sphinxAtStartPar
Producer burden: \(\text{Old price received} - \text{New price received} = 7 - 6.33 = 0.67\)

\sphinxAtStartPar
This means that the consumer bears \(\frac{2}{3}\) of the total burden of the tax.
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Part 4:}
What is change in quantity transacted due to the tax?

\begin{sphinxadmonition}{note}{Solution}

\sphinxAtStartPar
Originally, \(Q = 2000 - 100P_c = 2000 - 100\times 7 = 1300\).

\sphinxAtStartPar
Now, \(Q = 2000 - 100P_c = 2000 - 100\times 8.33 = 1167\).
The difference in quantity transacted is thus \(1300 - 1167 = 133\) units.

\sphinxAtStartPar
Note that we can also plug in \(P_p\) into the supply equation and get the same results!
\end{sphinxadmonition}


\subsection{Surplus}
\label{\detokenize{content/03-public/surplus:surplus}}\label{\detokenize{content/03-public/surplus::doc}}

\subsubsection{Consumer Surplus}
\label{\detokenize{content/03-public/surplus:consumer-surplus}}
\sphinxAtStartPar
Although all consumers face the same market price, consumers are different in how much they individually value a good. We say that consumers have a maximum price that they are willing to pay for a good, and any price marginally higher than this price will dissuade the consumer from participating in the market. This max willingness to pay (WTP) price varies among entities based on their desire for the good, which in turn can be based on how much of the good they already have.

\sphinxAtStartPar
Consider the market for electricity. Among consumers we have entities such as households, commercial buildings, factories, and so on. A factory would likely have a very high WTP for electricity because the opportunity costs for factories to not operate are very high. Capital is expensive, employees still have to be paid, and it is inconvenient to have to stop and start up machinery frequently. Thus, for a factory it is preferable to always have a reliable supply of electricity to continue operations and this need is reflected in the WTP. Contrast this with households, who certainly value having electricity, but should electricity become prohibitively expensive, probably would decide to cut back on usage as the drawbacks of not having electricity aren’t as severe compared to the factory above.


\subsubsection{Producer Surplus}
\label{\detokenize{content/03-public/surplus:producer-surplus}}
\sphinxAtStartPar
Producers experience a similar characteristic. A producer has a minimum price at which it is willing to produce a good based on its costs. Any market price less than this price would dissuade a producer from supplying its good. Again, in the electricity example, we have several power plants that produce electricity, but each inherently does so at different costs. Imagine and contrast the operating costs of a solar farm with a coal plant, or a newer, more efficient natural gas plant versus an older one.

\sphinxAtStartPar
Putting all of these concepts together we arrive at the idea of economic welfare. Suppose electricity costs 10 cents per kWh. On the demand side, imagine a factory who’s WTP is 30 cents/kWh. This factory enjoys a consumer surplus of 20 cents/kWh, in other words, it’s paying 20 cents less per kWh than what it would be willing to pay. A household might have a WTP of 15 cents/kWh. Here the household’s surplus is only 5 cents/kWh. We can also imagine a consumer whose WTP is less than the market price and thus doesn’t participate in the market. Imagine for some reason that cryptocurrency prices have dropped to the point that they aren’t worth the electricity it takes to mine them. In this case, we might have an idle or non\sphinxhyphen{}existent crypto\sphinxhyphen{}farm (a place with a lot of computing power) due to electricity being too expensive. On the producer side, maybe we have a solar plant which is operating at the market price, but a natural gas plant that is idling because the price of supplying electricity isn’t sufficient to make up for operating costs.

\sphinxAtStartPar
Combining the surpluses of all individual consumers and producers yields the market consumer surplus and producer surplus. As the market price fluctuates, certain comsumers and producers enter and exit the market, and the total surplus varies. Note from the above examples that a consumer is not always an individual, it can be a firm buying from another firm. We now explore further.


\subsubsection{Example}
\label{\detokenize{content/03-public/surplus:example}}
\sphinxAtStartPar
We create a consumer class with a WTP characteristic, and a list of consumers with WTP from 10 to 1. The binary function \sphinxcode{\sphinxupquote{demand}} \sphinxcode{\sphinxupquote{1}} if the consumer participates in the market at a given price and \sphinxcode{\sphinxupquote{0}} if not.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{class} \PYG{n+nc}{Consumer}\PYG{p}{:}
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{WTP}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{WTP} \PYG{o}{=} \PYG{n}{WTP}
        
    \PYG{k}{def} \PYG{n+nf}{demand}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{price}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{if} \PYG{n}{price} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{WTP}\PYG{p}{:}
            \PYG{k}{return} \PYG{l+m+mi}{1}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{k}{return} \PYG{l+m+mi}{0}
        
    \PYG{k}{def} \PYG{n+nf}{surplus}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{price}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{if} \PYG{n}{price} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{WTP}\PYG{p}{:}
            \PYG{k}{return} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{WTP} \PYG{o}{\PYGZhy{}} \PYG{n}{price}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{k}{return} \PYG{l+m+mi}{0}
        
\PYG{n}{consumers} \PYG{o}{=} \PYG{p}{[}\PYG{n}{Consumer}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{]}

\PYG{p}{[}\PYG{n}{x}\PYG{o}{.}\PYG{n}{demand}\PYG{p}{(}\PYG{l+m+mi}{6}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{consumers}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]
\end{sphinxVerbatim}

\sphinxAtStartPar
For a market price of 6, we have 5 consumers who participate and 5 who don’t. Now let’s make a table of the lists of participants for each market price between 1 and 10.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{per\PYGZus{}consumer} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{n}{x}\PYG{o}{.}\PYG{n}{demand}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{consumers}\PYG{p}{]} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{T}
\PYG{n}{Table}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}columns}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Market Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} 
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Consumer with WTP: 10}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}consumer}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Consumer with WTP: 9}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}consumer}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Consumer with WTP: 8}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}consumer}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Consumer with WTP: 7}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}consumer}\PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Consumer with WTP: 6}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}consumer}\PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Consumer with WTP: 5}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}consumer}\PYG{p}{[}\PYG{l+m+mi}{5}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Consumer with WTP: 4}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}consumer}\PYG{p}{[}\PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Consumer with WTP: 3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}consumer}\PYG{p}{[}\PYG{l+m+mi}{7}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Consumer with WTP: 2}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}consumer}\PYG{p}{[}\PYG{l+m+mi}{8}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Consumer with WTP: 1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}consumer}\PYG{p}{[}\PYG{l+m+mi}{9}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Market Price | Consumer with WTP: 10 | Consumer with WTP: 9 | Consumer with WTP: 8 | Consumer with WTP: 7 | Consumer with WTP: 6 | Consumer with WTP: 5 | Consumer with WTP: 4 | Consumer with WTP: 3 | Consumer with WTP: 2 | Consumer with WTP: 1
10           | 1                     | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0
9            | 1                     | 1                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0
8            | 1                     | 1                    | 1                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0
7            | 1                     | 1                    | 1                    | 1                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0
6            | 1                     | 1                    | 1                    | 1                    | 1                    | 0                    | 0                    | 0                    | 0                    | 0
5            | 1                     | 1                    | 1                    | 1                    | 1                    | 1                    | 0                    | 0                    | 0                    | 0
4            | 1                     | 1                    | 1                    | 1                    | 1                    | 1                    | 1                    | 0                    | 0                    | 0
3            | 1                     | 1                    | 1                    | 1                    | 1                    | 1                    | 1                    | 1                    | 0                    | 0
2            | 1                     | 1                    | 1                    | 1                    | 1                    | 1                    | 1                    | 1                    | 1                    | 0
1            | 1                     | 1                    | 1                    | 1                    | 1                    | 1                    | 1                    | 1                    | 1                    | 1
\end{sphinxVerbatim}

\sphinxAtStartPar
You can draw a downward\sphinxhyphen{}sloping diagonal line sepearating \sphinxcode{\sphinxupquote{1}}s from \sphinxcode{\sphinxupquote{0}}s \sphinxhyphen{} a vague resemblance of a downward\sphinxhyphen{}sloping demand curve. The left\sphinxhyphen{}most consumer, with a WTP of 10, always participates for the market prices we have listed. The right\sphinxhyphen{}most consumer only participates at a market price of 1. Now lets try and find the number of consumers who participate for each price point, starting at 10.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{market} \PYG{o}{=} \PYG{n}{Table}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Market Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{market} \PYG{o}{=} \PYG{n}{market}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Number of Participants}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} 
                   \PYG{n}{market}\PYG{o}{.}\PYG{n}{apply}\PYG{p}{(}\PYG{k}{lambda} \PYG{n}{price} \PYG{p}{:} \PYG{n+nb}{sum}\PYG{p}{(}\PYG{p}{[}\PYG{n}{x}\PYG{o}{.}\PYG{n}{demand}\PYG{p}{(}\PYG{n}{price}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{consumers}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Market Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{market}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Market Price | Number of Participants
10           | 1
9            | 2
8            | 3
7            | 4
6            | 5
5            | 6
4            | 7
3            | 8
2            | 9
1            | 10
\end{sphinxVerbatim}

\sphinxAtStartPar
Instead of printing a binary 1 or 0 indicating market participation, we’ve displayed each participant’s actual surplus value. Similarly, let’s find total surplus per price point.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{surplus} \PYG{o}{=} \PYG{n}{Table}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Market Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{surplus} \PYG{o}{=} \PYG{n}{surplus}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Total Surplus}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} 
                   \PYG{n}{surplus}\PYG{o}{.}\PYG{n}{apply}\PYG{p}{(}\PYG{k}{lambda} \PYG{n}{price} \PYG{p}{:} \PYG{n+nb}{sum}\PYG{p}{(}\PYG{p}{[}\PYG{n}{x}\PYG{o}{.}\PYG{n}{surplus}\PYG{p}{(}\PYG{n}{price}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{consumers}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Market Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{surplus}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Market Price | Total Surplus
10           | 0
9            | 1
8            | 3
7            | 6
6            | 10
5            | 15
4            | 21
3            | 28
2            | 36
1            | 45
\end{sphinxVerbatim}

\sphinxAtStartPar
Clearly there must be an opposite “force” at play here, otherwise all prices would converge to 0 as consumers maximize their surplus (more on maximization later). Naturally, we must also consider the producers who sell their product to the consumers. We essentially repeat the exercise above, but now instead of a consumer class with individual willingness to pay, we have a producer class with some minimal market price at which production can occur.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{class} \PYG{n+nc}{Producer}\PYG{p}{:}
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{WTA}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{WTA} \PYG{o}{=} \PYG{n}{WTA}
        
    \PYG{k}{def} \PYG{n+nf}{supply}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{price}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{if} \PYG{n}{price} \PYG{o}{\PYGZgt{}}\PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{WTA}\PYG{p}{:}
            \PYG{k}{return} \PYG{l+m+mi}{1}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{k}{return} \PYG{l+m+mi}{0}
        
    \PYG{k}{def} \PYG{n+nf}{surplus}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{price}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{if} \PYG{n}{price} \PYG{o}{\PYGZgt{}}\PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{WTA}\PYG{p}{:}
            \PYG{k}{return} \PYG{n}{price} \PYG{o}{\PYGZhy{}} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{WTA}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{k}{return} \PYG{l+m+mi}{0}
        
\PYG{n}{producers} \PYG{o}{=} \PYG{p}{[}\PYG{n}{Producer}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{11}\PYG{p}{)}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{per\PYGZus{}producer} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{n}{x}\PYG{o}{.}\PYG{n}{surplus}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{producers}\PYG{p}{]} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{T}

\PYG{n}{Table}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}columns}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Market Price}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} 
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Producer with WTP: 10}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}producer}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Producer with WTP: 9}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}producer}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Producer with WTP: 8}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}producer}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Producer with WTP: 7}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}producer}\PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Producer with WTP: 6}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}producer}\PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Producer with WTP: 5}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}producer}\PYG{p}{[}\PYG{l+m+mi}{5}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Producer with WTP: 4}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}producer}\PYG{p}{[}\PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Producer with WTP: 3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}producer}\PYG{p}{[}\PYG{l+m+mi}{7}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Producer with WTP: 2}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}producer}\PYG{p}{[}\PYG{l+m+mi}{8}\PYG{p}{]}\PYG{p}{,}
                     \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Producer with WTP: 1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{per\PYGZus{}producer}\PYG{p}{[}\PYG{l+m+mi}{9}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Market Price | Producer with WTP: 10 | Producer with WTP: 9 | Producer with WTP: 8 | Producer with WTP: 7 | Producer with WTP: 6 | Producer with WTP: 5 | Producer with WTP: 4 | Producer with WTP: 3 | Producer with WTP: 2 | Producer with WTP: 1
10           | 9                     | 8                    | 7                    | 6                    | 5                    | 4                    | 3                    | 2                    | 1                    | 0
9            | 8                     | 7                    | 6                    | 5                    | 4                    | 3                    | 2                    | 1                    | 0                    | 0
8            | 7                     | 6                    | 5                    | 4                    | 3                    | 2                    | 1                    | 0                    | 0                    | 0
7            | 6                     | 5                    | 4                    | 3                    | 2                    | 1                    | 0                    | 0                    | 0                    | 0
6            | 5                     | 4                    | 3                    | 2                    | 1                    | 0                    | 0                    | 0                    | 0                    | 0
5            | 4                     | 3                    | 2                    | 1                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0
4            | 3                     | 2                    | 1                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0
3            | 2                     | 1                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0
2            | 1                     | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0
1            | 0                     | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0                    | 0
\end{sphinxVerbatim}

\sphinxAtStartPar
Looks familiar, but with an opposite slope! Here we’ve captured the idea of producer surplus. At a market price of 10, the leftmost producer is very happy with a surplus of 9, as in this case that producer is actually able to produce and sell at a price of 1 but is able to operate at a price of 10.

\sphinxAtStartPar
Before we continue, let’s take a moment to think about the meaning and significance of our findings. Firms that can produce at lower market prices than their peers seem to be better off in the sense that they enjoy higher surplus. This minimum production price is based on the costs of operation the firm experiences, so naturally it seems that firms that can operate at lower costs do better. Certainly, if market prices decrease, more inefficent firms would be the first to shut down while these low operating cost firms continue to do business. This idea is very important in economics: Firms that can reduce their costs are rewarded with higher surplus. This is pretty much how society advances, at least in an economics context. Production methods continually to improve, and less efficient firms must either follow suit or shut down as prices decrease, to the benefit of consumers.

\sphinxAtStartPar
However, what would the equivalent be for the consumer side of things? We’ve discussed the idea of willingness to pay, and initially it might seem that in our perfectly\sphinxhyphen{}competitive market environment, only the consumers who most need a good or service will be the first to get it, as their WTP is the highest. We might think that resources are efficiently allocated in this way. Most of the time this is likely the case, but we’ve made an assumption while reaching this conclusion; an assumption that doesn’t necessarily hold. We have assumed that a person with high willingness to pay also has at least an equally high \sphinxstyleemphasis{ability} to pay. In reality, this might not be the case. A hungry person might have high WTP for a serving of food, but if this person lacks the means to pay for this food, his willingness to pay won’t do him much good. In this scenario, our earlier exercise reflects willingness to pay with a simultaneous ability to pay as well. While this week isn’t about the ethics of certain types of markets and whether they achieve their goals, it’s important to keep in mind that in these ideal exercises, an efficient economy with rational pricing should reflect consumers’ willingness to pay, whereas in reality this might not actually be the case.


\subsubsection{Note on the Demand and Supply Curves}
\label{\detokenize{content/03-public/surplus:note-on-the-demand-and-supply-curves}}
\sphinxAtStartPar
As pointed out above, the matrix we saw with rows of surpluses and columns of prices resembles the demand curve in the sense that we can see a diagonal line separating participants from non\sphinxhyphen{}participants. This is no coincidence. This idea is essentially what the demand and supply curves depict, except that due to there usually being many participants in a market, we simplify the concept to a continuous curve as opposed to a set of discrete values. This is helpful not only for visualization, but as we will soon see we can use these curves to find rates of change, which will prove to be useful as well.

\sphinxAtStartPar
Earlier we had a matrix of each individual’s surplus at each price point, and the overall surplus at each price point. Notice how as the price decreased, surplus increased. Let’s see this exact same concept illustrated on a familiar demand curve. Take a few moments to adjust the slider controlling the market price to see how consumer surplus behaves.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Producer surplus with the supply curve works exactly the same way but mirrored to reflect the fact that producers gain surplus from higher prices instead of lower.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here we used a demand curve of \(10-P\) and a supply curve of \(P\).


\subsection{Other Forms of Government Intervention}
\label{\detokenize{content/03-public/govt-intervention:other-forms-of-government-intervention}}\label{\detokenize{content/03-public/govt-intervention::doc}}

\subsubsection{Price Controls}
\label{\detokenize{content/03-public/govt-intervention:price-controls}}
\sphinxAtStartPar
The last type of government intervention is far more forceful than taxes and subsidies. Instead of changing the per\sphinxhyphen{}unit cost of a good paid by consumers or producers, price controls directly fix the market price. It does not change the amount different consumers are willing and able to pay or how much producers are willing and able to produce.

\sphinxAtStartPar
When price controls are introduced to a market, the equilibrium price and quantity no longer exist. Consumer and producers are forced to sell or buy goods at the prescribed price.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{fig6-price-floor}.png}
\caption{A price floor}\label{\detokenize{content/03-public/govt-intervention:price-floor}}\end{figure}

\sphinxAtStartPar
Let’s take a price floor as the first example. This is when the government imposes a minimum price for which a good can be sold. For this to be effective, the price floor must be set above the equilibrium price, otherwise the market would just settle at equilibrium. This results in a surplus, as producers are willing to sell far more goods than consumers are willing to purchase. This results in a surplus as \(Q_s > Q_d\). Normally, without government intervention, the invisible hand would push prices down until \(Q_s = Q_d\). However, with the price floor, the market remains in a state of disequilibrium.

\sphinxAtStartPar
Minimum wages act as a price floor, keeping wages above a certain level. At this higher rate, more workers are willing to work than there is demand for, creating unemployment.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{fig7-price-ceil}.png}
\caption{A price ceiling}\label{\detokenize{content/03-public/govt-intervention:price-ceil}}\end{figure}

\sphinxAtStartPar
The other control is a price ceiling. This is when the government imposes a maximum price for which a good can be sold. This results in a shortage as consumers are to purchase more goods than producer are willing to sell: \(Q_d > Q_s\).

\sphinxAtStartPar
Rent control in Berkeley acts as a price ceiling, keeping rents from rising above a certain level.


\subsubsection{Optional: World Trade vs. Autarky}
\label{\detokenize{content/03-public/govt-intervention:optional-world-trade-vs-autarky}}
\sphinxAtStartPar
Throughout the class so far, we have assumed that the economy is operating by itself, in isolation. Economists use the word “autarky” to represent the scenario when a country is economically self\sphinxhyphen{}sufficient. The key consequence of this is that the country’s economy is unaffected by global events, allowing us to conclude that any changes to equilibrium price or quantity are purely a result of shifts in domestic demand or supply.

\sphinxAtStartPar
We will now assume that the country is no longer in autarky, and is thus subject to world prices, demand and supply.

\sphinxAtStartPar
We now label our demand and supply curves as domestic demand and supply, respectively. Their intersection represents where the market would be if we were in autarky. However, as we are now open to world trade, the price where the market operates is now determined by the world price, which may be totally different from the equilibrium price.

\sphinxAtStartPar
Where the world price line intersects with domestic demand represents the total quantity demanded within the market. Where it intersects with the domestic supply curve is the total quantity supplied.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{fig8-autarky}.png}
\caption{Domestic supply and demand in the world market}\label{\detokenize{content/03-public/govt-intervention:autarky}}\end{figure}

\sphinxAtStartPar
Let’s first imagine a scenario where world price is lower than domestic price. From our graph, we find that \(Q_s < Q_d\). This is a shortage. Domestic producers are not willing to fully provide all goods demanded by consumers in the economy. The difference between what is produced domestically and the total quantity demanded will be fulfilled by international producers. Thus, \(Q_d - Q_s =\) imports. As prices are lower than what some consumers were willing to pay, there is a significant consumer surplus. Unfortunately for producers, as world prices are lower than what they would have been able to charge, they lose producer surplus. There is a net gain in the change in consumer surplus is greater than the loss in producer surplus. This is represented by the triangle between the curves and above the world price line.

\sphinxAtStartPar
Now, let’s imagine that world price is greater than domestic price. In this case, \(Q_s > Q_d\). We now have a surplus where the quantity demanded by consumers is far less than what domestic producers are willing to provide at this higher price. Thus, domestic producers will willingly sell goods to domestic customers and sell the rest on the global market. \(Q_s - Q_d =\) exports. As prices are higher than what some consumers were willing to pay, there is a significant decrease in consumer surplus. Producers however rejoice as world prices are higher than what they would have been able to charge. They gain producer surplus. There is a net gain in total surplus as the increase in producer surplus is greater than the loss in consumer surplus. This is represented by the triangle between the curves and above the world price line.


\section{Production}
\label{\detokenize{content/04-production/index:production}}\label{\detokenize{content/04-production/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{Student Learning Outcomes:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Understand how Cobb\sphinxhyphen{}Douglas Production Functions model the means by which nations produce output

\item {} 
\sphinxAtStartPar
Derive and visualize how a per\sphinxhyphen{}unit change in Capital, Labor or Total Factor Productivity affect output

\item {} 
\sphinxAtStartPar
Introduce the concept of returns to scale

\item {} 
\sphinxAtStartPar
Develop a framework of comparing how countries produce output over time

\end{itemize}


\subsection{Production and Cobb\sphinxhyphen{}Douglas Functions}
\label{\detokenize{content/04-production/production:production-and-cobb-douglas-functions}}\label{\detokenize{content/04-production/production::doc}}

\subsubsection{Production in the Economy}
\label{\detokenize{content/04-production/production:production-in-the-economy}}
\sphinxAtStartPar
At the core of macroeconomics is the study of how a nation’s various resources are used as inputs in the production of goods and services. The aggregate value of what a nation produces is known as its Gross Domestic Product, which is calculated in many different ways. The focus of this lecture is on production and the functions that aim to model how much output a country can produce, when given a certain set of inputs.

\sphinxAtStartPar
These set of inputs are known as factors of production:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(K\): Capital \sphinxhyphen{} a monetary value of the stock or value of productive assets.

\item {} 
\sphinxAtStartPar
\(L\): Labor \sphinxhyphen{} the number of worker hours.

\item {} 
\sphinxAtStartPar
\(A\): Total Factor Productivity \sphinxhyphen{} a measure of the effectiveness with which the two factors of production are used.

\end{itemize}

\sphinxAtStartPar
This model of production in an economy provides a simple yet effective way of modeling output. It would be way too complicated to account for every possible input to production, especially as we are operating at the country level. However, the key simplication is that we can classify all of these different inputs as either capital or labor: anything physical or tangible is capital and any work done by humans is labor. Taking the monetary value of either of these, while a rough approximation, still yields great insight into the different ways countries produce goods and services. Even if two countries have very similar GDPs, one maybe more capital intensive than the other. Having this knowledge would greatly inform policy and would help governments direct funding towards areas of concern.

\sphinxAtStartPar
We will see this in action during Project 2 where we will examine real life data from different countries and compare/contrast their usage of labor, capital and total factor productivity.

\sphinxAtStartPar
This simplication has allowed economists to derive the following key notion:
A nation’s output is a function of the amount of the factors of production that are utilized in its economy; that is to say output is a function of labor and capital.

\sphinxAtStartPar
Thus, the economy’s production function is:
\begin{equation*}
\begin{split}Y = A \cdot f(K, L)\end{split}
\end{equation*}
\sphinxAtStartPar
\(f(K, L)\) refers to any specific mathematical model of output. One such example is the Cobb\sphinxhyphen{}Douglas production function that we will be examining in the next section.


\paragraph{Total Factor Productivity}
\label{\detokenize{content/04-production/production:total-factor-productivity}}
\sphinxAtStartPar
In modern economies, one way to think about total factor producivity (TFP) is technology or research and development. A country with a high TFP (or technology) can produce far more goods and services than another with a lower TFP but the exact same amount of capital and labor. Think about it: a country with 5 factories utilizing robotic arms to assemble cars will be able to produce more than another nation that also has 5 factories but utilizes workers working in 8\sphinxhyphen{}hour shifts. The former country would have a higher TFP than the latter. Thus, it can be said that technology increases the efficiency with which the factors of production are used.

\sphinxAtStartPar
There are three key differences between TFP and the other two factors of production:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
TFP “scales” production by some factor A. The other two are raised to an exponent that is less than 1, reducing its value relative to the input. Thus, TFP is very powerful as it creates a proportional increase in output.

\item {} 
\sphinxAtStartPar
Technology is “non\sphinxhyphen{}rivalrous”, meaning that more than one person can use it at any given time. For example, robotics technology is not limited to one person, but a specific robotic arm can only be used by a single person at a time.

\item {} 
\sphinxAtStartPar
Technology is “non\sphinxhyphen{}excludable”, meaning that one person cannot block another from using that factor. Even with the patent system, after expiry, technologies that were once protected now becomes free to use or adapt.

\end{enumerate}

\sphinxAtStartPar
Note that TFP has no intrinsic value by itself, but becomes informative when it is compared across nations. For example, a TFP of 1.4 means nothing. However, if one country has a TFP of 1.8 while the other is 1.4, then we can say that the first country is more effective at utilizing its resources to produce output.


\subsubsection{The Cobb\sphinxhyphen{}Douglas Production Function}
\label{\detokenize{content/04-production/production:the-cobb-douglas-production-function}}
\sphinxAtStartPar
The Cobb\sphinxhyphen{}Douglas Production Function is
\begin{equation*}
\begin{split}\begin{aligned}
f(K, L) &= K^\alpha L^\beta \\
 Y &= A \cdot f(K, L) \\
 &= A K^\alpha L^\beta
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\alpha\) and \(\beta\) are exponents.

\sphinxAtStartPar
A common simplification is that \(\beta = 1 - \alpha\). We will later explore the implications of this statement. For now, let us rewrite the above function:
\begin{equation*}
\begin{split}
Y = A K^\alpha L^{1 - \alpha}
\end{split}
\end{equation*}
\sphinxAtStartPar
Note that this is a function of two variables, \(K\) and \(L\). If we were to plot this function utilizing both variables, we would need a 3D plot with \(K\), \(L\) and \(Y\) each having their own axis. For now, let us gain greater insight of what this function will look like by holding one variable constant and plot the other versus output.


\paragraph{Capital}
\label{\detokenize{content/04-production/production:capital}}
\sphinxAtStartPar
For the first case, let us visualize the Cobb\sphinxhyphen{}Douglas Production Function with output as a function of capital, holding the amount of labor constant at \(\bar L\).

\noindent\sphinxincludegraphics{{production_6_0}.png}

\sphinxAtStartPar
Notice some of the properties of the function above:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
It is increasing. This is called increasing returns to capital wherein any increase in capital will lead to an increase in output, assuming that labor is held constant.

\item {} 
\sphinxAtStartPar
It is concave (increasing at a decreasing rate). This is called diminishing marginal returns to capital wherein any additional unit of capital will lead to smaller and smaller increases in capital. For a better idea of this, let us take the partial derivative of the Cobb\sphinxhyphen{}Douglas function with respect to capital.

\end{enumerate}
\begin{equation*}
\begin{split}\begin{aligned}
Y &= A K^\alpha L^{1 - \alpha} \\
\dfrac{\partial Y}{\partial K} &= \alpha A \left ( \dfrac{L}{K} \right )^{1 - \alpha} 
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
\(\dfrac{\partial Y}{\partial K}\) is called the \sphinxstylestrong{marginal product of capital (MPK)}. Let us plot this function, once again holding labor constant at \(\bar L\).

\noindent\sphinxincludegraphics{{production_8_0}.png}

\sphinxAtStartPar
Note that \(\text{MPK} \cdot P = R\) is the rental rate of capital less the cost of purchasing or renting an additional unit of capital.

\sphinxAtStartPar
The MPK is monotonically decreasing, converging towards an asymptote at \(\text{MPK} = 0\). This means that the rate of increase of output due to an increase in capital will become 0, meaning that the amount of output added per unit of additional capital will become constant. What would be the intuition behind this?

\sphinxAtStartPar
Say a company making pizzas has 1 oven and 10 employees. There is a hard limit on how many pizzas can be baked in a given period of time. However, if the company purchases a second oven, suddenly the employees can bake more pizzas at the same time, thereby increasing the number that can be baked in the same amount of time. In this case, the MPK would be very high as output has greatly increased just by addding slightly to the company’s capital stock.

\sphinxAtStartPar
Let us move to the case when the company has 100 ovens and 10 employees. Adding another oven would do little to increase output as the 10 employees can only do so much \sphinxhyphen{} the extra capacity would not be helpful. In this case, the MPK would be very low as output has not increased by much (if at all) even when the company’s capital stock increased.


\paragraph{Labor}
\label{\detokenize{content/04-production/production:labor}}
\sphinxAtStartPar
We will now move to using the Cobb\sphinxhyphen{}Douglas function for output as a function of labor, holding the amount of capital constant at \(\bar K\).

\noindent\sphinxincludegraphics{{production_11_0}.png}

\sphinxAtStartPar
The properties of the Labor function are similar to that of the capital function. Let us take the partial derivative of the Cobb\sphinxhyphen{}Douglas function with respect to labor.
\begin{equation*}
\begin{split}\begin{aligned}
Y &= A K^\alpha L^{1 - \alpha} \\
\dfrac{\partial Y}{\partial L} &= A (1 - \alpha) \left ( \dfrac{K}{L} \right )^{\alpha}
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
\(\dfrac{\partial Y}{\partial L}\) is called the \sphinxstylestrong{marginal product of labor (MPL)}. Let us plot this function, once again holding capital constant at \(\bar K\).

\noindent\sphinxincludegraphics{{production_13_0}.png}

\sphinxAtStartPar
Note that \(\text{MPL} \cdot P = W\), the real wage rate less the cost of hiring an additional unit of labor.

\sphinxAtStartPar
Similar to the MPK, the MPL is monotonically decreasing, converging towards an asymptote at \(\text{MPL} = 0\). This means that the rate of increase of output due to an increase in labor will become 0.

\sphinxAtStartPar
Say the same company making pizzas has 5 ovens and 5 employees. One oven per employee seems like overkill but provides significant extra capacity in terms of capital that would give great flexibility for the company when producing pizzas. However, if the company hires 1 more worker, each oven can be utilized more effectively, as another employee can go to prepping pizzas before baking. This greatly increasies the number of pizzas baked in a given unit of time. The MPL would be very high as output increases significantly with the addition of one more worker. On the above graph, we would be on the steep part of the function.

\sphinxAtStartPar
If the company has 5 ovens but 20 employees, hiring an additional worker would do little to increase output. The kitchen would probably be too crowded and there are only so many servers needed. The MPL would be very low as output has not increased by much even when the company’s amount of labor has increased. We would be near the flat part of the graph, as the MPL approaches 0.


\paragraph{Implication for Cross\sphinxhyphen{}Country Comparisons}
\label{\detokenize{content/04-production/production:implication-for-cross-country-comparisons}}
\sphinxAtStartPar
Work by Professors C.W. Cobb and P.H. Douglas found that production or output was a weighted average of the log of capital and labor. The equation for Cobb\sphinxhyphen{}Douglas production functions were the result of their research, especially when a log transformation was applied to the equation:
\begin{equation*}
\begin{split}\begin{aligned}
Y &= A K^\alpha L^{1 - \alpha} \\
\ln Y &= \ln A + \alpha \ln K + (1 - \alpha) \ln L
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Note that this is exactly the weighted average that Cobb \& Douglas found in their empirical findings: capital and labor are weighted by \(\alpha\) and \(1 - \alpha\) respectively. However, this is still showing production as a function of two variables, \(K\) and \(L\). Rearranging the equation yields something interesting:
\begin{equation*}
\begin{split}\begin{aligned}
\ln Y &= \ln A + \alpha \ln K + \ln L - \alpha \ln L \\
\ln Y- \ln L &= \ln A + \alpha \left ( \ln K - \ln L \right ) \\
\ln \frac{Y}{L} &= \ln A + \alpha \ln \frac{K}{L}
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
The Cobb\sphinxhyphen{}Douglas function is now an equation in 1 variable: \(\ln \frac{K}{L}\). This provides a pathway for comparing values of \(A\) and \(\alpha\) across countries, and by extension how capital and labor are deployed in different ways between nations. We will explore this idea further in the next section.


\subsection{Analyzing Shifts in \protect\(A\protect\) and \protect\(\alpha\protect\)}
\label{\detokenize{content/04-production/shifts:analyzing-shifts-in-a-and-alpha}}\label{\detokenize{content/04-production/shifts::doc}}

\subsubsection{Shifts in \protect\(A\protect\) and their Effect on Output}
\label{\detokenize{content/04-production/shifts:shifts-in-a-and-their-effect-on-output}}
\sphinxAtStartPar
First, let us plot a 3D surface of the Cobb\sphinxhyphen{}Douglas production function. Output, \(Y\), will go on the vertical (or \(z\)) axis. Capital and labor will go on the \(y\) and \(x\) axes, resp. The plot below plots the Cobb\sphinxhyphen{}Douglas function with \(A=2\), also showing \(A=1\) for reference.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Supply or total factor productivity shocks could cause \(A\) to change. These occur if there is a change in total output for a given level of capital and labor. Examples of these include financial crises, technology shocks, natural environment/distasters and energy prices.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Favorable shocks rotate the production function upward through an increase in A. Thus, each unit of input from capital and labor now simulataneously produce more output. What does this mean for the rental rate of capital and the real wage? Recall the functions for both of them:
\begin{equation*}
\begin{split}\begin{aligned}
\text{MPL} &= A (1 - \alpha) \left ( \frac{K}{L} \right )^{\alpha} \\
\text{MPK} &= \alpha A \left ( \frac{L}{K} \right )^{1 - \alpha} 
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Both MPK and MPL will increase by a factor of \(A\). Thus, it would be more expensive to hire an additional unit of labor or rent an additional unit of capital. As they are both more productive than previously, they are both more valuable to a business and thus will cost more. Negative shocks do the opposite. They rotate the production function downward through a decrease in \(A\). Each unit of input is now less productive, meaning that both the rental rate of capital and the real wage are lower.


\subsubsection{Shifts in \protect\(\alpha\protect\) and their Effect on Output}
\label{\detokenize{content/04-production/shifts:shifts-in-alpha-and-their-effect-on-output}}
\sphinxAtStartPar
We will now plot what happens to the Cobb\sphinxhyphen{}Douglas function as we vary \(\alpha\), while holding all other variables constant. The plot below shows \(\alpha = 0.8\) (the purple\sphinxhyphen{}yellow surface) with \(\alpha=0.5\) for reference (the blue\sphinxhyphen{}yellow surface). Try and hypothesize what this will do to our production function.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
The next plot has \(\alpha = 0.2\) (the purple\sphinxhyphen{}yellow surface) with \(\alpha=0.5\) for reference (the blue\sphinxhyphen{}yellow surface). What is the difference between the plot above and the one below?

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Below is an interactive plot with a slider to change \(\alpha\). Try out different values and see how the shape of the production function changes.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
\(\alpha\) and \(\beta\) are called the output elasticities of capital and labor, respectively. They measure the responsiveness of output to a change in the levels of either labor or capital, holding all else constant. This means that if \(\alpha\) or \(\beta\) were high, then any small increase in their respective input would lead to a relatively large increase in output. As an example, if \(\alpha\) was 0.4, then a 1\% increase in capital would lead to a 0.4\% increase in output.

\sphinxAtStartPar
Note, we assume that there are constant returns to scale. Thus, an increase in \(\alpha\) necessarily means \(\beta\) decreases. This reveals something important when comparing countries: the higher the \(\alpha\), the more capital\sphinxhyphen{}intensive the country’s production is. This means that \(\alpha\) and \(\beta\) give economists and policymakers insight as to how resources are allocated across nations.


\subsubsection{Returns to Scale}
\label{\detokenize{content/04-production/shifts:returns-to-scale}}
\sphinxAtStartPar
The significance of the exponents adding up to 1 (\(\alpha + \beta = 1\)) is that this implies constant returns to scale. If all inputs are scaled by a common non\sphinxhyphen{}zero factor, the output will be scaled by that same factor. Below is a generalization of this:
\begin{equation*}
\begin{split}\begin{aligned}
Y &= A (c \cdot K)^\alpha (c \cdot L)^{1 - \alpha} \\
&= A c^\alpha K ^ \alpha c^{1 - \alpha}L^{1 - \alpha} \\
&= A c^{\alpha + 1 - \alpha}K^\alpha L^{1 - \alpha} \\
&= c \cdot A K^\alpha L^{1 - \alpha}
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Thus, any increase in either of the inputs will lead to a 1\sphinxhyphen{}1 increase in output. This is a significant assumption to make, as it essentially incentivizes companies to continue to “scale” their production inputs. They are not losing out on how much return is produced \sphinxhyphen{} they are getting output that matches exactly what they put into production.

\sphinxAtStartPar
The alternative case is when \(\alpha + \beta < 1\). This is called decreasing returns to scale, and occurs when a company scales their production inputs by a factor of c, but gets a scaling in output that is less than c.

\sphinxAtStartPar
The last case is the most profitable one, when \(\alpha + \beta > 1\). This is called increasing returns to scale, and occurs when a company increases their production inputs by c, but gets an increase in output that is greater than c.

\sphinxAtStartPar
Let us visually examine how values of \(\alpha\) and \(\beta\) affect output.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
The above graph shows increasing returns to scale with \(\alpha + \beta = 2\) (the purble\sphinxhyphen{}yellow surface) with constant returns to scale for comparison (the blue\sphinxhyphen{}yellow surface). Notice how the orange function no longer increases at a decreasing rate, but seems to mimic exponential growth. This is once again because of the definition of increasing returns to scale. As companies continue to increase their inputs by a factor of \(c\), they see their output increase by more than that factor. Thus, as inputs \((K, L)\) increase, output will increase at an even faster rate than that \sphinxhyphen{} in this case by the square.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
The above graph exhibits decreasing returns to scale as \(\alpha + \beta = 0.5\) (the purple\sphinxhyphen{}yellow surface) with constant returns to scale for comparison (the blue\sphinxhyphen{}yellow surface). This time, the orange production function flattens out far faster than the regular constant returns to scale function. You can prove this to yourself using the slider below, which adjusts the value of \(\alpha + \beta\).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}


\section{Utility}
\label{\detokenize{content/05-utility/index:utility}}\label{\detokenize{content/05-utility/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{Student Learning Outcomes:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Understand the basic principles of utility

\item {} 
\sphinxAtStartPar
Become familiar with utility function such as the Cobb\sphinxhyphen{}Douglas utility function

\item {} 
\sphinxAtStartPar
Translate utility functions with 2 inputs to indifference curves

\item {} 
\sphinxAtStartPar
Understand budget constraints and how they affect utility maximization

\end{itemize}


\subsection{Utility Functions and Indifference Curves}
\label{\detokenize{content/05-utility/utility:utility-functions-and-indifference-curves}}\label{\detokenize{content/05-utility/utility::doc}}

\subsubsection{What is Utility?}
\label{\detokenize{content/05-utility/utility:what-is-utility}}
\sphinxAtStartPar
When we consume a good, we assume that the good will have some impact on our total utility. Utility is a fundamental measure that helps economists model how consumers make decisions. An assumed rule in economics is that consumers will always act rationally, which translates to the assumption that consumers will always attempt to maximize their own utility.

\sphinxAtStartPar
It is important to note that utility doesn’t have specified units and even the face value of utility doesn’t have any meaning. \sphinxstyleemphasis{What does an apple providing 5 utility units even mean?} What is valuable, however, is that utility can be compared; if an apple provides 5 utility units and an orange provides 3 utility units, then we prefer apples to oranges.

\sphinxAtStartPar
As a very simple example, say Anne has 6 dollars and she can choose to buy any combination of goods A and B. If good A costs 2 dollars and provides 5 utility units per unit of A consumed, while good B costs 3 dollars and provides 6 utility units per unit of B consumed, then Anne will buy 3 units of good A, since that maximizes her utility.

\sphinxAtStartPar
In economics, however, our models are a little more complex than that. Typically, utility is the product of the consumption of many goods; typically having a lot of one good but not another does not provide much utility. In addition, consumption of one good faces diminishing marginal returns, i.e. holding all things equal, the consumption of one additional unit of a good will provide less utility than the utility received from the previous unit. Intuitively, imagine Bob is very hungry and decides to eat slices of pizza. The first slice of pizza will bring Bob the most utility, but the 8th slice will be much less satisfying to eat.


\subsubsection{Utility Functions}
\label{\detokenize{content/05-utility/utility:utility-functions}}
\sphinxAtStartPar
A consumer’s utility is determined by the amount of consumption from all the goods they consume. Typically, utility functions are multivariate: they take in multiple inputs (which represent the different amounts of consumption for each good, which we call a consumption bundle), and output one value, the utility. Today, we’ll only look at the case where consumers can only choose between 2 goods \(x_1\) and \(x_2\). Hence, a utility function can be represented by: \(u(x_1,x_2)\).

\sphinxAtStartPar
With that in mind, let’s start graphing some utility functions!


\paragraph{Cobb\sphinxhyphen{}Douglas Utility Function}
\label{\detokenize{content/05-utility/utility:cobb-douglas-utility-function}}
\sphinxAtStartPar
Consider the following utility function across \(x_1\) and \(x_2\):
\begin{equation*}
\begin{split}u(x_1, x_2)=x_1^{\alpha}x_2^{1-\alpha}\quad\text{where } 0<\alpha<1\end{split}
\end{equation*}
\sphinxAtStartPar
This is known as the \sphinxstylestrong{Cobb\sphinxhyphen{}Douglas utility function}. To visualize this function, we’ll need a 3D plot.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}


\subsubsection{Examining the Utility Function}
\label{\detokenize{content/05-utility/utility:examining-the-utility-function}}
\sphinxAtStartPar
There are 2 rules that utility functions generally follow:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Non\sphinxhyphen{}negative marginal utility: the consumption of a good will not decrease the utility. Economists generally assume that ‘more is better.’ If the consumption of a good decreased utility, then we would consume less of a good.

\item {} 
\sphinxAtStartPar
Diminishing marginal returns: all else equal, as consumption increases the marginal utility derived from each additional unit declines.

\end{itemize}


\paragraph{Non\sphinxhyphen{}negative Marginal Utility}
\label{\detokenize{content/05-utility/utility:non-negative-marginal-utility}}
\sphinxAtStartPar
Say we are currently consuming 2 units of \(x_1\) and \(x_2\) each with \(\alpha = \frac{1}{2}\), providing \(u(2,2)=2^{0.5}2^{0.5}=2\) utility units. One additional unit of \(x_1\) will provide me a higher point of utility: we can verify this result both graphically and numerically: \(u(3,2)=3^{0.5}2^{0.5}\approx2.45\). Indeed, consuming one more unit of a good should increase our utility!


\paragraph{Marginal Utility and the Law of Diminishing Returns}
\label{\detokenize{content/05-utility/utility:marginal-utility-and-the-law-of-diminishing-returns}}
\sphinxAtStartPar
Now let’s check for the second result: diminishing marginal returns. From above, we know that holding the consumption of \(x_2\) constant at 2, going from 2 to 3 units of \(x_1\) increases our utility by \(2.45-2=0.45\). Going from 3 to 4 units of \(x_1\) brings our utility to \(u(4,2)=4^{0.5}2^{0.5}\approx 2.83\), an increase of \(2.83-2.45=0.38\) utility units.

\sphinxAtStartPar
Using calculus, we can more formally define the marginal utility of a good. Since marginal utility is the change in utility that one additional unit of consumption provides (holding all others constant), the marginal utility with respect to \(x_1\) is its partial derivative: \(\frac{\partial u}{\partial x_1}\). In our case:
\begin{equation*}
\begin{split}
\begin{aligned}
\textrm{Marginal Utility of } x_1: &\quad\frac{\partial u}{\partial x_1} = \frac{1}{2}x_1^{-0.5}x_2^{0.5} \\
\textrm{Marginal Utility of } x_2: &\quad\frac{\partial u}{\partial x_2} = \frac{1}{2}x_1^{0.5}x_2^{-0.5}
\end{aligned}
\end{split}
\end{equation*}
\sphinxAtStartPar
Or, more generally,
\begin{equation*}
\begin{split}\begin{aligned}
\textrm{Marginal Utility of } x_1: &\quad\frac{\partial u}{\partial x_1} = \alpha x_1^{\alpha-1}x_2^{1-\alpha} \\
\textrm{Marginal Utility of } x_2: &\quad\frac{\partial u}{\partial x_2} = (1-\alpha) x_1^{\alpha}x_2^{-\alpha}
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
With marginal utility defined, note that both conditions can be explained using the marginal utility function \(\frac{\partial u}{\partial x}\):
\begin{itemize}
\item {} 
\sphinxAtStartPar
Non\sphinxhyphen{}negative marginal utility: \(\frac{\partial u}{\partial x} \geq 0\)

\item {} 
\sphinxAtStartPar
Diminishing marginal returns: \(\frac{\partial^2 u}{\partial x^2} < 0\)

\end{itemize}


\subsubsection{Indifference Curves}
\label{\detokenize{content/05-utility/utility:indifference-curves}}
\sphinxAtStartPar
Although the utility function above in 3D is cool, you’ll typically find utility graphs to be in 2D with \(x_1\) and \(x_2\) as the axis (eliminating the utility axis).

\sphinxAtStartPar
To represent utility levels, we plot a set of indifference curves on the 2D graph. An indifference curve satisfies the property in which \sphinxstylestrong{any point on the curve has the exact same amount of utility}, so that consumers are \sphinxstyleemphasis{indifferent} to any point on the curve. In our 3D plot, any point on the indifference curve has the exact same height, which represents the value of utility. If you’re familar with contour plots, you can also think of indifference curves as following the same idea.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}


\subsection{Budget Constraints and Utility Maximization}
\label{\detokenize{content/05-utility/budget-constraints:budget-constraints-and-utility-maximization}}\label{\detokenize{content/05-utility/budget-constraints::doc}}
\sphinxAtStartPar
In this section, we will assume that \(\alpha = 0.5\) (i.e. the utility function is: \(u(x_1, x_2) = x_1^{0.5}x_2^{0.5}\)).

\sphinxAtStartPar
Now we introduce the concept of money into our model. Consumers face a budget constraint when choosing to maximize their utility. Given an income \(M\) and prices \(p_1\) for good \(x_1\) and \(p_2\) for good \(x_2\), the consumer can at most spend up to \(M\) for both goods:
\begin{equation*}
\begin{split}M \geq p_1x_1 + p_2x_2\end{split}
\end{equation*}
\sphinxAtStartPar
Since goods will always bring non\sphinxhyphen{}negative marginal utility, consumers will try to consume as many goods as they can. Hence, we can rewrite the budget constraint as an equality instead (since if they have more income leftover, they will use it to buy more goods).
\begin{equation*}
\begin{split}M = p_1x_1 + p_2x_2\end{split}
\end{equation*}
\sphinxAtStartPar
This means that any bundle of goods \((x_1,x_2)\) that consumers choose to consume will adhere to the equality above. What does this mean on our graph? Let’s examine the indifference curve plots, assuming that \(M = 32\), and \(p_1 =2\) and \(p_2 = 4\).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
The budget constraint is like a possibilities curve: moving up or down the constraint means gaining more of one good while sacrificing the other.

\sphinxAtStartPar
Let’s take a look at what this budget constraint means. Because of the budget constraint, any bundle of goods \((x_1,x_2)\) that consumers ultimately decide to consume will lie on the budget constraint line. Adhering to this constraint where \(M=32, p_1 = 2, p_2 = 4\), we can see that consumers will be able to achieve 2 units of utility, and can also achieve 4 units of utility. But what is the maximum amount of utility that consumers can achieve?

\sphinxAtStartPar
Notice an interesting property about indifference curves: \sphinxstylestrong{the utility level of the indifference curves gets larger as we move up and to the right.} Hence, the maximizing amount of utility in this budget constraint is the rightmost indifference curve that still touches the budget constraint line. In fact, it’ll only ‘touch’ (and not intersect) the budget constraint and be tangential to it.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that as the price of one good increases, the indifference curve that represents the maximum attainable utility shifts towards the left (i.e. the max utility decreases). Intuitively, this makes sense. As the price of one good increases, consumers have to make adjustments to their consumption bundles and buy less of one, or both, goods. Hence, their maximum utility will decrease.

\sphinxAtStartPar
Let’s visualize the budget constraint in 3D where \(M=30, p_1=3, p_2=3\). Here, any point along the curve in which the 2 planes intersect represents an amount of utility in which the budget constraint holds true (i.e. where we’ve spent all our income). The utility maximizing quantity is a point on this intersecting curve at which the utility level is the highest.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}


\section{Inequality}
\label{\detokenize{content/06-inequality/index:inequality}}\label{\detokenize{content/06-inequality/index::doc}}
\sphinxAtStartPar
Income inequality is a relevant issue that often comes up in the news. In this chapter, we’ll go over measurements of inequality, trends in income inequality in the US, and compare income inequality measures across countries.

\sphinxAtStartPar
\sphinxstylestrong{Student Learning Outcomes:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Understand the Lorenz curve to depict income distributions within a country

\item {} 
\sphinxAtStartPar
Calculate the Gini coefficient as a measure of inequality

\end{itemize}


\subsection{Measurements of Inequality}
\label{\detokenize{content/06-inequality/inequality:measurements-of-inequality}}\label{\detokenize{content/06-inequality/inequality::doc}}

\subsubsection{The Lorenz Curve}
\label{\detokenize{content/06-inequality/inequality:the-lorenz-curve}}
\sphinxAtStartPar
The Lorenz Curve visually presents income inequality by plotting household income percentile on the \(x\)\sphinxhyphen{}axis, and the cumulative income share that the bottom \(x\) percentile own on the \(y\)\sphinxhyphen{}axis. The households are sorted by income, so that the first household at the 0th percentile has the least amount of income, while the household at the 100th percentile has the greatest income.

\sphinxAtStartPar
For any point \((x,y)\) on the Lorenz curve, “the bottom x percent own y\% of the income”. For example, if the \(x\)\sphinxhyphen{}axis reads 0.30 and \(y\)\sphinxhyphen{}axis reads 0.10, then it means that the bottom 30\% of the population received 10\% of the total population’s income. This yields 2 implications for the Lorenz Curve:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The points \((0,0)\) and \((1,1)\) are always on the curve. \((0,0)\) represents the 0\% of the population owning 0\% of the income and \((1,1)\) represents 100\% of the population owning 100\% of the income.

\item {} 
\sphinxAtStartPar
The slope is always increasing. This is because households are sorted by income as percentiles: for a slight increase in \(x\), households become richer and hence provide a larger share of total income.

\end{itemize}


\paragraph{Line of Perfect Equality}
\label{\detokenize{content/06-inequality/inequality:line-of-perfect-equality}}
\sphinxAtStartPar
In a world of perfect equality, everyone would have the exact same income. In this case, the Lorenz curve would just be a 45\sphinxhyphen{}degree straight line that runs through \((0,0)\) and \((1,1)\), i.e. \(y=x\). Mathematically, this is because the derivative is constant: for a slight increase in \(x\), the total share of income increases at a constant rate. Another way to think about this is that the bottom 10\% of the population will own 10\% of the total income, the bottom 50\% of the population will own 50\% of the total income, and so on. This line is known as the \sphinxstyleemphasis{line of perfect equality}, and we typically display this line when plotting our Lorenz curves as a reference.


\paragraph{A Toy Example}
\label{\detokenize{content/06-inequality/inequality:a-toy-example}}
\sphinxAtStartPar
Let’s suppose country 1 has the following income distribution:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The bottom 10\% owns a cumulative 2\% of total income

\item {} 
\sphinxAtStartPar
The bottom 20\% owns 5\% of total income

\item {} 
\sphinxAtStartPar
The bottom 30\% owns 9\% of total income

\item {} 
\sphinxAtStartPar
The bottom 40\% owns 15\% of total income

\item {} 
\sphinxAtStartPar
The bottom 50\% owns 23\% of total income

\item {} 
\sphinxAtStartPar
The bottom 60\% owns 33\% of total income

\item {} 
\sphinxAtStartPar
The bottom 70\% with 45\% of total income

\item {} 
\sphinxAtStartPar
The bottom 80\% with 59\% of total income

\item {} 
\sphinxAtStartPar
The bottom 90\% with 75\% of total income

\item {} 
\sphinxAtStartPar
The bottom 100\% with 100\% of total income

\end{itemize}

\sphinxAtStartPar
We will create an array of income shares and call it \sphinxcode{\sphinxupquote{Country1}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Country1} \PYG{o}{=} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.02}\PYG{p}{,} \PYG{l+m+mf}{0.05}\PYG{p}{,} \PYG{l+m+mf}{0.09}\PYG{p}{,} \PYG{l+m+mf}{0.15}\PYG{p}{,} \PYG{l+m+mf}{0.23}\PYG{p}{,} \PYG{l+m+mf}{0.33}\PYG{p}{,} \PYG{l+m+mf}{0.45}\PYG{p}{,} \PYG{l+m+mf}{0.59}\PYG{p}{,} \PYG{l+m+mf}{0.75}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
To better see this information, we will create a table containing population percentage and cumulative income share.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{income\PYGZus{}distribution} \PYG{o}{=} \PYG{n}{Table}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}columns}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Population Percentage (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{p}{)} \PYG{o}{*} \PYG{l+m+mi}{10}\PYG{p}{,} 
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{Country1} \PYG{o}{*} \PYG{l+m+mi}{100}\PYG{p}{,} 
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Perfect Equality Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{p}{)} \PYG{o}{*} \PYG{l+m+mi}{10}
\PYG{p}{)}
\PYG{n}{income\PYGZus{}distribution}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Population Percentage (\PYGZpc{}) | Cumulative Income Share (\PYGZpc{}) | Perfect Equality Income Share (\PYGZpc{})
0                         | 0                           | 0
10                        | 2                           | 10
20                        | 5                           | 20
30                        | 9                           | 30
40                        | 15                          | 40
50                        | 23                          | 50
60                        | 33                          | 60
70                        | 45                          | 70
80                        | 59                          | 80
90                        | 75                          | 90
... (1 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
How will the Lorenz Curve for this income distribution look?

\noindent\sphinxincludegraphics{{inequality_9_0}.png}


\paragraph{Comparing Lorenz Curves}
\label{\detokenize{content/06-inequality/inequality:comparing-lorenz-curves}}
\sphinxAtStartPar
Now let’s compare 2 countries’ Lorenz curves. Suppose country 2 has the following income distribution:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The bottom 10\% owns a cumulative 3\% of total income

\item {} 
\sphinxAtStartPar
The bottom 20\% owns 7\% of total income

\item {} 
\sphinxAtStartPar
The bottom 30\% owns 13\% of total income

\item {} 
\sphinxAtStartPar
The bottom 40\% owns 19\% of total income

\item {} 
\sphinxAtStartPar
The bottom 50\% owns 27\% of total income

\item {} 
\sphinxAtStartPar
The bottom 60\% owns 37\% of total income

\item {} 
\sphinxAtStartPar
The bottom 70\% with 50\% of total income

\item {} 
\sphinxAtStartPar
The bottom 80\% with 65\% of total income

\item {} 
\sphinxAtStartPar
The bottom 90\% with 81\% of total income

\item {} 
\sphinxAtStartPar
The bottom 100\% with 100\% of total income

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Country2} \PYG{o}{=} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.03}\PYG{p}{,} \PYG{l+m+mf}{0.07}\PYG{p}{,} \PYG{l+m+mf}{0.13}\PYG{p}{,} \PYG{l+m+mf}{0.19}\PYG{p}{,} \PYG{l+m+mf}{0.27}\PYG{p}{,} \PYG{l+m+mf}{0.37}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mf}{0.65}\PYG{p}{,} \PYG{l+m+mf}{0.81}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{)}
\PYG{n}{income\PYGZus{}distribution2} \PYG{o}{=} \PYG{n}{Table}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}columns}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Population Percentage (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{p}{)} \PYG{o}{*} \PYG{l+m+mi}{10}\PYG{p}{,} 
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{Country2} \PYG{o}{*} \PYG{l+m+mi}{100}\PYG{p}{,} 
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Perfect Equality Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{p}{)} \PYG{o}{*} \PYG{l+m+mi}{10}
\PYG{p}{)}
\PYG{n}{income\PYGZus{}distribution2}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Population Percentage (\PYGZpc{}) | Cumulative Income Share (\PYGZpc{}) | Perfect Equality Income Share (\PYGZpc{})
0                         | 0                           | 0
10                        | 3                           | 10
20                        | 7                           | 20
30                        | 13                          | 30
40                        | 19                          | 40
50                        | 27                          | 50
60                        | 37                          | 60
70                        | 50                          | 70
80                        | 65                          | 80
90                        | 81                          | 90
... (1 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
Comparing the 2 countries’ income distributions side by side:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{income\PYGZus{}distribution}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}
    \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Population Percentage (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Perfect Equality Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} 
    \PYG{n}{income\PYGZus{}distribution2}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Population Percentage (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Perfect Equality Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabel}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Country 1 Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabel}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)\PYGZus{}2}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Country 2 Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Population Percentage (\PYGZpc{}) | Perfect Equality Income Share (\PYGZpc{}) | Country 1 Cumulative Income Share (\PYGZpc{}) | Country 2 Cumulative Income Share (\PYGZpc{})
0                         | 0                                 | 0                                     | 0
10                        | 10                                | 2                                     | 3
20                        | 20                                | 5                                     | 7
30                        | 30                                | 9                                     | 13
40                        | 40                                | 15                                    | 19
50                        | 50                                | 23                                    | 27
60                        | 60                                | 33                                    | 37
70                        | 70                                | 45                                    | 50
80                        | 80                                | 59                                    | 65
90                        | 90                                | 75                                    | 81
... (1 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
Plotting both countries’ Lorenz curves, can you tell which country has a higher level of income inequality?

\noindent\sphinxincludegraphics{{inequality_15_0}.png}

\sphinxAtStartPar
In this case, we can see that country 2’s Lorenz curve is closer to the line of equality than that of country 1, which intuitively would suggest that country 2 is more equal. If we were to look at the numbers, we see that the bottom percentiles own a higher \% of total national income in country 2 than in country 1, while top percentiles own less in country 2 than in country 1. This would suggest that country 2 is more equal in income than country 1, so that country 1 has a higher level of income inequality.

\sphinxAtStartPar
But now let’s consider a different case; suppose country 3 has the following distribution:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Country3} \PYG{o}{=} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.03}\PYG{p}{,} \PYG{l+m+mf}{0.07}\PYG{p}{,} \PYG{l+m+mf}{0.12}\PYG{p}{,} \PYG{l+m+mf}{0.18}\PYG{p}{,} \PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{l+m+mf}{0.33}\PYG{p}{,} \PYG{l+m+mf}{0.42}\PYG{p}{,} \PYG{l+m+mf}{0.54}\PYG{p}{,} \PYG{l+m+mf}{0.73}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{)}
\PYG{n}{income\PYGZus{}distribution3} \PYG{o}{=} \PYG{n}{Table}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}columns}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Population Percentage (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{p}{)} \PYG{o}{*} \PYG{l+m+mi}{10}\PYG{p}{,} 
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{Country3} \PYG{o}{*} \PYG{l+m+mi}{100}\PYG{p}{,} 
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Perfect Equality Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{p}{)} \PYG{o}{*} \PYG{l+m+mi}{10}
\PYG{p}{)}
\PYG{n}{income\PYGZus{}distribution}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}
    \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Population Percentage (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Perfect Equality Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} 
    \PYG{n}{income\PYGZus{}distribution3}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Population Percentage (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Perfect Equality Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabel}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Country 1 Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabel}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)\PYGZus{}2}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Country 3 Cumulative Income Share (}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Population Percentage (\PYGZpc{}) | Perfect Equality Income Share (\PYGZpc{}) | Country 1 Cumulative Income Share (\PYGZpc{}) | Country 3 Cumulative Income Share (\PYGZpc{})
0                         | 0                                 | 0                                     | 0
10                        | 10                                | 2                                     | 3
20                        | 20                                | 5                                     | 7
30                        | 30                                | 9                                     | 12
40                        | 40                                | 15                                    | 18
50                        | 50                                | 23                                    | 25
60                        | 60                                | 33                                    | 33
70                        | 70                                | 45                                    | 42
80                        | 80                                | 59                                    | 54
90                        | 90                                | 75                                    | 73
... (1 rows omitted)
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{inequality_19_0}.png}

\sphinxAtStartPar
Now, ambiguity arises; while bottom income percentiles earn a larger share of national income in country 3, top income percentiles also have a larger share. We can visualize this phenomenon by the ‘crossing’ of Lorenz curves on the plot. As a result, we do cannot easily tell which country has a higher level of income inequality.

\sphinxAtStartPar
As you may see, the Lorenz curve is not able to produce a ‘quantitative’ measure of income inequality, making the scenario above hard for us to compare the 2 countries. For this, we turn to the Gini coefficient.


\subsubsection{The Gini Coefficient}
\label{\detokenize{content/06-inequality/inequality:the-gini-coefficient}}
\sphinxAtStartPar
We can use the Gini coefficeint to quantify the level of income inequality.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{Gini}.png}
\caption{The Gini coefficient}\label{\detokenize{content/06-inequality/inequality:gini-coefficient}}\end{figure}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstylestrong{Gini coefficient} is the ratio of the area between the line of equality and the Lorenz curve to the total area under the line of equality. Referring to \(A\) and \(B\) from \hyperref[\detokenize{content/06-inequality/inequality:gini-coefficient}]{Fig.\@ \ref{\detokenize{content/06-inequality/inequality:gini-coefficient}}}:
\begin{equation*}
\begin{split}\text{Gini} = \frac{\text{Area between line of equality and Lorenz curve}}{\text{Area under line of equality}} = \frac{A}{A+B}\end{split}
\end{equation*}
\sphinxAtStartPar
If we express the Lorenz curve as \(L(x)\), we can use calculus to derive an equation for the Gini coefficient:
\begin{equation*}
\begin{split}\text{Gini} = \frac{\frac{1}{2} - \int_0^1 L(x)\text{d}x}{\frac{1}{2}} = 1 - 2\int_0^1 L(x)\text{d}x\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Intuitively, the closer the Lorenz curve is to the line of equality, the lower income inequality exists. Hence, the smaller the area of A, the lower the inequality. \sphinxstylestrong{This means that the smaller the Gini coefficient, the lower the income inequality.} Also note that the Gini coefficient will always be between 0 and 1. Mathematically, since \(A\) and \(B\) are both positive, \(0<\frac{A}{A+B}<1\).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} This function estimates the Gini coefficient. You don\PYGZsq{}t have to understand how this code works below.}
\PYG{k}{def} \PYG{n+nf}{gini}\PYG{p}{(}\PYG{n}{distribution}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{sorted\PYGZus{}distribution} \PYG{o}{=} \PYG{n+nb}{sorted}\PYG{p}{(}\PYG{n}{distribution}\PYG{p}{)}
    \PYG{n}{height} \PYG{o}{=} \PYG{l+m+mi}{0}
    \PYG{n}{area} \PYG{o}{=} \PYG{l+m+mi}{0}
    \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n}{sorted\PYGZus{}distribution}\PYG{p}{:}
        \PYG{n}{height} \PYG{o}{+}\PYG{o}{=} \PYG{n}{i}
        \PYG{n}{area} \PYG{o}{+}\PYG{o}{=} \PYG{n}{height} \PYG{o}{\PYGZhy{}} \PYG{n}{i} \PYG{o}{/} \PYG{l+m+mi}{2}
    \PYG{n}{fair\PYGZus{}area} \PYG{o}{=} \PYG{n}{height} \PYG{o}{*} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{distribution}\PYG{p}{)} \PYG{o}{/} \PYG{l+m+mf}{2.}
    \PYG{k}{return} \PYG{p}{(}\PYG{n}{fair\PYGZus{}area} \PYG{o}{\PYGZhy{}} \PYG{n}{area}\PYG{p}{)} \PYG{o}{/} \PYG{n}{fair\PYGZus{}area}
\end{sphinxVerbatim}

\sphinxAtStartPar
When we use our population as the parameter to the \sphinxcode{\sphinxupquote{gini}} function, we get:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{gini\PYGZus{}coefficient\PYGZus{}country1} \PYG{o}{=} \PYG{n}{gini}\PYG{p}{(}\PYG{n}{Country1}\PYG{p}{)}
\PYG{n}{gini\PYGZus{}coefficient\PYGZus{}country1}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
0.518628912071535
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{gini\PYGZus{}coefficient\PYGZus{}country2} \PYG{o}{=} \PYG{n}{gini}\PYG{p}{(}\PYG{n}{Country2}\PYG{p}{)}
\PYG{n}{gini\PYGZus{}coefficient\PYGZus{}country2}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
0.48756218905472637
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{gini\PYGZus{}coefficient\PYGZus{}country3} \PYG{o}{=} \PYG{n}{gini}\PYG{p}{(}\PYG{n}{Country3}\PYG{p}{)}
\PYG{n}{gini\PYGZus{}coefficient\PYGZus{}country3}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
0.4934357195937577
\end{sphinxVerbatim}

\sphinxAtStartPar
These results confirm our intuition from the analysis we did previously via Lorenz curves. Previously, we concluded that country 1 had a higher level of income inequality than country 2, and this is supported by country 1’s higher gini coefficient. On the other hand, we had trouble comparing levels of inequality between country 1 and country 3. Here, the gini coefficient would indicate that country 1 has a higher level of income inequality than country 3.


\subsubsection{Other Forms of Measurement}
\label{\detokenize{content/06-inequality/inequality:other-forms-of-measurement}}
\sphinxAtStartPar
The Gini coefficient is a fairly comprehensive and robust measure of inequality with just a single value: as we’ve seen above, we look at the entire population’s income distribution to determine the Gini coefficient. As a result, calculating the Gini is often a challenging task. In reality, we will never observe the true population Lorenz curve without conducting a census to know how much exactly each household earns. As a result, economists will often attempt to interpolate the Lorenz curve and consequent Gini coefficient from the data they have available. The Gini coefficient is also not as easy to understand or explain; the value by itself does not have significant meaning.

\sphinxAtStartPar
Instead, another common measure of income inequality is the share of income earned by the “top \(x\)\%” or the “bottom \(y\)\%”. These measures are more often used in the media or by politicians in discussing the extent of inequality, since they are much easier to understand. Consider the chart below, which plots the share of income earned by the top 1\%, bottom 90\%, and the 90\sphinxhyphen{}99\%:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{alt_measure}.png}
\caption{Alternative forms of measurement}\label{\detokenize{content/06-inequality/inequality:id1}}\end{figure}


\subsection{Income Inequality Historically}
\label{\detokenize{content/06-inequality/historical-inequality:income-inequality-historically}}\label{\detokenize{content/06-inequality/historical-inequality::doc}}


\sphinxAtStartPar
In the last chart on the previous page, you may have noticed that income inequality was rising in the United States in the last few decades. We will examine this in more detail, and also observe global trends in inequality.


\subsubsection{The United States}
\label{\detokenize{content/06-inequality/historical-inequality:the-united-states}}
\sphinxAtStartPar
Let’s look at historical trends of income inequality in the US over the last 100 years. The data has been collected from \sphinxhref{https://wid.world/}{The World Inequality Database}, which is co\sphinxhyphen{}directed by Berkeley Economics professors Emanuel Saez and Gabriel Zucman. Specifically, we will observe income distributions for the bottom 50 percent, top 10 percent, and top 1 percent.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{us\PYGZus{}hist} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{US\PYGZus{}inequality.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{us\PYGZus{}hist}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{us\PYGZus{}hist}\PYG{o}{.}\PYG{n}{take}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{,}\PYG{l+m+mi}{105}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Percentile | Year | Income Share
p90p100    | 2013 | 0.4632
p90p100    | 2014 | 0.4702
p0p50      | 1913 | nan
p0p50      | 1914 | nan
p0p50      | 1915 | nan
\end{sphinxVerbatim}

\sphinxAtStartPar
Let’s begin with some data cleaning: it seems like our 3 brackets are ‘vertically stacked’ on top of each other. Instead, we would like a table with 5 columns: \sphinxcode{\sphinxupquote{Year}}, \sphinxcode{\sphinxupquote{bottom 50\% income share}}, \sphinxcode{\sphinxupquote{top 10\% income share}}, and \sphinxcode{\sphinxupquote{top 1\% income share}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{bottom\PYGZus{}50\PYGZus{}us} \PYG{o}{=} \PYG{n}{us\PYGZus{}hist}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{p0p50}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabeled}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Income Share}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Bottom 50}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{ Share}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{top\PYGZus{}10\PYGZus{}us} \PYG{o}{=} \PYG{n}{us\PYGZus{}hist}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{p90p100}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabeled}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Income Share}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Top 10}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{ Share}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{top\PYGZus{}1\PYGZus{}us} \PYG{o}{=} \PYG{n}{us\PYGZus{}hist}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{p99p100}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabeled}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Income Share}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Top 1}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{ Share}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{us\PYGZus{}hist\PYGZus{}joined} \PYG{o}{=} \PYG{n}{bottom\PYGZus{}50\PYGZus{}us}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Year}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{top\PYGZus{}10\PYGZus{}us}\PYG{p}{)}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Year}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{top\PYGZus{}1\PYGZus{}us}\PYG{p}{)}
\PYG{n}{us\PYGZus{}hist\PYGZus{}joined}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Year | Bottom 50\PYGZpc{} Share | Top 10\PYGZpc{} Share | Top 1\PYGZpc{} Share
1913 | nan              | 0.4231        | 0.1884
1914 | nan              | 0.4295        | 0.1933
1915 | nan              | 0.4219        | 0.187
1916 | nan              | 0.4439        | 0.2064
1917 | nan              | 0.449         | 0.2014
1918 | nan              | 0.4364        | 0.1895
1919 | nan              | 0.4543        | 0.2101
1920 | nan              | 0.4344        | 0.184
1921 | nan              | 0.4653        | 0.181
1922 | nan              | 0.4554        | 0.1763
... (92 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
Oh no, there are some \sphinxcode{\sphinxupquote{nan}} values! NaN (not a number) values are very common in real world datasets: often, we may not have some observations simply because no data was collected, or perhaps the data collected was faulty. Sometimes, we can try to impute or replace NaN values in order to avoid having gaps in our data, but for now let’s ignore NaNs and when plotting to see what’s going on:

\noindent\sphinxincludegraphics{{historical-inequality_8_0}.png}


\subsection{Income Inequality for the Rest of the World}
\label{\detokenize{content/06-inequality/historical-inequality:income-inequality-for-the-rest-of-the-world}}
\sphinxAtStartPar
Now let’s examine the trends of income inequality in other parts of the world.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{world\PYGZus{}hist} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{World\PYGZus{}Inequality.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{bottom\PYGZus{}50\PYGZus{}world} \PYG{o}{=} \PYG{n}{world\PYGZus{}hist}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{p0p50}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{top\PYGZus{}10\PYGZus{}world} \PYG{o}{=} \PYG{n}{world\PYGZus{}hist}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{p90p100}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{top\PYGZus{}1\PYGZus{}world} \PYG{o}{=} \PYG{n}{world\PYGZus{}hist}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{p99p100}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Percentile}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{top\PYGZus{}10\PYGZus{}world}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Year | Europe | World  | Russia | China  | USA    | India  | Brazil
1980 | 0.2846 | 0.4898 | 0.2102 | 0.2724 | 0.3424 | 0.315  | nan
1981 | 0.283  | 0.4888 | nan    | 0.2768 | 0.3472 | 0.3071 | nan
1982 | 0.2819 | 0.4815 | nan    | 0.2809 | 0.349  | 0.3005 | nan
1983 | 0.2823 | 0.4893 | nan    | 0.2819 | 0.3542 | 0.3528 | nan
1984 | 0.2845 | 0.4916 | nan    | 0.2867 | 0.3666 | 0.3338 | nan
1985 | 0.2871 | 0.4971 | 0.2237 | 0.2952 | 0.3666 | 0.3479 | nan
1986 | 0.2899 | 0.5008 | nan    | 0.2987 | 0.3647 | 0.3507 | nan
1987 | 0.2942 | 0.5043 | nan    | 0.2974 | 0.3761 | 0.3447 | nan
1988 | 0.2991 | 0.5078 | 0.2238 | 0.301  | 0.3895 | 0.3538 | nan
1989 | 0.3024 | 0.5108 | 0.2372 | 0.3067 | 0.3867 | 0.3541 | nan
... (28 rows omitted)
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{historical-inequality_12_0}.png}

\sphinxAtStartPar
Just like the US, it seems global inequality has been rising around the world, especially in China, India, Russia, and across Europe. However, in absolute terms, the level of income inequality in Europe is much lower than that in the United States.

\sphinxAtStartPar
Also look at Russia: income inequality spiked up around 1991. This was likely caused by the fall of the USSR: the failing Soviet state left the ownership of state assets uncontested, which allowed former USSR officials to acquire state property through informal deals. This led to the rise of many Russian oligarchs \sphinxhyphen{} those who rapidly accumulated wealth during the era of Russian privatization directly follwing the dissolution of the Soviet Union.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{top\PYGZus{}10\PYGZus{}world}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Year}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{USA}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Europe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Year}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{width}\PYG{o}{=}\PYG{l+m+mi}{11}\PYG{p}{,} \PYG{n}{height}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Gini Coefficient}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{fontsize}\PYG{o}{=}\PYG{l+m+mi}{14}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Year}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{fontsize}\PYG{o}{=}\PYG{l+m+mi}{14}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Income Inequality over Time}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{fontsize}\PYG{o}{=}\PYG{l+m+mi}{18}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{historical-inequality_14_0}.png}


\subsubsection{The Elephant Graph}
\label{\detokenize{content/06-inequality/historical-inequality:the-elephant-graph}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{elephant_curve}.jpg}
\caption{The elephant curve {[}\hyperlink{cite.content/references:id6}{MIL16}{]}}\label{\detokenize{content/06-inequality/historical-inequality:elephant-curve}}\end{figure}

\sphinxAtStartPar
The elephant curve is a graph that shows the real income growth per adult across each income group’s percentile around the world.

\sphinxAtStartPar
There are 3 key features of the elephant curve: a hump for the world’s poorest, valley for the middle class, and trunk for the upper class. The thump is made of the world’s poorest countries, most likely those from developing countries. The valley comprises the working class from the developed world and upper class from developing countries. The trunk is made of people from the upper class from developed countries. The hump and valley indicate growth among emerging countries, and the top global 1\%’s growth is higher than any other income group, thus explaining the positively sloped shape of the trunk.

\sphinxAtStartPar
A study done by the Brookings Institution{]} found that “poorer countries, and the lower income groups within those countries, have grown most rapidly in the past 20 years” {[}\hyperlink{cite.content/references:id4}{KS}{]}. This supports the World Bank’s claim that inequality between countries and within countries is decreasing. The Brookings Institution used only household surveys, however, which usually excludes the top and bottom percentile of the population, due to non\sphinxhyphen{}response bias. Still, the study is useful in corroborating the trends and growth in global income inequality.


\subsection{Factors that Affect Income Inequality}
\label{\detokenize{content/06-inequality/historical-inequality:factors-that-affect-income-inequality}}
\sphinxAtStartPar
Economists have isolated multiple factors that influence a country’s income inequality
\begin{itemize}
\item {} 
\sphinxAtStartPar
top marginal tax rates

\item {} 
\sphinxAtStartPar
unemployment rates

\item {} 
\sphinxAtStartPar
population growth

\end{itemize}

\sphinxAtStartPar
We will look at each of these scenarios independently and see its overall trends


\subsubsection{Top marginal tax rates}
\label{\detokenize{content/06-inequality/historical-inequality:top-marginal-tax-rates}}
\sphinxAtStartPar
Let’s also take a look at the top marginal tax rates in the United States throughout this time. Overall, the United States (and most of the rest of the world) has a progressive tax system, which means that the more income you earn, the higher percentage you will be taxed at. A good way to reduce income inequality is through progressive taxation; having the richer paying a higher portion of their income will help increase equality. Currently, the top marginal tax rate is 37\%, as we can see in the table below.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{MTR}.png}
\caption{Marginal tax rates. Image from the IRS}\label{\detokenize{content/06-inequality/historical-inequality:irs}}\end{figure}

\sphinxAtStartPar
The top marginal tax rate only applies to the portion of your income above a certain income level. For example, if you earned 19501 dollars in 2019, then you will pay 1940 dollars plus 12\% of \(19501-19401\), i.e. 12 dollars. For another example, if you earned 80000 dollars, then you will pay \(9086 + 0.22(80000-78950) = 9317\) dollars in tax, effectively a \(\frac{9317}{80000} = 11.6\%\) tax rate.

\sphinxAtStartPar
In general, the idea is you will pay a lower tax rate for your first \(x\) dollars, but a higher rate for dollars earned over \(x\).

\sphinxAtStartPar
Now let’s look at the historical trends in marginal top tax rates, which is the \% taxed at the highest tax bracket.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{toptax} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{toptaxrate.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{toptax}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Year | Tax Rate (\PYGZpc{})
1913 | 7
1914 | 7
1915 | 7
1916 | 15
1917 | 67
1918 | 77
1919 | 73
1920 | 73
1921 | 73
1922 | 58
... (95 rows omitted)
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{historical-inequality_23_0}.png}

\noindent\sphinxincludegraphics{{historical-inequality_24_0}.png}

\sphinxAtStartPar
This graph depicts income inequality decreasing between 1910 and 1970 and increasing from 1970 to present.

\sphinxAtStartPar
In 1913, Congress implemented the current income tax to promote equality. Originally meant to help compensate for revenue lost from reducing high tariffs, the new policy essentially made the top 1\% start contributing to taxes. Additionally, the top marginal tax rate increased from 7\% in 1913 to 73\% in 1918, thus helping reduce income inequality. Right before the Great Depression, income inequality peaked, where the richest 1\% possessed 19.6\% of all income. During the Great Depression, top marginal tax rates increased, peaking at 94\% in 1944. The top marginal tax rate decreased but remained high over subsequent decades, where it was 70\% in 1965 and 50\% in 1982. These high top marginal tax rates are correlated with low income inequality. During the Great Depression, the richest 1\% had about 15\% of total income. For the 10 years after the Great Depression, the top 1\% had below 10\% of total income and 8\% for the 30 years afterwards. This period was known as the Great Compression, as income differentials between the top 1\% and the rest of the country decreased.

\sphinxAtStartPar
In the 1970s, the economy took a turn for the worse with high unemployment and inflation (stagflation) and low growth. In order to stimulate economic growth, the government reduced top marginal tax rates (70\% to 38.5\% in 1980s), deregulated corporate institutions, and attacked labor union memberships (membership decreased by half within 30 years). Although these policies improved economic growth, it resulted in higher income inequality.

\sphinxAtStartPar
The graph below better shows that the share of income earned by the bottom 50\% percentile steadily decreased, while the share earned by the top 1\% increased steadily. This means that the top 1\% has more wealth than the entire bottom 50\% of the population. Suppose a class of 100 people has \$100 in aggregate. In a world with perfect equality, each person would have \$1. With this current level of income inequality, one person would have more wealth than 50 people combined.

\sphinxAtStartPar
The media continues to report on the nation’s significant income disparity. \sphinxhref{https://www.washingtonpost.com/business/2019/09/26/income-inequality-america-highest-its-been-since-census-started-tracking-it-data-show/}{The Washington Post wrote a story} and found that “The number of families earning \$15,000 or less has fallen since 2007, according to the latest census data, while the number of households bringing in \$250,000 a year or more has grown more than 15 percent.”

\sphinxAtStartPar
Can we conclude that high marginal tax rates lead to low income inequality but slow economic growth?


\subsubsection{Unemployment rates}
\label{\detokenize{content/06-inequality/historical-inequality:unemployment-rates}}
\sphinxAtStartPar
Economists believe that unemployment is one of the leading factors that leads to income inequality. When looking at what influences the Gini coefficient, a paper from \sphinxhref{https://rpds.princeton.edu/sites/rpds/files/media/menendez\_unemployment\_ar.pdf}{Princeton} found that the unemployment rate had the largest effect on the income inequality rates

\sphinxAtStartPar
Below, we look at the unemployment rates for the past 20 years across many different countries. These are the same countries and regions that we will further study below.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{unemployment} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Unemployment.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{unemployment}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Year | World | India | Europe | Brazil | United States | China | Russia
1991 | 4.76  | 5.45  | 8.1    | 6.37   | 6.8           | 2.37  | 5.14
1992 | 4.9   | 5.5   | 8.8    | 6.42   | 7.5           | 2.37  | 5.18
1993 | 5.21  | 5.61  | 10.14  | 6.03   | 6.9           | 2.69  | 5.88
1994 | 5.43  | 5.63  | 10.87  | 6.23   | 6.1           | 2.9   | 8.13
1995 | 5.58  | 5.64  | 10.65  | 6.42   | 5.6           | 3     | 9.45
1996 | 5.66  | 5.65  | 10.78  | 7.25   | 5.4           | 3.12  | 9.66
1997 | 5.69  | 5.64  | 10.76  | 8.16   | 4.9           | 3.23  | 11.81
1998 | 5.83  | 5.63  | 10.55  | 9.42   | 4.5           | 3.24  | 13.26
1999 | 5.94  | 5.69  | 9.82   | 10.21  | 4.2           | 3.25  | 13.04
2000 | 5.77  | 5.66  | 8.88   | 9.9    | 4             | 3.26  | 10.58
... (19 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
As we can see from the graph, the unemployment rates for China, India and the rest of the world have stayed somewhat steady. On the other hand, Brazil, the US, Russia and Europe are encountering drastically different unemployment situations than before.

\noindent\sphinxincludegraphics{{historical-inequality_29_0}.png}

\noindent\sphinxincludegraphics{{historical-inequality_30_0}.png}

\sphinxAtStartPar
The graphs above show a positive correlation between unemployment and income inequality. As unemployment increases, income inequality also increases. In 2011, Hanan Morsy, an Egyptian economist who serves as the Director of Macroeconomic Policy, Forecasting and Research at the African Development Bank, actually researched this topic {[}\hyperlink{cite.content/references:id7}{Mor11}{]}. Her group examined the member nations of the Organization  for  Economic  Cooperation  and  Development  (OECD) between 1980 and 2005. She found that specific groups that were vulnerable to the economic shocks that led to an increase in income inequality:
\begin{itemize}
\item {} 
\sphinxAtStartPar
young workers

\item {} 
\sphinxAtStartPar
low\sphinxhyphen{}skilled workers

\item {} 
\sphinxAtStartPar
workers who had been out of work for a long time

\end{itemize}

\sphinxAtStartPar
Her solution was to increase job creation opportunities for temporary, recently fired, and recently hired workers, provide job assistance and training to prevent long\sphinxhyphen{}term unemployment, and improve incentives for working by aligning incentives with productivity of labor. Morsy’s research found that the most vulnerable groups to economic shocks were young, low\sphinxhyphen{}skilled and temporary workers. Creating opportunities for these different demographics would help them be more protected from potential shocks and thus decrease income inequality.


\subsubsection{Population growth}
\label{\detokenize{content/06-inequality/historical-inequality:population-growth}}
\sphinxAtStartPar
As the number of people in a country’s population increase, it becomes more difficult for a country to distribute its public goods to everyone. This leads to many social consequences in which resources are not fairly distributed to all members of the population, cause inaccessibility for different parts of the population

\sphinxAtStartPar
The table below shows how the population growth has changed for the same countries we saw above. We are only looking at data for the past 10 years.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{pop\PYGZus{}growth} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Population Growth.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{pop\PYGZus{}growth}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Year | World | India | Brazil | United States | China | Russia
1980 | 1.77  | 2.34  | 2.39   | 0.94          | 1.42  | 0.67
1981 | 1.77  | 2.35  | 2.38   | 0.94          | 1.39  | 0.68
1982 | 1.77  | 2.36  | 2.37   | 0.94          | 1.37  | 0.69
1983 | 1.78  | 2.35  | 2.33   | 0.94          | 1.41  | 0.7
1984 | 1.8   | 2.32  | 2.27   | 0.94          | 1.51  | 0.71
1985 | 1.82  | 2.29  | 2.18   | 0.94          | 1.65  | 0.72
1986 | 1.84  | 2.25  | 2.1    | 0.94          | 1.81  | 0.73
1987 | 1.85  | 2.21  | 2.01   | 0.94          | 1.93  | 0.72
1988 | 1.84  | 2.17  | 1.94   | 0.95          | 1.94  | 0.68
1989 | 1.79  | 2.13  | 1.88   | 0.95          | 1.81  | 0.58
... (29 rows omitted)
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{historical-inequality_34_0}.png}

\noindent\sphinxincludegraphics{{historical-inequality_35_0}.png}

\sphinxAtStartPar
The graphs above show that most countries high population growth between 1\sphinxhyphen{}2\% during the 1980’s. The effects of this can be seen in the rising income inequality during the 90’s.

\sphinxAtStartPar
Recent research by University of Toronto’s Marijn Bolhuis and Univeristy of Oxford’s Alexandra de Pleijt shows that there is a strong correlation between a country’s population growth (measured by birth rates) and its income inequality {[}\hyperlink{cite.content/references:id5}{BdP}{]}. Their most recent study in 2016 analyzed income inequality and birth rates data between 1870 and 2000 across 67 countries. They concluded that if a country had 50\% higher income inequality, then that country’s birth rate would be about twice as high as another country with the same level of economic development. Bolhuis says that these higher birth rates mean that economic growth has to be equal to or greater than the birth rate to offset the implications of higher birth rates.

\sphinxAtStartPar
This is part of a larger debate about the relationship between birth rates and income inequality. Economist Thomas Piketty finds that low birth rates, rather than high birth rates, are causing today’s income inequality. With lower birth rates, fewer children per couple are being borne, so these children get more of their parents’ inheritance.


\section{Game Theory}
\label{\detokenize{content/07-game-theory/index:game-theory}}\label{\detokenize{content/07-game-theory/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{Game theory} is a branch of mathematics concerned with the study of strategic interaction among rational decision\sphinxhyphen{}makers. While inherently mathematical at its foundation, game theory has numerous applications in several social science disciplines, including economics. Game theory originated with the study of equilibria in zero\sphinxhyphen{}sum games by John von Neumann and has since expanded into many other paradigms, including applications such as a method of examining and strategizing for interactions between the US and the USSR during the Cold War and explaining the evolution and prevalence of 1:1 sex ratios in biology. In this chapter, we will study a few particular aspects of game theory and their application to economics.

\sphinxAtStartPar
There are many different ways to conceive of games and to divide them along different attributes.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Cooperative vs. non\sphinxhyphen{}cooperative:} A game is \sphinxstyleemphasis{cooperative} if the players are able to form commitments that can be externally enforced. A game is \sphinxstyleemphasis{non\sphinxhyphen{}cooperative} if the players cannot form agreements or if those agreements need to be self\sphinxhyphen{}enforced.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Symmetric vs. asymmetric:} A game is \sphinxstyleemphasis{symmetric} if the payoffs depend only on the strategies used and not on the players using those strategies. It is \sphinxstyleemphasis{asymmetric} if changing the identities of the players changes the payoffs.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Simultaneous vs. sequential:} A game is \sphinxstyleemphasis{simultaneous} if players move at the same time without being aware of the other players’ actions. A game is \sphinxstyleemphasis{sequential} if moves occur one after the other and players have some knowledge of the earlier actions of their competitors.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Perfect vs. imperfect information:} Games of \sphinxstyleemphasis{perfect information} occur when all players know the moves previously made by all other players. If this is not the case, the game is an \sphinxstyleemphasis{imperfect\sphinxhyphen{}information} game.

\end{itemize}

\sphinxAtStartPar
In this chapter, we will concern ourselves with simultaneous games of imperfect information, examining both cooperative and non\sphinxhyphen{}cooperative games as well as symmetric and asymmetric ones. We will also discuss different theoretical aspects, like strategies and payoffs. We will look at various common game paradigms, including one of the most popular games: the prisoner’s dilemma. Lastly, we will study the economic application of game theory, including topics like equilibria and oligopolies.


\subsection{Expected Utility Theory}
\label{\detokenize{content/07-game-theory/expected-utility:expected-utility-theory}}\label{\detokenize{content/07-game-theory/expected-utility::doc}}
\sphinxAtStartPar
Imagine you’re offered a choice between \$1 guaranteed or \$100 with probability \(\frac{1}{80}\) (i.e. with probability \(\frac{79}{80}\), you get \$0). Which would you choose?

\sphinxAtStartPar
In game theory, we consider rationality by examining the utility of different outcomes to individuals. To do so, we calculate the \sphinxstylestrong{expected utility} of a set of outcomes, which is the average of the utilities of those outcomes weighted by their probabilities. In the example above, there are two outcomes:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\$1 guaranteed. This occurs with probability \(p_1=1\) and we’ll say has utility \(u_1 = 1\).

\item {} 
\sphinxAtStartPar
\$100 with probability \(p_2 = \frac{1}{80}\). We’ll say this has utility \(u_2 = 100\).

\end{itemize}

\sphinxAtStartPar
The expected utility of the first choice would be \(p_1 \cdot u_1 = 1\) because there is only one possible outcome and it has utility 1. The expected utility of the second choice would be \(p_2 \cdot u_2 + (1 - p_2) \cdot 0 = 1.25\) because we obtain utility \(u_2\) with probability \(p_2\) and utility 0 with probability \(1-p_2\). Notice that the expected utility of the second choice is higher! This means that, had you chosen the \$1 guaranteed, you would have made the irrational choice, because it is \sphinxstyleemphasis{expected} that you would get \$1.25 with the second choice.

\sphinxAtStartPar
The idea that individuals, when making a gamble, will choose the option that maximizes the expected utility based on their preferences is called the \sphinxstylestrong{expected utility hypothesis}.


\subsubsection{Expected Utility}
\label{\detokenize{content/07-game-theory/expected-utility:expected-utility}}
\sphinxAtStartPar
The expected utility is a calculated value based on two pieces of information: an individual’s preferences for different outcomes and the probability of those outcomes occurring. Let’s illustrate this with an example: Suppose Alice is deciding whether to attend lecture today and her professor is deciding whether to take attendance today. If Alice goes to lecture, she will be bored but get her attendance counted if it’s taken. If she doesn’t, she won’t be bored, but she  won’t get her attendance point. We must define the utilities for Alice and her professor in order to construct a payoff matrix.







\begin{sphinxadmonition}{note}{Reading a payoff matrix}

\sphinxAtStartPar
A payoff matrix specifies the payoffs of two players. The 2\sphinxhyphen{}tuples in each cell define the payoff for both players according to the combination of strategies corresponding to the row and column. For example, the bottom right cell above corresponds to the payoffs for Alice not attending and the professor not taking attendance. The tuples are formatted as \sphinxcode{\sphinxupquote{(row player, column player)}}, so the first element is Alice’s payoff and the second is the professor’s. The payoff of (5, 0) indicates that that outcome has a utility of 5 for Alice and 0 for the professor.
\end{sphinxadmonition}

\sphinxAtStartPar
Let’s say that we know the professor’s strategy: he will take attendance randomly with probability 0.7. Then we can calculate the expected utility of Alice’s two options (attending and not attending) by taking the expected utility of each:
\begin{equation*}
\begin{split}\begin{aligned}
E[\text{attending}] &= 0.7 (0) + 0.3 (-2) \\
&= - 0.6 \\
E[\text{not attending}] &= 0.7 (-5) + 0.3 (5) \\
&= -2
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
By calculating out Alice’s expected utilities, we see that her utility is maximized by attending, given that the professor’s strategy is to take attendance with probability 0.7.

\sphinxAtStartPar
An important point here is that we rely on the professor’s strategy for playing the game to determine how to maximize Alice’s expected utility. If the professor had a different strategy, then it could be the case that not attending would be the better option.

\sphinxAtStartPar
Let’s formalize our definition of the expected utility.

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstylestrong{expected utility} of a set of \(n\) outcomes \(x_i\) is the average of the utility of each outcome \(u(x_i)\) weighted by the probability of that outcome’s occurrence \(p_i\):
\begin{equation*}
\begin{split}
E[u(x)] = \sum_{i=1}^n p_i u(x_i)
\end{split}
\end{equation*}\end{sphinxadmonition}


\paragraph{Strategies}
\label{\detokenize{content/07-game-theory/expected-utility:strategies}}
\sphinxAtStartPar
One of the underpinnings of game theory is the idea of \sphinxstylestrong{strategies}, systematic methods of playing games. There are many different ways to conceptualize strategies, some of which we’ve already seen. The professor’s randomness strategy from the last example is one such, maximizing expected utility is another. Strategies tell the players of a game what move to make based on available information, and can be conceived of as a probability distribution over a player’s choices.

\sphinxAtStartPar
There are many different types of strategies. Any strategy that puts probability 1 on a single choice is called a \sphinxstylestrong{pure} strategy; all others are called \sphinxstylestrong{mixed} strategies. If Alice’s strategy had been “never attend class,” this would have been a pure strategy, because the probability of not attending was always 1. The professor’s strategy was a mixed strategy, since there wasn’t a single option with probability 1.


\subsection{Equilibria \& Oligopolies}
\label{\detokenize{content/07-game-theory/equilibria-oligopolies:equilibria-oligopolies}}\label{\detokenize{content/07-game-theory/equilibria-oligopolies::doc}}
\sphinxAtStartPar
This section introduces the concept of equilibria in games, the paradigm of the prisoner’s dilemma, and oligopolies. These concepts are essential to understanding the models we will be studying the next sections, and for relating game theory to its economic applications.


\subsubsection{Equilibrium}
\label{\detokenize{content/07-game-theory/equilibria-oligopolies:equilibrium}}
\sphinxAtStartPar
The \sphinxhref{https://en.wikipedia.org/wiki/Prisoner\%27s\_dilemma}{prisoner’s dilemma} is a classic game first discussed by Merrill Flood and Melvin Dresher in 1950. In this game, there are two prisoners who have been captured and are being interrogated. The prisoners cannot contact each other in any way. They have two options: they can \sphinxstylestrong{defect} (betray the other prisoner to the police) or they can \sphinxstylestrong{cooperate} (maintain their silence). If both defect, both receive 4 years in prison. If one defects and the other does not, the defector goes free and the cooperator receives 5 years in prison. If both cooperate (meaning neither talks to the police), then they each receive 2 years in prison. We define \sphinxstylestrong{mutual defection} as the case when both prisoners defect and \sphinxstylestrong{mutual cooperation} as the case when both cooperate. The purpose of this game is to consider how a completely rational person would be best advised to proceed, and how different strategies for playing this game can be more or less effective.







\sphinxAtStartPar
In the above payoff matrix, we see that if Prisoner A cooperates and Prisoner B defects, then Prisoner A gets 5 years in prisoner and Prisoner B gets none. It is important to note that the above payoff matrix is inverted; because we are talking about \sphinxstyleemphasis{years in prison} as opposed to utility, a higher value is \sphinxstylestrong{worse} for the player, and a player’s goal is to \sphinxstyleemphasis{minimize} their value in the payoff matrix, not maximize it as normally. We will use this payoff matrix convention when discussing the prisoner’s dilemma, but \sphinxstyleemphasis{not} with other games.

\sphinxAtStartPar
An important concept in game theory is finding the equilibrium of a game. There are different types of equilibria, but the most common one considered is the \sphinxstylestrong{Nash equilibrium}, named for the mathematician John Forbes Nash, Jr. (who you may remember as a character played by Russel Crowe in \sphinxhref{https://en.wikipedia.org/wiki/A\_Beautiful\_Mind\_(film)}{\sphinxstyleemphasis{A Beautiful Mind}}). A Nash equilibrium occurs when no player can increase their own payoff by changing only their own strategy.

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstylestrong{Nash equilibrium} is a set of strategy choices in a non\sphinxhyphen{}cooperative game in which each player, assumed to know the equilibrium strategies of the other players, has a chosen strategy and there can be no monotonic improvement; that is, no player can increase their payoffs by changing their strategy without another player changing \sphinxstyleemphasis{their} strategy.
\end{sphinxadmonition}

\sphinxAtStartPar
Using this definition, what constitutes a Nash equilibrium for the prisoner’s dilemma? Well let’s consider the four possible combinations of strategies. (We use “D” as shorthand for “defect” and “C” for “cooperate” below.)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Prisoner A: C, Prisoner B: C.} In this case, both Prisoner A and Prisoner B get 4 years. However, if Prisoner A’s strategy remains unchanged, Prisoner B can get fewer years in prison by changing to D, and vice versa. Thus, this is \sphinxstylestrong{not} a Nash equilibrium.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Prisoner A: D, Prisoner B: C.} In this case, Prisoner B can change to D and lower their years from 5 to 4. Thus, this is \sphinxstylestrong{not} a Nash equilibrium.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Prisoner A: C, Prisoner B: D.} As with (2), Prisoner A can change to D and lower their years in prison. Thus, this is \sphinxstylestrong{not} a Nash equilibrium.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Prisoner A: D, Prisoner B: D.} In this case, if Prisoner A changes to C, then their years in prison \sphinxstyleemphasis{increases} from 4 to 5, as with Prisoner B. Neither player can increase their winnings (decrease their years in prison) by changing their strategy. Thus, this \sphinxstylestrong{is} a Nash equilibrium.

\end{enumerate}

\sphinxAtStartPar
By describing the four states of the game, we see that only mutual defection is a Nash equilibrium of the prisoner’s dilemma.

\begin{sphinxadmonition}{note}{Nash equilibria in payoff matrices}

\sphinxAtStartPar
It is easy to use a payoff matrix to  see which  states, if any, are Nash equilibria. To see if a game state is a Nash equilibrium, the first value in the cell must be the maximum among all first values in that column and the second value must be the maximum across all second values in that row. This is because moving up and down a column represents changing the row\sphinxhyphen{}player’s strategy and  moving along a row represents changing the column\sphinxhyphen{}player’s strategy. If these values are both maxima in their respective directions, then no player can obtain a better payoff by unilaterally changing their strategy, and we have a Nash equilibrium.

\sphinxAtStartPar
You can easily verify this by looking at the payoff matrix for the prisoner’s dilemma: the  first 4 in mutual defection has the best payoff in the column and the second  4 has the best payoff in the row.
\end{sphinxadmonition}


\subsubsection{Oligopolies}
\label{\detokenize{content/07-game-theory/equilibria-oligopolies:oligopolies}}
\sphinxAtStartPar
One of the most common applications of game theory in economics is the study of \sphinxstylestrong{oligopolies}, markets where the number of participants is limited. There are several examples of oligopolies that we experience without knowing in daily life: airlines, soft drinks, and telecom providers, to name a few. Oligopolies are different from regular markets in that they allow their participants to function similar to a monopoly by setting prices as a group; groups of participants conspiring on this kind of illicit activity are referred to as \sphinxstylestrong{cartels}.

\sphinxAtStartPar
Within oligopolies, however, we can observe competition more like a normal market as firms attempt to take market share from one another. When cartels set prices (by limiting the production of the good or service provided by their market), a firm can make a bid for market share by ignoring the agreed\sphinxhyphen{}upon production level and producing more. This has the effect of lowering the price of the good but the increase in production by the renegade firm will allow them to make up for the lost marginal revenue through increased sales volume. In this way, oligopoly members can compete against each other, making the market more and more competitive.

\sphinxAtStartPar
A prime example of this type of within\sphinxhyphen{}cartel competition was observed in the \sphinxhref{https://en.wikipedia.org/wiki/2020\_Russia\%E2\%80\%93Saudi\_Arabia\_oil\_price\_war}{2020 oil price war between Russia and Saudi Arabia}. Both countries are members of \sphinxhref{https://en.wikipedia.org/wiki/OPEC}{OPEC (the Organization of Petroleum Exporting Countries)}, an oil cartel that consists of 12 member countries controlling 79\% of the world’s oil reserves and 44\% of oil production. OPEC sets oil prices by limiting the output of its member countries (a decrease in production results in higher prices).

\sphinxAtStartPar
The price war began when Saudi Arabia discounted its oil in response to Russia’s refusal to reduce production in accordance with OPEC’s directive. OPEC’s members had agreed to reduce oil production due to a low forecasted demand for oil due to the COVID\sphinxhyphen{}19 pandemic. When Russia (who was not an official member of OPEC but had agreed to cooperate with Saudi Arabia to manage oil prices) didn’t abide  by OPEC’s decision, Saudi Arabia announced discounts on its oil, starting the price war and leading to a massive drop in the price of oil. We can see the effects of this price war by looking at the price per barrel of OPEC’s crude oil, plotted below.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.HTML object\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
The plot above marks the official start of the price war on March 8, 2020, in red. We see some precipitous drops both just before and for a while after the start of the price war, indicating the effect that it is having on oil prices. While there are some confounding variables here (hi there, COVID\sphinxhyphen{}19), we still see a serious drop in price that is not just attributable to the stock market volatility that experienced by the rest of the market in early 2020.


\subsection{Cournot Competition}
\label{\detokenize{content/07-game-theory/cournot:cournot-competition}}\label{\detokenize{content/07-game-theory/cournot::doc}}
\sphinxAtStartPar
One model of understanding oligopolies comes in \sphinxstylestrong{Cournot competition}, named for Aontoine Cournot who first proposed it. Cournot competition is a model describing a market in which firms compete by changing their output. In Cournot competition, there are a fixed number of firms in a market that produce the same product. Firms do not collude but have \sphinxstyleemphasis{market power} (i.e. each firm’s output decisions affect the price of the good). Each firm knows the number of firms in the market and has its own cost function that it uses to determine its level of output.

\sphinxAtStartPar
OPEC is a good example of a Cournot oligopoly: its participants affect prices by changing their output. OPEC also demonstrates a flaw in the reasoning behind Cournot competition: the equilibrium state of a Cournot oligopoly suggests that collusion by market participants is the rational policy, but in reality game theory shows us this cannot be the “true” equilibrium because cartel members undercut one another in a bid for market share.


\subsubsection{Cournot Equilibrium}
\label{\detokenize{content/07-game-theory/cournot:cournot-equilibrium}}
\sphinxAtStartPar
To find the equilibrium state of a Cournot duopoly, let \(c\) be the (constant) marginal cost of both firms (i.e. each additional good costs the same amount to produce regardless of the number currently being produced), \(p_1\) and \(p_2\) be the prices of firms 1 and 2, respectively, and \(q_1\) and \(q_2\) their quantities. Let \(P\) be the price function for a given level of production. We know that the equilibrium price is \(p_1 = p_2 = P(q_1 + q_2)\), and therefore firm 1’s profit is \(q_1(P(q_1 + q_2) - c)\) (since \(c\) is constant).

\sphinxAtStartPar
The first step is to calculate firm 1’s residual demand. If firm 1 believes that firm 2 is going to produce \(q_2\) units of output, we can draw a \sphinxstylestrong{residual demand curve} for firm 1. If firm 1 decides to produce 0 units of output, then the price of the good is \(P(0 + q_2) = P(q_2)\). If they produce \(q_1\) units, it’s \(P(q_1 + q_2)\). Using this information, we can draw the residual demand curve. This curve will be called \(d_1\).

\sphinxAtStartPar
Now we need to determine firm 1’s optimal output, which occurs where the \sphinxstylestrong{marginal revenue} (the additional revenue gained by increasing production by one unit) intersects the marginal cost \(c\). The marginal revenue curve is the line with twice the slope of the residual demand and the same \(y\)\sphinxhyphen{}intercept. We can show this by taking the derivative of the revenue function \(\text{TR} = P(Q) \cdot Q\) where \(\text{TR}\) is the total revenue. If the demand curve \(P(Q)\) has slope \(m\) and \(y\)\sphinxhyphen{}intercept \(b\), this is
\begin{equation*}
\begin{split}\begin{aligned}
\text{TR} &= Q (mQ + b) \\
&= m Q^2 + bQ \\
\frac{\text{d}}{\text{d} Q} \text{TR} &= 2mQ + b
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Thus, the marginal revenue curve is a line with slope \(2m\) and \(y\)\sphinxhyphen{}intercept \(b\). The marginal revenue of firm 1 is denoted \(r_1\) and is a function of \(q'_1\).

\sphinxAtStartPar
Let \(q'_1\) be the optimum output for firm 1, such that \(r_1(q'_1) = c\). The graph below shows the curves and their relationships to one another.

\noindent\sphinxincludegraphics{{cournot_3_0}.png}

\sphinxAtStartPar
\(q'_1\) is a function of \(q_2\) as firm 1’s optimal output depends on what it thinks firm 2 is going to produce. To find the equilibrium, we must define \(q'_1\) for all possible values of \(q_2\). Consider the case when \(q_2=0\); then firm 1’s residual demand is the same as the market demand, since \(d_1\) and \(D\) are separated horizontally by a difference of \(q_2\). Firm 1 then produces the monopoly quantity \(q_m\), since that is where its marginal revenue equals its marginal cost. If, however, firm 2 chooses to produce at a level of perfect competition, \(q_c\), the optimum for firm 1 is to produce 0 output units, since their marginal revenue will intersect \(c\) at \(q_1 = 0\). The graph below shows both of these cases.

\noindent\sphinxincludegraphics{{cournot_5_0}.png}

\sphinxAtStartPar
When demand is linear and marginal cost is constant, the function \(q'_1\) is also linear. Because we have two points, \(q'_1(0) = q_m\) and \(q'_1(q_c) = 0\), we can draw the curve \(q'_1\). Remember that \(q'_1\) is a function of what firm 1 \sphinxstyleemphasis{thinks} firm 2 is going to produce.

\noindent\sphinxincludegraphics{{cournot_7_0}.png}

\sphinxAtStartPar
Finally, we need to know firm 2’s reaction to firm 1’s production. Because both firms have the same cost function, firm 2’s optimum output \(q'_2\) given firm 1’s output \(q_1\) is the inverse of firm 1’s. The equilibrium of the model is at the intersection of these reaction functions.

\noindent\sphinxincludegraphics{{cournot_9_0}.png}


\subsubsection{Implications}
\label{\detokenize{content/07-game-theory/cournot:implications}}
\sphinxAtStartPar
The Cournot model implies that output is greater in a Cournot duopoly than in a monopoly, but still lower than perfect competition. Prices are also lower in a Cournot duopoly, but higher than perfect competition. Cournot equilibria are also a subset of Nash equilibria, and so the equilibrium we just derived is one from which neither player will likely deviate. As noted earlier, Cournot also indicates that members of a duopoly could form a cartel and raise profits by colluding.


\subsubsection{Applying Cournot}
\label{\detokenize{content/07-game-theory/cournot:applying-cournot}}
\sphinxAtStartPar
Now that we have shown how to derive the Cournot equilibrium, let’s apply this to a problem. Consider the industry of airline manufacturing: there are two main competitors, Boeing and Airbus, and for this problem we will think of this market as a Cournot duopoly. Suppose the market demand curve is given by \(P = -1.89 Q + 148.89\) where the price is in millions of \$ and that the marginal cost of both firms is constant at \(c = 100\).

\noindent\sphinxincludegraphics{{cournot_12_0}.png}

\sphinxAtStartPar
Now suppose we want to find the equilibrium and that Boeing believes that Airbus will produce at quantity \(q_2 = 20\). To find the equilibrium, we need to start by finding Boeing’s residual demand curve. This is given by
\begin{equation*}
\begin{split}\begin{aligned}
d_1(q_1) &= P(q_1 + q_2) \\
&= -1.89(q_1 + q_2) + 148.89 \\
&= -1.89(q_1 + 20) + 148.89 \\
&= -1.89 q_1 + 111.09
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Now we need the marginal revenue \(r_1\) of Boeing, which is the line with the same \(y\)\sphinxhyphen{}intercept but twice the slope. We can easily find \(r_1\) as \(2 d_1(q_1) - d_1(0)\) as this will double the slope for us but subtract out half of the doubled \(y\)\sphinxhyphen{}intercept.
\begin{equation*}
\begin{split}\begin{aligned}
r_1(q_1) &= 2 \cdot d_1(q_1) - d_1(0) \\
&= -3.78 + 111.09
\end{aligned}\end{split}
\end{equation*}
\noindent\sphinxincludegraphics{{cournot_14_0}.png}

\sphinxAtStartPar
Based on this graph, if Boeing’s prediction that Airbus will produce 20 units of output is correct, we can already tell what Boeing’s optimal output is; but instead, let’s use SymPy to calculate it.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{c} \PYG{o}{=} \PYG{l+m+mi}{100}
\PYG{n}{q\PYGZus{}1} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{q\PYGZus{}1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{r\PYGZus{}1} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{3.78} \PYG{o}{*} \PYG{n}{q\PYGZus{}1} \PYG{o}{+} \PYG{l+m+mf}{111.09}

\PYG{n}{solve}\PYG{p}{(}\PYG{n}{r\PYGZus{}1}\PYG{p}{,} \PYG{n}{c}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
2.93386243386243
\end{sphinxVerbatim}

\sphinxAtStartPar
Therefore, if Boeing thinks that Airbus will produce 20 planes, they should produce 3.

\sphinxAtStartPar
Now, however, let’s say that Boeing is unsure of it’s guess for \(q_2\). How can we arrive at the \sphinxstyleemphasis{actual} Cournot equilibrium, the quantities at which both Boeing and Airbus should produce? We need to start by finding the monopoly quantity \(q_m\) and the perfect competition quantity \(q_c\). We can find \(q_m\) by looking at Boeing’s marginal revenue when Airbus is assumed to produce 0 planes. In this case, \(d_1 = P(q_1 + 0) = -1.89 q_1 + 148.89\) and therefore \(r_1 = -3.78 q_1 + 148.89\). We find \(q_m\) as the point at which this new marginal revenue curve intersects the marginal cost curve.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{r\PYGZus{}1} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{3.78} \PYG{o}{*} \PYG{n}{q\PYGZus{}1} \PYG{o}{+} \PYG{l+m+mf}{148.89}
\PYG{n}{q\PYGZus{}m} \PYG{o}{=} \PYG{n}{solve}\PYG{p}{(}\PYG{n}{r\PYGZus{}1}\PYG{p}{,} \PYG{n}{c}\PYG{p}{)}
\PYG{n}{q\PYGZus{}m}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
12.9338624338624
\end{sphinxVerbatim}

\sphinxAtStartPar
So the monopoly quantity is \(q_m = 12.934\). To find the perfect competition quantity \(q_c\), we need to find the point at which the market demand curve \(P\) intersects the marginal cost.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Q} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Q}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{P} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.89} \PYG{o}{*} \PYG{n}{Q} \PYG{o}{+} \PYG{l+m+mf}{148.89}
\PYG{n}{q\PYGZus{}c} \PYG{o}{=}  \PYG{n}{solve}\PYG{p}{(}\PYG{n}{P}\PYG{p}{,} \PYG{n}{c}\PYG{p}{)}
\PYG{n}{q\PYGZus{}c}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
25.8677248677249
\end{sphinxVerbatim}

\sphinxAtStartPar
And thus we get \(q_c = 25.868\). Now, we know that when Airbus is producing at \(q_c\), Boeing is producing 0 planes because their marginal revenue is below the marginal cost for every value above 0. When Airbus is producing 0 planes, Boeing produces at \(p_m\). From this, we have two points with which we can draw Boeing’s reaction curve to Airbus’s quantity choice \(q'_1(q_2)\):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{x1}\PYG{p}{,} \PYG{n}{y1} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{q\PYGZus{}m}
\PYG{n}{x2}\PYG{p}{,} \PYG{n}{y2} \PYG{o}{=} \PYG{n}{q\PYGZus{}c}\PYG{p}{,} \PYG{l+m+mi}{0}

\PYG{n}{m} \PYG{o}{=} \PYG{p}{(}\PYG{n}{y2} \PYG{o}{\PYGZhy{}} \PYG{n}{y1}\PYG{p}{)} \PYG{o}{/} \PYG{p}{(}\PYG{n}{x2} \PYG{o}{\PYGZhy{}} \PYG{n}{x1}\PYG{p}{)}
\PYG{n}{b} \PYG{o}{=} \PYG{n}{y1} \PYG{o}{\PYGZhy{}} \PYG{n}{m} \PYG{o}{*} \PYG{n}{x1}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{y = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{m}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ * x + }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{b}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
y = \PYGZhy{}0.500000000000000 * x + 12.9338624338624
\end{sphinxVerbatim}

\sphinxAtStartPar
Because the marginal cost is constant and the same for both Boeing and Airbus, Airbus’s reaction function \(q'_2(q_1)\) is symmetrical to Boeing’s:

\noindent\sphinxincludegraphics{{cournot_24_0}.png}

\sphinxAtStartPar
To get the exact values, let’s use SymPy one last time:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{q\PYGZus{}2} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{q\PYGZus{}2}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{q\PYGZus{}1\PYGZus{}prime} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{o}{.}\PYG{l+m+mi}{5} \PYG{o}{*} \PYG{n}{q\PYGZus{}2} \PYG{o}{+} \PYG{n}{q\PYGZus{}m}
\PYG{n}{q\PYGZus{}2\PYGZus{}prime} \PYG{o}{=} \PYG{p}{(}\PYG{n}{q\PYGZus{}2} \PYG{o}{\PYGZhy{}} \PYG{n}{q\PYGZus{}m}\PYG{p}{)} \PYG{o}{/} \PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{o}{.}\PYG{l+m+mi}{5}\PYG{p}{)}

\PYG{n}{q\PYGZus{}2\PYGZus{}star} \PYG{o}{=} \PYG{n}{solve}\PYG{p}{(}\PYG{n}{q\PYGZus{}1\PYGZus{}prime}\PYG{p}{,} \PYG{n}{q\PYGZus{}2\PYGZus{}prime}\PYG{p}{)}
\PYG{n}{q\PYGZus{}1\PYGZus{}star} \PYG{o}{=} \PYG{n}{q\PYGZus{}1\PYGZus{}prime}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{q\PYGZus{}2}\PYG{p}{,} \PYG{n}{q\PYGZus{}2\PYGZus{}star}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{q\PYGZus{}1\PYGZus{}star = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{q\PYGZus{}1\PYGZus{}star}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{q\PYGZus{}2\PYGZus{}star = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{q\PYGZus{}2\PYGZus{}star}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
q\PYGZus{}1\PYGZus{}star = 8.62257495590830
q\PYGZus{}2\PYGZus{}star = 8.62257495590827
\end{sphinxVerbatim}


\subsection{Bertrand Competition}
\label{\detokenize{content/07-game-theory/bertrand:bertrand-competition}}\label{\detokenize{content/07-game-theory/bertrand::doc}}
\sphinxAtStartPar
Another model we consider is \sphinxstylestrong{Bertrand competition}, named for Joseph Louis Francois Bertrand, that is similar to Cournot competition but that firms compete using \sphinxstyleemphasis{prices} rather than quantity. Under the assumptions of this model, consumers want to buy everything at the lowest price, and if the price is the same then demand is evenly split between those producers. One fundamental assumption is that all firms have the same unit cost of production, which means that as long as the price the firm sets is above the unit cost, it is willing to supply any amount that is demanded.

\sphinxAtStartPar
An example of a Bertrand oligopoly comes form the soft drink industry: Coke and Pepsi (which form a \sphinxstylestrong{duopoly}, a market with only two participants). Both firms compete by changing their prices based on a function that takes into account the price charged by their competitor. This model predicts that even this small competition will result in prices being reduced to the marginal cost level, the same outcome as perfect competition.


\subsubsection{Bertrand Equilibrium}
\label{\detokenize{content/07-game-theory/bertrand:bertrand-equilibrium}}
\sphinxAtStartPar
To find the Bertrand equilibrium, let \(c\) be the (constant) marginal cost, \(p_1\) be firm 1’s price level, \(p_2\) be firm 2’s price level, and \(p_m\) be the monopoly price level. Firm 1’s price depends on what it believes firm 2 will set its prices to be. Because consumers always buy at the lowest price and the firm will fulfill any level of demand, pricing just below firm 2 will obtain full market demand for firm 1. Why might this not be a good idea? If firm 2 is pricing below the level of marginal cost, then firm 1 will incur losses because they would need to sell at a price lower than the cost of production.

\sphinxAtStartPar
Let \(p'_1(p_2)\) be firm 1’s optimal price based on price \(p_2\) set by firm 2. The graph below shows \(p'_1(p_2)\). Note that when \(p_2 < c\), \(p'_1\) is equal to \(c\), that \(p'_1\) rises linearly along but \sphinxstyleemphasis{just below} the line \(p_1 = p_2\) with \(p_2\) until \(p_2\) reaches \(p_m\) (the monopoly price level), and that it then levels off at \(p_m\). In this way, firm 1’s price stays below firm 2’s price when it is not operating at a loss and does not exceed \(p_m\) (because \(p_m\) is the profit\sphinxhyphen{}maximizing amount for a monopoly and producing more actually results in less profit). This piecewise function has the formula
\begin{equation*}
\begin{split}
p'_1(p_2) = \begin{cases}
c & \text{if } p_2 < c + h \\
p_2 - h & \text{if } c + h \le p_2 < p_m + h \\
p_m & \text{otherwise}
\end{cases}
\end{split}
\end{equation*}
\sphinxAtStartPar
where \(h\) is a small positive value and indicates the vertical distance between \(p'_1\) and the line \(p_1 = p_2\). We can think of \(h\) as the amount by which firm 1 will undercut firm 2: as long as firm 1 will be operating at a profit and not exceeding \(p_m\), they will sell at \(h\) dollars below \(p_2\).

\noindent\sphinxincludegraphics{{bertrand_3_0}.png}

\sphinxAtStartPar
Because firm 2 has the same marginal cost \(c\) as firm 1, its reaction function \(p'_2(p_1)\) is symmetrical to firm 1’s about the line \(p_1 = p_2\):

\noindent\sphinxincludegraphics{{bertrand_5_0}.png}

\sphinxAtStartPar
These two strategies form a Nash equilibrium because neither firm can increase profits by changing their own strategy unilaterally. The equilibrium occurs where \(p_1 = p'_1(p_2)\) and \(p_2 = p'_2(p_1)\), at the intersection of the two reaction curves. Notably, this means that the Bertrand equilibrium occurs when both firms are producing \sphinxstyleemphasis{at marginal cost}.

\sphinxAtStartPar
This makes intuitive sense: say that the two firms both set equal prices at a price above \(c\) where they split demand equally. Then both firms have incentive to reduce their price slightly and take the other half of the market share from their competitor. Thus, both firms are tempted to lower prices as much as possible, but lowering below the level of marginal cost makes no sense because then they’re operating at a loss. Thus, both firms sell at the price level \(c\).


\subsubsection{Implications}
\label{\detokenize{content/07-game-theory/bertrand:implications}}
\sphinxAtStartPar
The Bertrand model implies that even a duopoly in a market is enough to push prices down to the level of perfect competition. It does, however, rely on some serious assumptions. For example, there are many reasons why consumers might not buy the lowest\sphinxhyphen{}priced item (e.g. non\sphinxhyphen{}price competition, search costs). When these factors are included in the Bertrand model, the same result is no longer reached. It also ignores the fact that firms may not be able to supply the entire market demand; including these capacity constraints in the model can result in the system having no Nash equilibrium. Lastly, the Bertrand model demonstrates big incentives to cooperate and raise prices to the monopoly level; however, this state is not a Nash equilibrium, and in fact, the only Nash equilibrium of this model is the non\sphinxhyphen{}cooperative one with prices at marginal cost.


\subsubsection{Applying Bertrand}
\label{\detokenize{content/07-game-theory/bertrand:applying-bertrand}}
\sphinxAtStartPar
Now that we have derived the Bertrand equilibrium, let’s apply it to a problem. Consider the Coke\sphinxhyphen{}Pepsi duopoly we mentioned above. Suppose that the only product in the soft\sphinxhyphen{}drink market is the 12\sphinxhyphen{}oz. can, that the market demand for cans is given by \(P = -0.05 Q + 5.05\), and that the marginal cost for Coke and Pepsi is constant at \(c = 0.25\). To find the equilibrium price for Coke based in it’s belief that Pepsi will sell at \(p_2 = 1\), we need to start by finding the monopoly price level \(p_m\); recall from Cournot that this occurs when the marginal revenue curve of the market demand intersects the marginal cost. The marginal revenue is \(r(q) = -0.1 q + 5.05\):

\noindent\sphinxincludegraphics{{bertrand_9_0}.png}

\sphinxAtStartPar
Using SymPy, we can find the quantity \(q\) at which \(r(q) = c\). This value, denoted \(q_m\), is the monopoly quantity.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{c} \PYG{o}{=} \PYG{l+m+mf}{0.25}
\PYG{n}{q} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{q}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{r} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{o}{.}\PYG{l+m+mi}{1} \PYG{o}{*} \PYG{n}{q} \PYG{o}{+} \PYG{l+m+mf}{5.05}

\PYG{n}{q\PYGZus{}m} \PYG{o}{=} \PYG{n}{solve}\PYG{p}{(}\PYG{n}{r}\PYG{p}{,} \PYG{n}{c}\PYG{p}{)}
\PYG{n}{q\PYGZus{}m}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
48.0000000000000
\end{sphinxVerbatim}

\sphinxAtStartPar
The monopoly price \(p_m\) is the price from the market demand curve that this level of output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Q} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Q}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{P} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{o}{.}\PYG{l+m+mi}{05} \PYG{o}{*} \PYG{n}{Q} \PYG{o}{+} \PYG{l+m+mf}{5.05}

\PYG{n}{p\PYGZus{}m} \PYG{o}{=} \PYG{n}{P}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{Q}\PYG{p}{,} \PYG{n}{q\PYGZus{}m}\PYG{p}{)}
\PYG{n}{p\PYGZus{}m}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
2.65000000000000
\end{sphinxVerbatim}

\sphinxAtStartPar
Now that we have found \(p_m\), we can use this to construct Coke’s reaction function \(p'_1(p_2)\) to Pepsi’s choice of price. Assuming Coke selects \(h=0.1\) (that is, Coke will sell at \$0.10 below Pepsi as long as they operate at a profit), the formula for \(p'_1\) is
\begin{equation*}
\begin{split}
p'_1(p_2) = \begin{cases}
0.25 & \text{if } p_2 < 0.25 + 0.1 \\
p_2 - 0.1 & \text{if } 0.25 + 0.1 \le p_2 < 2.65 + 0.1 \\
2.65 & \text{otherwise}
\end{cases}
\end{split}
\end{equation*}
\noindent\sphinxincludegraphics{{bertrand_15_0}.png}

\sphinxAtStartPar
Finally, to find Coke’s selling price, we find \(p'_1(1)\), since Coke believes Pepsi will sell at \$1.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{c} \PYG{o}{=} \PYG{l+m+mf}{0.25}
\PYG{n}{h} \PYG{o}{=} \PYG{l+m+mf}{0.1}
\PYG{n}{p\PYGZus{}2} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{p\PYGZus{}2}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{p\PYGZus{}1\PYGZus{}prime} \PYG{o}{=} \PYG{n}{sympy}\PYG{o}{.}\PYG{n}{Piecewise}\PYG{p}{(}
    \PYG{p}{(}\PYG{n}{c}\PYG{p}{,} \PYG{n}{p\PYGZus{}2} \PYG{o}{\PYGZlt{}} \PYG{n}{c} \PYG{o}{+} \PYG{n}{h}\PYG{p}{)}\PYG{p}{,}
    \PYG{p}{(}\PYG{n}{p\PYGZus{}2} \PYG{o}{\PYGZhy{}} \PYG{n}{h}\PYG{p}{,} \PYG{n}{p\PYGZus{}2} \PYG{o}{\PYGZlt{}} \PYG{n}{p\PYGZus{}m} \PYG{o}{+} \PYG{n}{h}\PYG{p}{)}\PYG{p}{,}
    \PYG{p}{(}\PYG{n}{p\PYGZus{}m}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{p}{)}

\PYG{n}{p\PYGZus{}1\PYGZus{}prime}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{p\PYGZus{}2}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
0.900000000000000
\end{sphinxVerbatim}

\sphinxAtStartPar
Thus, if Coke believes that Pepsi will sell cans at \$1, it should sell at \$0.90. This should make intuitive sense: we showed that \(p'_1(p_2)\) was below the line \(p_1=p_2\) by a vertical distance of \(h=0.1\), so it makes sense that Coke would sell at \$0.10 below Pepsi. If Coke had believed that Pepsi was going to sell at, say, \$2.70, then it would have been better for them to sell at the monopoly price level \(p_m = 2.65\). If Pepsi was selling below margin cost, at \$0.20 maybe, then Coke’s best bet would have been to sell at \(c = 0.25\), although they would have sold 0 units of output because consumers buy from the lowest\sphinxhyphen{}priced vendor.


\subsection{Python Classes}
\label{\detokenize{content/07-game-theory/python-classes:python-classes}}\label{\detokenize{content/07-game-theory/python-classes::doc}}
\sphinxAtStartPar
Because Python is an \sphinxhref{https://en.wikipedia.org/wiki/Object-oriented\_programming}{\sphinxstylestrong{object\sphinxhyphen{}oriented} programming language}, you can create custom structures for storing data and methods called \sphinxstylestrong{classes}. A class represents an object and stores variables related to and functions that operate on that object. You’re already familiar with Python classes, even if you don’t know it: the \sphinxcode{\sphinxupquote{Table}}s you work with in Data 8 are Python classes, as are NumPy arrays.

\sphinxAtStartPar
We use classes because they allow us to store data in a rigorously structured way and provide standardized methods of accessing and interacting with that data. For example, let’s say you want to create a program that manages a person’s banking information. You need to store their name, account number, and balance. You might do something like create an array for each individual, where the first element is their name, the second is their account number, and the third is their balance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{account1} \PYG{o}{=} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Jane Doe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{123456}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{)}
\PYG{n}{account2} \PYG{o}{=} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{John Doe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{234567}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
But what happens if you need to track more data? Or suppose the structure of this data changes? Then you need to go to \sphinxstyleemphasis{every} place where you access an element of the array and update it! It’s really easy to forget things like this or to have instances fall through the cracks. Instead, we might create an \sphinxcode{\sphinxupquote{Account}} class, so that whenever we need to update the structure, we need only do so once. (This is a very simplified version of a complex topic called \sphinxhref{http://composingprograms.com/pages/22-data-abstraction.html}{data abstraction} that demonstrates the need for complex, templated data structures and methods of accessing their data without violating \sphinxhref{http://composingprograms.com/pages/22-data-abstraction.html\#abstraction-barriers}{abstraction barriers}.)

\sphinxAtStartPar
Some terminology: a \sphinxstylestrong{class} is the abstract definition of one such data structure, the definition from which class instances are created. When refer to an \sphinxstylestrong{instance}, we mean a single copy of one of these objects. It’s kind\sphinxhyphen{}of like cookies and cookie cutters: the class is the cookie cutter, the template from which we make instances, the cookies. Think about tables: \sphinxcode{\sphinxupquote{Table}} is the class from which we create table instances:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Table} \PYG{c+c1}{\PYGZsh{} this is the class}
\PYG{n}{tbl} \PYG{o}{=} \PYG{n}{Table}\PYG{p}{(}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} this is an instance}
\end{sphinxVerbatim}

\sphinxAtStartPar
Instances are created by calling the \sphinxstylestrong{constructor} (more below) as if it were a function (e.g. \sphinxcode{\sphinxupquote{Table()}}).


\subsubsection{Creating Instances}
\label{\detokenize{content/07-game-theory/python-classes:creating-instances}}
\sphinxAtStartPar
Classes can be created using a \sphinxcode{\sphinxupquote{class}} statement. Inside the statement, you put the variables and methods that define the class. The first and most important of these methods is the \sphinxcode{\sphinxupquote{\_\_init\_\_}} method which is called when an instance of a class is created. \sphinxcode{\sphinxupquote{\_\_init\_\_}} is an example of Python’s \sphinxhref{https://www.geeksforgeeks.org/dunder-magic-methods-python/}{dunder (double\sphinxhyphen{}underscore) methods}, which are used to allow classes to interact with built\sphinxhyphen{}in functions and operators.

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{\_\_init\_\_}} method should take any arguments needed for the class and create all of the \sphinxstyleemphasis{instance variables} that the instance tracks. Consider the \sphinxcode{\sphinxupquote{Car}} class:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{class} \PYG{n+nc}{Car}\PYG{p}{:}
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{make}\PYG{p}{,} \PYG{n}{model}\PYG{p}{,} \PYG{n}{year}\PYG{p}{,} \PYG{n}{color}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{=} \PYG{n}{make}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model} \PYG{o}{=} \PYG{n}{model}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year} \PYG{o}{=} \PYG{n}{year}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{=} \PYG{n}{color}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note that the first argument to the \sphinxcode{\sphinxupquote{\_\_init\_\_}} method is a variable called \sphinxcode{\sphinxupquote{self}}; this argument will be filled by Python with the instance of class that is being called. For example, when we call an instance’s \sphinxstylestrong{method} (a function included in the class), we might have something like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{class} \PYG{n+nc}{Foo}\PYG{p}{:}
    \PYG{k}{def} \PYG{n+nf}{bar}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{return} \PYG{k+kc}{None}

\PYG{n}{foo} \PYG{o}{=} \PYG{n}{Foo}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{foo}\PYG{o}{.}\PYG{n}{bar}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
When we run \sphinxcode{\sphinxupquote{foo.bar()}}, the function \sphinxcode{\sphinxupquote{Foo.bar}} is called and the first argument (\sphinxcode{\sphinxupquote{self}}) is filled with the instance \sphinxcode{\sphinxupquote{foo}}.

\sphinxAtStartPar
In the \sphinxcode{\sphinxupquote{\_\_init\_\_}} method (or any method, for that matter), we create instance variables (variables tied to a single instance of a class) using \sphinxcode{\sphinxupquote{<instance>.<variable name>}} syntax, e.g.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{some\PYGZus{}variable} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some value}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\sphinxAtStartPar
If we’re outside of a method, we can use the same syntax using the variable name:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{foo}\PYG{o}{.}\PYG{n}{some\PYGZus{}variable} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some value}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\sphinxAtStartPar
When you create a \sphinxcode{\sphinxupquote{Car}}, \sphinxcode{\sphinxupquote{Car.\_\_init\_\_}} is called by Python. We can create a \sphinxcode{\sphinxupquote{Car}} and access the values of its instance variables using the dot syntax.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{car} \PYG{o}{=} \PYG{n}{Car}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Honda}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Civic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{2018}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{blue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{car}\PYG{o}{.}\PYG{n}{make}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsq{}Honda\PYGZsq{}
\end{sphinxVerbatim}


\subsubsection{Class Representations}
\label{\detokenize{content/07-game-theory/python-classes:class-representations}}
\sphinxAtStartPar
Now let’s see what our \sphinxcode{\sphinxupquote{car}} object (an instance of the \sphinxcode{\sphinxupquote{Car}} class) looks like.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{car}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}\PYGZus{}\PYGZus{}main\PYGZus{}\PYGZus{}.Car at 0x10848c358\PYGZgt{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Hmm, that representation isn’t very descriptive. Another dunder method of Python’s is \sphinxcode{\sphinxupquote{\_\_repr\_\_}}, which defines a string representation of an object. Let’s define one for our \sphinxcode{\sphinxupquote{Car}} class.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{class} \PYG{n+nc}{Car}\PYG{p}{:}
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{make}\PYG{p}{,} \PYG{n}{model}\PYG{p}{,} \PYG{n}{year}\PYG{p}{,} \PYG{n}{color}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{=} \PYG{n}{make}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model} \PYG{o}{=} \PYG{n}{model}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year} \PYG{o}{=} \PYG{n}{year}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{=} \PYG{n}{color}
        
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}repr\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{return} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{+} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{+} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year}\PYG{p}{)} \PYG{o}{+} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{+}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{+} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{+} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model}
\end{sphinxVerbatim}

\sphinxAtStartPar
Now that we have defined \sphinxcode{\sphinxupquote{Car.\_\_repr\_\_}}, we can get a nicer representation of \sphinxcode{\sphinxupquote{car}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{car} \PYG{o}{=} \PYG{n}{Car}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Honda}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Civic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{2018}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{blue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{car}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
blue 2018 Honda Civic
\end{sphinxVerbatim}


\subsubsection{Operators}
\label{\detokenize{content/07-game-theory/python-classes:operators}}
\sphinxAtStartPar
Now let’s create two of the same cars and compare them. They should be equal, right…?

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{car\PYGZus{}1} \PYG{o}{=} \PYG{n}{Car}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Honda}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Civic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{2018}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{blue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{car\PYGZus{}2} \PYG{o}{=} \PYG{n}{Car}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Honda}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Civic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{2018}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{blue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{car\PYGZus{}1} \PYG{o}{==} \PYG{n}{car\PYGZus{}2}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
False
\end{sphinxVerbatim}

\sphinxAtStartPar
They aren’t equal! That’s because, by default, the custom classes are only equal if they are the \sphinxstyleemphasis{same instance}, so \sphinxcode{\sphinxupquote{car\_1 == car\_1}} is \sphinxcode{\sphinxupquote{True}} but \sphinxcode{\sphinxupquote{car\_1 == car\_2}} is \sphinxcode{\sphinxupquote{False}}. For this reason, we need to define the \sphinxcode{\sphinxupquote{\_\_eq\_\_}} dunder method of \sphinxcode{\sphinxupquote{Car}} which Python will call when we use the \sphinxcode{\sphinxupquote{==}} operator on a \sphinxcode{\sphinxupquote{Car}}. We’ll say and object is equal to a \sphinxcode{\sphinxupquote{Car}} if the other object is also a \sphinxcode{\sphinxupquote{Car}} (determined using the \sphinxcode{\sphinxupquote{isinstance}} function) and has the same four attributes as the current car.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{class} \PYG{n+nc}{Car}\PYG{p}{:}
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{make}\PYG{p}{,} \PYG{n}{model}\PYG{p}{,} \PYG{n}{year}\PYG{p}{,} \PYG{n}{color}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{=} \PYG{n}{make}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model} \PYG{o}{=} \PYG{n}{model}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year} \PYG{o}{=} \PYG{n}{year}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{=} \PYG{n}{color}
        
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}repr\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{return} \PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}
    
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}eq\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{other}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{if} \PYG{n+nb}{isinstance}\PYG{p}{(}\PYG{n}{other}\PYG{p}{,} \PYG{n}{Car}\PYG{p}{)}\PYG{p}{:}
            \PYG{k}{return} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{make} \PYG{o+ow}{and} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{model} \PYG{o+ow}{and} \PYGZbs{}
                \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{year} \PYG{o+ow}{and} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{color}
        \PYG{k}{return} \PYG{k+kc}{False}        
\end{sphinxVerbatim}

\sphinxAtStartPar
Now our call from above will work:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{car\PYGZus{}1} \PYG{o}{=} \PYG{n}{Car}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Honda}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Civic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{2018}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{blue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{car\PYGZus{}2} \PYG{o}{=} \PYG{n}{Car}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Honda}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Civic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{2018}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{blue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{car\PYGZus{}1} \PYG{o}{==} \PYG{n}{car\PYGZus{}2}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
True
\end{sphinxVerbatim}

\sphinxAtStartPar
Other important dunder methods include


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
Method Name
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Description
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\_\_str\_\_}}
&
\sphinxAtStartPar
the string representation of an object
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\_\_len\_\_}}
&
\sphinxAtStartPar
length of an object (\sphinxcode{\sphinxupquote{len(obj)}}
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\_\_lt\_\_}}, \sphinxcode{\sphinxupquote{\_\_gt\_\_}}, \sphinxcode{\sphinxupquote{\_\_lte\_\_}}, \sphinxcode{\sphinxupquote{\_\_gte\_\_}}
&
\sphinxAtStartPar
less than, greater than, less than or equal to, and greater than or equal to operators, resp.
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\_\_hash\_\_}}
&
\sphinxAtStartPar
\sphinxhref{https://en.wikipedia.org/wiki/Hash\_function}{hash function} value (\sphinxcode{\sphinxupquote{hash(obj)}})
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\_\_getitem\_\_}}, \sphinxcode{\sphinxupquote{\_\_setitem\_\_}}
&
\sphinxAtStartPar
getter and setter (resp.) for indexes (\sphinxcode{\sphinxupquote{obj{[}idx{]}}})
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\_\_getattr\_\_}}, \sphinxcode{\sphinxupquote{\_\_setattr\_\_}}
&
\sphinxAtStartPar
getter and setter (resp.) for dot syntax (\sphinxcode{\sphinxupquote{obj.attr}})
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Note that when using comparison operators the object to the \sphinxstylestrong{left} of the operator has its comparison operator method called. In the below example, the first comparison calls \sphinxcode{\sphinxupquote{point\_1.\_\_lt\_\_}} and the second calls \sphinxcode{\sphinxupquote{point\_2.\_\_lt\_\_}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{point\PYGZus{}1} \PYG{o}{=} \PYG{n}{Point}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{point\PYGZus{}2} \PYG{o}{=} \PYG{n}{Point}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{point\PYGZus{}1} \PYG{o}{\PYGZlt{}} \PYG{n}{point\PYGZus{}2}      \PYG{c+c1}{\PYGZsh{} calls point\PYGZus{}1.\PYGZus{}\PYGZus{}lt\PYGZus{}\PYGZus{}}
\PYG{n}{point\PYGZus{}2} \PYG{o}{\PYGZlt{}} \PYG{n}{point\PYGZus{}1}      \PYG{c+c1}{\PYGZsh{} calls point\PYGZus{}2.\PYGZus{}\PYGZus{}lt\PYGZus{}\PYGZus{}}
\end{sphinxVerbatim}


\subsubsection{Instance Methods}
\label{\detokenize{content/07-game-theory/python-classes:instance-methods}}
\sphinxAtStartPar
Now let’s define some methods for a \sphinxcode{\sphinxupquote{Car}}. We’ll add a few more instance variables:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{car.mileage}} is the number of miles driven by the car

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{car.gas}} is number of gallons of gas in the tank

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{car.mpg}} is the number of miles to a gallon that the car gets.

\end{itemize}

\sphinxAtStartPar
Note that \sphinxcode{\sphinxupquote{car.mileage}} and \sphinxcode{\sphinxupquote{car.gas}} are initialized to 0 when we create the car in \sphinxcode{\sphinxupquote{\_\_init\_\_}}. We’ll first define the \sphinxcode{\sphinxupquote{fill\_tank}} method, which fills the gas tank to 10 gallons.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{class} \PYG{n+nc}{Car}\PYG{p}{:}
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{make}\PYG{p}{,} \PYG{n}{model}\PYG{p}{,} \PYG{n}{year}\PYG{p}{,} \PYG{n}{color}\PYG{p}{,} \PYG{n}{mpg}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{=} \PYG{n}{make}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model} \PYG{o}{=} \PYG{n}{model}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year} \PYG{o}{=} \PYG{n}{year}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{=} \PYG{n}{color}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mpg} \PYG{o}{=} \PYG{n}{mpg}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mileage} \PYG{o}{=}  \PYG{l+m+mi}{0}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{=} \PYG{l+m+mi}{0}
        
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}repr\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{return} \PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}
    
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}eq\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{other}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{if} \PYG{n+nb}{isinstance}\PYG{p}{(}\PYG{n}{other}\PYG{p}{,} \PYG{n}{Car}\PYG{p}{)}\PYG{p}{:}
            \PYG{k}{return} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{make} \PYG{o+ow}{and} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{model} \PYG{o+ow}{and} \PYGZbs{}
                \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{year} \PYG{o+ow}{and} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{color}
        \PYG{k}{return} \PYG{k+kc}{False}
    
    \PYG{k}{def} \PYG{n+nf}{fill\PYGZus{}tank}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{=} \PYG{l+m+mi}{10}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can create a car and fill its take by calling \sphinxcode{\sphinxupquote{car.fill\_tank}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{car} \PYG{o}{=} \PYG{n}{Car}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Honda}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Civic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{2018}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{blue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{18}\PYG{p}{)}
\PYG{n}{car}\PYG{o}{.}\PYG{n}{fill\PYGZus{}tank}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{car}\PYG{o}{.}\PYG{n}{gas}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
10
\end{sphinxVerbatim}


\paragraph{Assertions}
\label{\detokenize{content/07-game-theory/python-classes:assertions}}
\sphinxAtStartPar
Now we’ll define the \sphinxcode{\sphinxupquote{car.drive}} method that drives \sphinxcode{\sphinxupquote{miles}} miles and ensures that we have enough gas to drive that far by throwing an \sphinxcode{\sphinxupquote{AssertionError}} if we don’t.

\sphinxAtStartPar
We throw assertion errors using an \sphinxcode{\sphinxupquote{assert}} statement which takes two arguments: a boolean expression and a string telling the user what caused the error. For example, if we want to make sure that a string has no spaces, we might write

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{assert} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{not} \PYG{o+ow}{in} \PYG{n}{string}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Spaces found in string}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\sphinxAtStartPar
Then, if \sphinxcode{\sphinxupquote{string}} has a space, the user would see:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{string} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some string}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{k}{assert} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{not} \PYG{o+ow}{in} \PYG{n}{string}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Spaces found in string}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{AssertionError}\PYG{g+gWhitespace}{                            }Traceback (most recent call last)
\PYG{n+nn}{\PYGZlt{}ipython\PYGZhy{}input\PYGZhy{}20\PYGZhy{}18b8ef0eb9ac\PYGZgt{}} in \PYG{n+ni}{\PYGZlt{}module\PYGZgt{}}\PYG{n+nt}{()}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{1} \PYG{n}{string} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some string}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{2} \PYG{k}{assert} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{not} \PYG{o+ow}{in} \PYG{n}{string}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Spaces found in string}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{n+ne}{AssertionError}: Spaces found in string
\end{sphinxVerbatim}


\paragraph{Reassignment Operators}
\label{\detokenize{content/07-game-theory/python-classes:reassignment-operators}}
\sphinxAtStartPar
Another new syntax needed for the \sphinxcode{\sphinxupquote{Car.drive}} method is \sphinxcode{\sphinxupquote{+=}} and \sphinxcode{\sphinxupquote{\sphinxhyphen{}=}}. An operator followed by \sphinxcode{\sphinxupquote{=}} tells Python to perform the operation combining the values on the left and right sides of the operator and then reassigns this value to the variable on the left side. This means that the expression \sphinxcode{\sphinxupquote{x += 2}} is the exact same as \sphinxcode{\sphinxupquote{x = x + 2}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{x} \PYG{o}{=} \PYG{l+m+mi}{2}

\PYG{n}{x} \PYG{o}{+}\PYG{o}{=} \PYG{l+m+mi}{1}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} x is now 3}

\PYG{n}{x} \PYG{o}{\PYGZhy{}}\PYG{o}{=} \PYG{l+m+mi}{4}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} x is now \PYGZhy{}1}

\PYG{n}{x} \PYG{o}{*}\PYG{o}{=} \PYG{l+m+mi}{100}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} x is now \PYGZhy{}100}

\PYG{n}{x} \PYG{o}{/}\PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{100}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} x is now 1}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
3
\PYGZhy{}1
\PYGZhy{}100
1.0
\end{sphinxVerbatim}

\sphinxAtStartPar
Now let’s define \sphinxcode{\sphinxupquote{Car.drive}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{class} \PYG{n+nc}{Car}\PYG{p}{:}
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{make}\PYG{p}{,} \PYG{n}{model}\PYG{p}{,} \PYG{n}{year}\PYG{p}{,} \PYG{n}{color}\PYG{p}{,} \PYG{n}{mpg}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{=} \PYG{n}{make}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model} \PYG{o}{=} \PYG{n}{model}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year} \PYG{o}{=} \PYG{n}{year}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{=} \PYG{n}{color}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mpg} \PYG{o}{=} \PYG{n}{mpg}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mileage} \PYG{o}{=}  \PYG{l+m+mi}{0}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{=} \PYG{l+m+mi}{0}
        
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}repr\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{return} \PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}
    
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}eq\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{other}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{if} \PYG{n+nb}{isinstance}\PYG{p}{(}\PYG{n}{other}\PYG{p}{,} \PYG{n}{Car}\PYG{p}{)}\PYG{p}{:}
            \PYG{k}{return} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{make} \PYG{o+ow}{and} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{model} \PYG{o+ow}{and} \PYGZbs{}
                \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{year} \PYG{o+ow}{and} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{color}
        \PYG{k}{return} \PYG{k+kc}{False}
    
    \PYG{k}{def} \PYG{n+nf}{fill\PYGZus{}tank}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{=} \PYG{l+m+mi}{10}
        
    \PYG{k}{def} \PYG{n+nf}{drive}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{miles}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{assert} \PYG{n}{miles} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{*} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mpg}\PYG{p}{,} \PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not enough gas to drive }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{miles}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ miles}\PYG{l+s+s2}{\PYGZdq{}}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mileage} \PYG{o}{+}\PYG{o}{=} \PYG{n}{miles}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{\PYGZhy{}}\PYG{o}{=} \PYG{n}{miles} \PYG{o}{/} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mpg}
\end{sphinxVerbatim}

\sphinxAtStartPar
Let’s drive our \sphinxcode{\sphinxupquote{Car}} 100 miles.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{car} \PYG{o}{=} \PYG{n}{Car}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Honda}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Civic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{2018}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{blue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{18}\PYG{p}{)}
\PYG{n}{car}\PYG{o}{.}\PYG{n}{fill\PYGZus{}tank}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{car}\PYG{o}{.}\PYG{n}{drive}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{)}
\PYG{n}{car}\PYG{o}{.}\PYG{n}{mileage}\PYG{p}{,} \PYG{n}{car}\PYG{o}{.}\PYG{n}{gas}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(100, 4.444444444444445)
\end{sphinxVerbatim}

\sphinxAtStartPar
Now let’s see how many miles we have left to drive by defining \sphinxcode{\sphinxupquote{Car.miles\_to\_empty}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{class} \PYG{n+nc}{Car}\PYG{p}{:}
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{make}\PYG{p}{,} \PYG{n}{model}\PYG{p}{,} \PYG{n}{year}\PYG{p}{,} \PYG{n}{color}\PYG{p}{,} \PYG{n}{mpg}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{=} \PYG{n}{make}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model} \PYG{o}{=} \PYG{n}{model}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year} \PYG{o}{=} \PYG{n}{year}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{=} \PYG{n}{color}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mpg} \PYG{o}{=} \PYG{n}{mpg}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mileage} \PYG{o}{=}  \PYG{l+m+mi}{0}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{=} \PYG{l+m+mi}{0}
        
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}repr\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{return} \PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}
    
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}eq\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{other}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{if} \PYG{n+nb}{isinstance}\PYG{p}{(}\PYG{n}{other}\PYG{p}{,} \PYG{n}{Car}\PYG{p}{)}\PYG{p}{:}
            \PYG{k}{return} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{make} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{make} \PYG{o+ow}{and} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{model} \PYG{o+ow}{and} \PYGZbs{}
                \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{year} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{year} \PYG{o+ow}{and} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{color} \PYG{o}{==} \PYG{n}{other}\PYG{o}{.}\PYG{n}{color}
        \PYG{k}{return} \PYG{k+kc}{False}
    
    \PYG{k}{def} \PYG{n+nf}{fill\PYGZus{}tank}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{=} \PYG{l+m+mi}{10}
        
    \PYG{k}{def} \PYG{n+nf}{drive}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{miles}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{assert} \PYG{n}{miles} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{*} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mpg}\PYG{p}{,} \PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not enough gas to drive }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mileage}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ miles}\PYG{l+s+s2}{\PYGZdq{}}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mileage} \PYG{o}{+}\PYG{o}{=} \PYG{n}{miles}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{\PYGZhy{}}\PYG{o}{=} \PYG{n}{miles} \PYG{o}{/} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mpg}
        
    \PYG{k}{def} \PYG{n+nf}{miles\PYGZus{}to\PYGZus{}empty}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{return} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{*} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mpg}
    
\PYG{n}{car} \PYG{o}{=} \PYG{n}{Car}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Honda}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Civic}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{2018}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{blue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{18}\PYG{p}{)}
\PYG{n}{car}\PYG{o}{.}\PYG{n}{fill\PYGZus{}tank}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{car}\PYG{o}{.}\PYG{n}{drive}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{)}
\PYG{n}{car}\PYG{o}{.}\PYG{n}{miles\PYGZus{}to\PYGZus{}empty}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
80.0
\end{sphinxVerbatim}

\sphinxAtStartPar
We have 80 miles left before we’re empty, so we see that if we try to drive 90 miles, the car will thrown an error:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{car}\PYG{o}{.}\PYG{n}{drive}\PYG{p}{(}\PYG{l+m+mi}{90}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{AssertionError}\PYG{g+gWhitespace}{                            }Traceback (most recent call last)
\PYG{n+nn}{\PYGZlt{}ipython\PYGZhy{}input\PYGZhy{}25\PYGZhy{}8ae22d6f2de2\PYGZgt{}} in \PYG{n+ni}{\PYGZlt{}module\PYGZgt{}}\PYG{n+nt}{()}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{1} \PYG{n}{car}\PYG{o}{.}\PYG{n}{drive}\PYG{p}{(}\PYG{l+m+mi}{90}\PYG{p}{)}

\PYG{n+nn}{\PYGZlt{}ipython\PYGZhy{}input\PYGZhy{}24\PYGZhy{}e4c645b85ba9\PYGZgt{}} in \PYG{n+ni}{drive}\PYG{n+nt}{(self, miles)}
\PYG{g+gWhitespace}{     }\PYG{l+m+mi}{21} 
\PYG{g+gWhitespace}{     }\PYG{l+m+mi}{22}     \PYG{k}{def} \PYG{n+nf}{drive}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{miles}\PYG{p}{)}\PYG{p}{:}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{23}         \PYG{k}{assert} \PYG{n}{miles} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{*} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mpg}\PYG{p}{,} \PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not enough gas to drive }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mileage}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ miles}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gWhitespace}{     }\PYG{l+m+mi}{24}         \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mileage} \PYG{o}{+}\PYG{o}{=} \PYG{n}{miles}
\PYG{g+gWhitespace}{     }\PYG{l+m+mi}{25}         \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{gas} \PYG{o}{\PYGZhy{}}\PYG{o}{=} \PYG{n}{miles} \PYG{o}{/} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{mpg}

\PYG{n+ne}{AssertionError}: not enough gas to drive 100 miles
\end{sphinxVerbatim}

\sphinxAtStartPar
For more information on Python classes, check out \sphinxhref{http://composingprograms.com/pages/25-object-oriented-programming.html}{Sections 2.5\sphinxhyphen{}2.7 of Composing Programs}, the CS 61A/CS 88 textbook.


\section{Development}
\label{\detokenize{content/08-development/index:development}}\label{\detokenize{content/08-development/index::doc}}
\sphinxAtStartPar
A fundamental aspect of inferential thinking and statistical measurement is how to design experiments in order to be measuring causation instead of correlation. An intervention can be thought of as some sort of change that is thought to bring about some desired outcome.   Correlation between two measurements can be due to many underlying factors besides the intervention being studied.  A properly designed experiment can isolate the effect of the intervention being studied.

\sphinxAtStartPar
The main idea is to take an overall population, create two subsets and randomly assign which of the subsets of the population gets an intervention (called \sphinxstyleemphasis{treatment}) and another subset who does not get an intervention ( called \sphinxstyleemphasis{control}).  The population can be studied before and after an intervention is rolled out. The application of this methodology in Development Economics has caused a revolution in how the field measures the impacts of different development interventions.

\sphinxAtStartPar
Historically many of the early statistical models came from agriculture, where a scientist might be looking to increase the yield of a crop being planted. The experiment might be to plant two fields side by side with the same seeds, but one field gets two times the fertilizer of the second field. The amount that the yield increases due to fertilizer can be measured by the yield on the treated field (more fertilizer) minus the yield on the control field with baseline fertilizer.  (\sphinxstyleemphasis{And an economist would then balance the cost of the extra fertilizer against the revenue from the additional crop yield})

\sphinxAtStartPar
More recently, most people are familiar with drug trials, where new medicines are evaluated using an experimental design. In 2020 the whole world waited for the results of randomized controlled trials of the COVID\sphinxhyphen{}19 vaccines to be carried out before the vaccines could be used.  In these trials, 30,000 \sphinxhyphen{} 40,000 volunteers were recruited from a diverse set of ages and ethnicities and randomized into two groups, treatment and control. In the treatment groups the volunteers received the vaccine, in the control groups the volunteers received an injection of a neutral saline solution.  The study continued until a certain number of people in the control group had gotten COVID\sphinxhyphen{}19, and the number of people in the two study arms were compared.

\sphinxAtStartPar
In the current construction of the internet as we use it, A/B testing is a very common tool for UX design, and a very common work for data scientists working in internet companies.  Every time you surf the web or visit an internet site you may be unknowingly part of a test of the size or color of a button, flow of the page, or other details. The internet companies constantly divide site visitors into treatment and control groups and measure site engagement metrics to calibrate changes to their site.  A manager of any site, no matter how small, has tools such as Google Analytics that can allow them to measure changes in site design on user interaction metrics.

\sphinxAtStartPar
In the world of Development Economics, this has taken the form of evaluating interventions that are usually aimed at reducing poverty, or improving health and education outcomes. This field is generally called Randomized Controlled Trials (RCTs), or also sometimes Impact Evaluation.  In many cases these are pilot programs for new interventions that can be measured well in a pilot case, and if measured well and a strong effect is found, can be used as evidence to make the case for a broader rollout. In many cases the pilot study may only have resources to provide the intervention to a subset of the overall population and this could lead naturally to a control subset and treatment subset, where the control subset will eventually get the treatment in future time periods.

\sphinxAtStartPar
Some examples of treatments that were tested out in pilot RCT are:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Malaria bednets to reduce childhood malaria

\item {} 
\sphinxAtStartPar
Household water treatment to reduce child diarrhea

\item {} 
\sphinxAtStartPar
Clean cooking stoves to reduce child respiratory illness

\item {} 
\sphinxAtStartPar
Conditional payments to incentivize health clinic visits

\item {} 
\sphinxAtStartPar
Payments for completion of school to incentivize girls schooling

\end{itemize}

\sphinxAtStartPar
In each of these we can think of reasons that randomization can be needed to screen out confounding factors. For example if malaria bednets were just sold at the store, it might be households with more wealth, more connected with social capital, or more education who might be the ones to purchase and use them.  These \sphinxstyleemphasis{confounding factors} would make it hard for researchers to know what the effect of bednets were alone.

\sphinxAtStartPar
\sphinxhref{http://emiguel.econ.berkeley.edu/research/worms-identifying-impacts-on-education-and-health-in-the-presence-of-treatment-externalities}{One seminal RCT was a study of deworming} \sphinxhyphen{} giving out an anti\sphinxhyphen{}helminthic pill to kill intestinal parasites \sphinxhyphen{} to primary school children in Rural Kenya.  This study was carried out to help a local non\sphinxhyphen{}profit that was working on increasing the rate of primary school attendance where there was high absenteeism due to childhood illness.  The economics professors who carried this study out (and actually continue to carry it out) are Edward Miguel and Michael Kremer.  Edward Miguel is now a Professor at UC Berkeley who teaches the Economics of Development Course (ECON 172) and Michael Kremer, Miguel’s PhD thesis advisor at Harvard, won the Nobel Prize for Economics in 2019.  The randomization of populations was more elaborate than just two groups and the comparison of students who got the deworming pill and who did not showed positive health  and school attendance effects not just for the students who got it, but also for students at the same school who didn’t get it and students who just happened to live in nearby villages to where the deworming was carried out.   The researchers were also able to carefully document these effects using the correct study design and thus argue for the expansion of the program, which has since been carried out nationally in Kenya and in \sphinxhref{https://www.evidenceaction.org/dewormtheworld/}{several other countries with high parasite burden} “with over 1 billion treatments delivered since 2014 and 280 million treatments in 2019”

\sphinxAtStartPar
The researchers involve in this seminal study later moved on to study other interventions that could reduce the burden of childhood diseases by focusing on water\sphinxhyphen{}borne diseases such as diarrhea.  Water\sphinxhyphen{}borne diarrhea is a leading cause of mortality in sub\sphinxhyphen{}Saharan Africa but is fatal primarily in infants under 5 years old. So the target of these studies was measuring health outcomes in children under 5.  These interventions included the protection of water sources, \sphinxstyleemphasis{\sphinxhref{http://emiguel.econ.berkeley.edu/research/spring-cleaning-rural-water-impacts-valuation-and-property-rights-institutions}{Spring Protection}},  and the \sphinxhref{http://emiguel.econ.berkeley.edu/research/social-engineering-evidence-from-a-suite-of-take-up-experiments-in-kenya}{promotion of the household use of Chlorine}, sold in Kenya as \sphinxstyleemphasis{Water Guard} to purify drinking water.  A subset of this study is the focus of this week’s lab.

\sphinxAtStartPar
The pedagogical purpose of this week’s lab is also for students to think about the process that goes on behind the scenes of an economics journal article. The researchers work with the local NGO to map a set of villages where Spring Protection or Water Guard Promotion are going to be carried out. The populations are divided into a control arm, which will get the intervention in a future time period, and a set of comparable populations who get different treatment interventions, or even combinations of interventions.  The NGO employs surveyors, who visit the households at baseline, before the intervention begins, and at various intervals later on after the intervention has been deployed.  This household survey data is used to create a data set that is used to measure the effects of the intervention.


\section{Macroeconomic Policy}
\label{\detokenize{content/09-macro/index:macroeconomic-policy}}\label{\detokenize{content/09-macro/index::doc}}

\subsection{Macroeconomic Indicators}
\label{\detokenize{content/09-macro/MacroChapter:macroeconomic-indicators}}\label{\detokenize{content/09-macro/MacroChapter::doc}}
\sphinxAtStartPar
The process of conducting macroeconomic policy often starts with studying and projecting the behavior of a variety of indicators that provide some information about the economy’s current or expected future performance. While there are many different variables one could look to depending on the interests and goals of the individual(s) or institution(s) involved, in this chapter we will focus specifically on four main indicators that tend to play a critical role in many policy decisions.


\subsubsection{GDP (\protect\(Y\protect\))}
\label{\detokenize{content/09-macro/MacroChapter:gdp-y}}
\sphinxAtStartPar
Earlier, when studying Production, we introduced the concept of GDP briefly. To recap, we looked at how GDP aims to capture a country’s overall production over a given period of time. In theory it can then be used as a way to measure a country’s economic performance in a given quarter or year; the higher its GDP, the more that it’s produced, the better it’s doing economically, and vice versa. In this chapter, we’ll go into more detail on its significance and how it’s measured. By definition, GDP, often denoted as \(Y\), is measured as the:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{market value} of

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{final} goods and services

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{newly produced}

\item {} 
\sphinxAtStartPar
in the \sphinxstylestrong{domestic economy}

\item {} 
\sphinxAtStartPar
over a \sphinxstylestrong{specified period of time}

\end{enumerate}

\sphinxAtStartPar
Let’s dive into each of these individually:

\sphinxAtStartPar
First, the \sphinxstylestrong{market value} refers to the market price of price goods and services, which sets a standard for how we value goods and services. This is especially useful when we are trying to add together products that may be quite different from one another.

\sphinxAtStartPar
Second, \sphinxstylestrong{final goods and services} refers to those which \sphinxstyleemphasis{are not} used up in the production process. We only consider these in our calculation of GDP, because we don’t want to end up overrepresenting the overall level of production. Intermediate goods, which \sphinxstyleemphasis{are} used up in the production process, inherently add some value to the final product, and therefore if we were to consider these in our calculation, we would end up overstating the level of production.

\sphinxAtStartPar
Third, \sphinxstylestrong{newly produced} tells us that we are only interested in goods and services that were made during the time period we are looking at. Since we are using GDP as a way to measure the level of production in the economy, it wouldn’t really make a whole lot of sense to include products that were produced outside the time period that we are looking at in our calculation.

\sphinxAtStartPar
Fourth, \sphinxstylestrong{in the domestic economy} refers to the fact that in our calculation of GDP we only include goods and services that were produced within the geographical area of the country that we are looking at. Given that we are trying to measure the  level of production of a certain country, it makes sense that we wouldn’t want to consider products or services that are produced outside of the country in our calculation.

\sphinxAtStartPar
Lastly, \sphinxstylestrong{over a specified period of time} simply points out that GDP is measured as a unit of time. This is important to consider when comparing countries based on their GDP, as we would want to make sure to consider the same time period for all of them.

\sphinxAtStartPar
The above definition and approach to calculating GDP considers the production of goods and services in the economy. However, it’s important to note that GDP can also be calculated by looking at the total spending on those goods and services or total income earned from producing those goods and services. You may recall that in our discussion on Production, we often referred to output and income synonomously. This is because in theory, each of these approaches to calculating GDP (production, expenditure, and income) should all yield the same result, and indeed we find that for the most part they do. While we won’t go into detail on the income approach to calculating GDP, we will take a look at the expenditure approach later on in this chapter.


\subsubsection{Unemployment Rate (\protect\(U\protect\))}
\label{\detokenize{content/09-macro/MacroChapter:unemployment-rate-u}}
\sphinxAtStartPar
The unemployment rate is also an important measure of a country’s economic performance, as it gives us some insight on the supply and demand of labor in the economy. By definition, the unemployment rate measures the percentage of the labor force – the sum of all employed and unemployed people – that is not currently employed, but is willing, able, and looking for work. Mathematically, this can be expressed by the following equation:
\begin{equation*}
\begin{split}Unemployment Rate = \frac{Unemployed}{Labor Force}\end{split}
\end{equation*}
\sphinxAtStartPar
As stated before, the labor force is just the sum of all employed and unemployed persons in the population, so we can simplify the equation above to be
\begin{equation*}
\begin{split}Unemployment Rate = \frac{Unemployed}{Employed + Unemployed}\end{split}
\end{equation*}
\sphinxAtStartPar
An important thing to remember, is that in order to be considered unemployed, a person must be able, willing, and currently looking for work. This means that anyone who is unable to work or has stopped looking for a job is no longer considered part of the labor force and is therefore not included in the unemployment rate. Intuitively this makes sense for the most part, as it probably wouldn’t be very helpful to include retirees or stay\sphinxhyphen{}at\sphinxhyphen{}home parents or even students for that matter when calculating the unemployment rate. It’s worth considering, however, that this also means that people who have been unable to find any work and therefore stopped looking – often referred to as discouraged workers – would not be represented in the unemployment rate either.


\subsubsection{Inflation Rate (\protect\(\pi\protect\))}
\label{\detokenize{content/09-macro/MacroChapter:inflation-rate-pi}}
\sphinxAtStartPar
Generally speaking, the inflation rate in an economy measures the percent change in prices over a specified period of time, and it is usually calculated using a price index. While there are many different price indices that can be used to calculate inflation, one of the more common ones is the Consumer Price Index (CPI). The CPI measures the average price for a basket of goods and services relative to some defined base year, and is calculated by taking the value of said basket in any given year, dividing it by its value in the base year, and multiplying that by 100. Mathematically, this can be expressed as
\begin{equation*}
\begin{split} CPI_t = \frac{Price~of~Goods_t}{Price~of~Goods_0} * 100\end{split}
\end{equation*}
\sphinxAtStartPar
where t = 0 refers to the base year.

\sphinxAtStartPar
We can then calculate the inflation rate for a given year as
\begin{equation*}
\begin{split} \pi_t = \frac{CPI_t - CPI_{t-1}}{CPI_{t-1}} * 100\end{split}
\end{equation*}
\sphinxAtStartPar
The inflation rate is yet another key indicator that macroeconomists look at, as it also tends to be a representation of a country’s overall economic performance. A small, positive inflation rate is considered a good thing, as it’s usually an indication of a growing economy. However, inflation rates that are negative or too high can create a lot of problems, and as such the inflation rate tends to play an important role in guiding monetary policy decisions – something we will discuss more later in this chapter.


\subsubsection{Real Interest Rate (\protect\(r\protect\))}
\label{\detokenize{content/09-macro/MacroChapter:real-interest-rate-r}}
\sphinxAtStartPar
If you have a bank account or own a credit card or have ever taken a loan, chances are that you’ve come across an interest rate at some point. In general, interest rates represent the cost of borrowing or on the flip side the return on saving or lending. There are many different interest rates that can be found in the economy from interest rates for savings accounts to interest rates charged for mortgages to interest rates set by the Central Bank. All of the interest rates that we observe in the economy are known as nominal interest rates – interest rates that are not adjusted for inflation.

\sphinxAtStartPar
As discussed earlier, inflation measures the change in prices over a given time and can be used in some sense to measure the relative value of a dollar (or other unit of currency) over time. It makes sense then, that we might want to take into inflation into account, when deciding what interest rate would make sense to lend/borrow at. To do this, we use real interest rates, which are calculated by taking nominal interest rates and subtracting inflation. This relationship between inflation, nominal interest rates, and real interest rates is captured by what is known as the Fisher Equation
\begin{equation*}
\begin{split} r_t = i_t - \pi_t \end{split}
\end{equation*}
\sphinxAtStartPar
where \(r_t\) refers to the real interest rate, \(i_t\) refers to the nominal interest rate, and \(\pi_t\) refers to the inflation rate, all in a given time period.

\sphinxAtStartPar
As a final note, we find that generally speaking all of the nominal interest rates present in the economy tend to be pretty strongly correlated with each other. Therefore, for purposes of simplification, macroeconomists will often refer to these rates in singular form in their models as simply the nominal interest rate or the real interest rate. As seen in the Fisher equation above, we use \(i\) to denote the nominal interest rate, and \(r\) to denote the real interest rate.


\section{Finance}
\label{\detokenize{content/10-finance/index:finance}}\label{\detokenize{content/10-finance/index::doc}}
\sphinxAtStartPar
This week, we will be covering some of the greatest hits of Financial Economics \sphinxhyphen{} most of which you can learn by taking Econ 136. We will begin our discussion with an important introduction to interest rates and the time value of money. After, we will pivot to stock options. These are ways investors can bet on stock value movements through purchasing or selling contracts that only have value at certain stock prices.


\subsection{Present Value, Future Value, and Interest Rates}
\label{\detokenize{content/10-finance/value-interest:present-value-future-value-and-interest-rates}}\label{\detokenize{content/10-finance/value-interest::doc}}

\subsubsection{The Time Value of Money}
\label{\detokenize{content/10-finance/value-interest:the-time-value-of-money}}
\sphinxAtStartPar
An important concept that is the basis for most of finance is the \sphinxstyleemphasis{time value of money}: money now is worth more than money in the future. This makes sense; you would rather have \$100 now than later. But what if I owed you money and I really wanted to postpone the payment? In order to compensate you for your bias toward having money as soon as possible, I would need to pay more than I owed. Otherwise, you might not tolerate a delayed payment. This idea of an extra payment to address time concerns is called \sphinxstyleemphasis{interest}. There is also a dimension of risk as well. If you had reason to doubt my ability to repay you in the future, you might charge me more interest to compensate for this risk.

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\sphinxstylestrong{Interest} is payment at a particular rate for the use of money or for delaying the repayment of money. Interest is typically set at a specific rate and that rate fluctuates based on the amount of time between borrowing and repayment, the risk of default, and other factors determined by the lender.
\end{sphinxadmonition}


\subsubsection{Interest}
\label{\detokenize{content/10-finance/value-interest:interest}}
\sphinxAtStartPar
Interest is at the heart of loans, fixed income securities (think bonds), and financial economics in general. We are familiar with the bank account: you give a certain amount of money to a financial institution, and they compensate you for allowing them to use your money to invest in other assets. What they pay you for keeping your money is interest, and is normally quantified as a percentage of what you deposit with them \sphinxhyphen{} an interest rate. Thus, for each \$1 deposited at the bank, you will receive \(r\) dollars in interest, where \(r\) is the interest rate quoted by the bank. Note that \(r\) takes the form of a decimal value: 0.05, for instance, and not 5\%.

\sphinxAtStartPar
Interest can be paid out in different time intervals \sphinxhyphen{} usually monthly, quarterly, yearly or continuously. Also, if you earn some interest in one year, in the next year you will not only earn interest on the initial amount you deposited, but also on the amount you earned the year before. This reflects the idea of \sphinxstyleemphasis{compounding interest}. We are able to determine how much \$1 will be worth in \(t\) years, when compounding \(n\) times per year at an interest rate of \(r\).
\begin{equation*}
\begin{split}\begin{aligned}
\text{Value of 1 dollar in } t \text{ years} &= 1 \times \left(1 + \dfrac{r}{n} \right) \times \left(1 + \dfrac{r}{n} \right) \times \cdots \times \left(1 + \dfrac{r}{n} \right) \\
&= 1 \left(1 + \dfrac{r}{n} \right)^{nt}
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Take a look at the table below for an example of the effects of compounding.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

\sphinxAtStartPar

&\sphinxstyletheadfamily 
\sphinxAtStartPar
Bank 1: 5\% annual compounding
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Bank 2: 5\% semi\sphinxhyphen{}annual compounding
\\
\hline
\sphinxAtStartPar
January 2016
&
\sphinxAtStartPar
\$100
&
\sphinxAtStartPar
\$100
\\
\hline
\sphinxAtStartPar
July 2016
&
\sphinxAtStartPar

&
\sphinxAtStartPar
\(100 \left(1 + \dfrac{0.05}{2} \right) =\) \$102.50
\\
\hline
\sphinxAtStartPar
January 2017
&
\sphinxAtStartPar
\(100 (1 + 0.05) =\) \$105
&
\sphinxAtStartPar
\(102.50 \left(1 + \dfrac{0.05}{2} \right) =\) \$105.0625
\\
\hline
\sphinxAtStartPar
July 2017
&
\sphinxAtStartPar

&
\sphinxAtStartPar
\(105.0625 \left(1 + \dfrac{0.05}{2} \right) =\) \$107.69
\\
\hline
\sphinxAtStartPar
January 2018
&
\sphinxAtStartPar
\(105 (1 + 0.05) =\) \$110.25
&
\sphinxAtStartPar
\(107.69 \left(1 + \dfrac{0.05}{2} \right) =\) \$110.38
\\
\hline
\sphinxAtStartPar
Total Percent Change
&
\sphinxAtStartPar
10.25\%
&
\sphinxAtStartPar
10.38\%
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Notice that instead of a \(5\% \cdot 2 = 10\%\) increase, you end up receiving a 10.25\% or 10.38\% increase depending on the rate of compounding. This is because the interest you received in the first compounding period (in bank 1’s case, a year, in bank 2’s case, half a year) is added onto your initial deposit, and this new deposit is used for calculating interest in the next period. Thus, even a small amount of money can grow quickly under interest rate compounding.


\subsubsection{Present Value, Future Value, and the Discount Factor}
\label{\detokenize{content/10-finance/value-interest:present-value-future-value-and-the-discount-factor}}
\sphinxAtStartPar
An important related concept is the idea of present and future value (which are effectively opposites). We have already discussed future value above. A \$100 deposit at bank 1 above has a future value of \$110.25 after 2 years. Conversely, an important question frequently asked in finance is the following:
\begin{quote}

\sphinxAtStartPar
Given an amount of money in the future, what is its fair value today?
\end{quote}

\sphinxAtStartPar
In this example, what is the present value of \$110.25 at bank 1 two years in the future? Well, from the table above, \$100! This idea of present value is essential to the pricing of assets. In general, an asset’s price is the present value of all expected future payments.
\begin{equation*}
\begin{split}\begin{aligned}
\text{FV of 1 dollar} &= 1 \times \left(1 + \dfrac{r}{n} \right)^{nt} \\
\text{PV of 1 dollar} &= \dfrac{1}{\left(1 + \dfrac{r}{n} \right)^{nt}}
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
We call \(\dfrac{1}{(1 + \frac{r}{n})^{nt}}\) a \sphinxstyleemphasis{discount factor}. It discounts the value of \$1 from the future into today. This ties in with the time value of money. Since a dollar today is worth more than a dollar tomorrow, in order for you to be indifferent between receiving money today or tomorrow, the money you would receive tomorrow has to be discounted into the present by some amount that depends on the interest rate.
\begin{equation*}
\begin{split}
\text{PV} = \text{DF} \cdot \text{FV}
\end{split}
\end{equation*}

\subsection{Options}
\label{\detokenize{content/10-finance/options:options}}\label{\detokenize{content/10-finance/options::doc}}
\sphinxAtStartPar
Before we discuss options, it’s important to understand some basics regarding stocks. A stock is a share in a company. By owning stock you are owning a small part of a company. Stocks trade on a stock exchange, where people come together to buy and sell shares to one another. People who want to buy a stock place a \sphinxstyleemphasis{bid}, or a price at which they want to buy. Others who want to sell place an \sphinxstyleemphasis{ask}, or a price that they want to sell. The market price of a stock is where these bids and asks come together.

\sphinxAtStartPar
If I purchase and hold onto a stock, I am said to have a \sphinxstyleemphasis{long} position on the stock. If the stock goes up in value, I profit. If it goes down in value, I lose. It is also possible to have inverse exposure to the price of a stock, meaning that if the price of the stock goes down I profit, and if it goes up I lose. This is called shorting the stock, or having a \sphinxstyleemphasis{short} position on the stock. This is accomplished by borrowing stock from a stock broker and selling it today, and then buying it back sometime in the future to pay off your “loan” of borrowed stock from the broker.

\sphinxAtStartPar
You can see how you can profit from this if you sell stock at \$100. Then, if the value of the stock goes down to \$70 in the future, you can buy back the stock using the \$100 you made earlier, thus finishing your loan from the broker. However, you have \$30 left over. You made \$100 selling the stock, yet it only cost \$70 to buy it back. Thus, you have made a profit from the stock going down in value.

\sphinxAtStartPar
Recall that in a short position, you never actually owned the stock to begin with. You borrowed the stock from a stock broker, and you paid back that stock in the future. In reality, the stock broker wants to be paid for the service it provides you, and someone shorting stock will have to effectively pay interest on that “loan”, just like a normal loan.


\subsubsection{Puts}
\label{\detokenize{content/10-finance/options:puts}}
\sphinxAtStartPar
Suppose you own some stock in an investment account. You want your stock to be able to increase in value over time, but you also don’t want its value to decrease too much. One way to think about this is that you want to own some asset that has asymmetrical payoff; you want all the potential upside of owning the asset with as little of the downside as possible.

\sphinxAtStartPar
One way to achieve this is to buy “insurance” on your stock. You might want an insurance contract that will cover losses if the value of your stock goes below a certain number. This type of contract exists, and they are called \sphinxstyleemphasis{puts}.

\sphinxAtStartPar
The simplest way to think about a put is that it is a contract that pays you a dollar for each dollar that your stock does below some specified number. So for instance, if you own a stock that trades at \$110, and you don’t want to lose more than \$10 in value from owning the stock, you might buy a put with a \sphinxstyleemphasis{strike} of \$100. The strike of the put is this pre\sphinxhyphen{}specified number below which you don’t want to lose money. Now, let’s say your stock starts going down in value. Going down from \$110 to \$100, there’s nothing that your put can do. But starting at \$100, each dollar that your stock goes down in value, your put pays you one dollar. Therefore, when you own this put \sphinxstyleemphasis{in combination} with the stock, the overall value of this combination cannot go below \$100.

\sphinxAtStartPar
Let’s call this combination of stock and put a \sphinxstyleemphasis{portfolio}. Your portfolio’s value depends on the value of the stock, and the portfolio’s value looks like this:

\sphinxAtStartPar
\sphinxincludegraphics{{figure1}.png}

\sphinxAtStartPar
Now that we have the basic intuition down, let’s get more specific. While a put behaves like insurance, the way a put is technically defined is a bit different. A put contract says the following:
\begin{quote}

\sphinxAtStartPar
“The holder of this contract has the right, \sphinxstyleemphasis{but not the obligation}, to sell 100 shares of an underlying stock at a specified strike price, from now until some expiration date.”
\end{quote}

\sphinxAtStartPar
You can see how this behaves essentially as insurance. If the strike price is \$100 as above, and your stock goes below \$100 in value, you might want to exercise your right to sell your shares at \$100. Regardless of how far below \$100 your stock is, the put allows you to sell at \$100. Additionally, if your stock is valued above \$100, there’s no reason to exercise your right to sell at \$100; you could just sell at whatever price your stock is trading.


\subsubsection{Calls}
\label{\detokenize{content/10-finance/options:calls}}
\sphinxAtStartPar
The opposite of a put, in a sense, is a \sphinxstyleemphasis{call}. A call contract specifies the following:
\begin{quote}

\sphinxAtStartPar
“The holder of this contract has the right, \sphinxstyleemphasis{but not the obligation}, to buy 100 shares of an underlying stock at a specified strike price, from now until some expiration date.”
\end{quote}

\sphinxAtStartPar
You could technically interpret calls as insurance for people who are \sphinxstyleemphasis{short} some stock, but this isn’t the most helpful way to think about them. A better way to think about calls is the following: Suppose you want to buy and hold a stock, but you aren’t sure if the value of the stock will go up in a desired time frame. Instead of buying the stock and risking that its value will decrease, you could buy a call that gives you the \sphinxstyleemphasis{opportunity} to purchase the stock at some price that you want, say \$100. That way, if the value of the stock goes above \$100, instead of missing out on that increase in value, your call gives you the right to purchase the stock at \$100, even though it is actually worth more than \$100. If the stock is worth less than \$100 after some time, you don’t have to do anything and you didn’t lose the value you would have lost if you had purchased the stock.


\subsubsection{Payoff Diagrams}
\label{\detokenize{content/10-finance/options:payoff-diagrams}}
\sphinxAtStartPar
Instead of thinking about the value of a portfolio with a stock and a put, let’s just think about the value of a put given the price of the underlying stock. In other words, you don’t actually own the stock, you just own the put. Let’s use the example of a put with a strike of \$100 as above. If the stock is trading somewhere below \$100, say \$90, then the put has a payoff of \$10. The reason for this is because you could purchase the stock for \$90, and then use your put, which gives you the right to sell a stock for \$100. That’s a profit of \$10, and therefore the put has a payoff of \$10.

\sphinxAtStartPar
Similarly, if the stock is trading above \$100, the put has no payoff. If you were to buy the stock at its price and use your put to sell at \$100, you would lose money. This is because it cost you more than \$100 to buy the stock, but you only sold for \$100. Since you are never actually obligated to use a put, you would not use it in this case, and it has 0 payoff.

\sphinxAtStartPar
\sphinxstylestrong{Notice that all of this occured without you ever owning the stock to begin with.}

\sphinxAtStartPar
Now let’s plot the payoff of this put with a strike of \$100, given the price of the underlying stock.

\sphinxAtStartPar
\sphinxincludegraphics{{figure2}.png}

\sphinxAtStartPar
The payoff of a call works similarly. Remember that a call gives you the right to buy a stock at a certain price. So if you own a call with a strike of \$100, and the underlying stock is trading at \$110, the call has a payoff of \$10. This is because you could use your call to buy the stock for \$100, and then sell it for \$110, since this is the market price of the stock. And again, if the stock is trading below \$100 the call has no payoff. This is because if you were to use your call to purchase the stock at \$100, you could only sell it for less than \$100, thus losing money. A rational investor would never use the call for this, and therefore it has no payoff. Below is the payoff diagram for a call with a strike of \$100.

\sphinxAtStartPar
\sphinxincludegraphics{{figure3}.png}

\sphinxAtStartPar
And quickly, here are the payoff diagrams for being long and short a stock, which should appear trivial by now. These diagrams ignore the price of the stock when you bought/shorted it. In other words, if you purchased the stock at \$100, and sold at \$100, the diagram implies a payoff of \$100. This is to be consistent with the above diagrams, in which we implicitly assumed that there is no cost in buying an option, a claim which we will examine below.

\sphinxAtStartPar
\sphinxincludegraphics{{figure4}.png}

\sphinxAtStartPar
\sphinxincludegraphics{{figure5}.png}

\sphinxAtStartPar
Now, we see how we can generate the payoff diagram for the portfolio of a stock and a put from above. The diagram for that portfolio is copied below.

\sphinxAtStartPar
\sphinxincludegraphics{{figure1}.png}

\sphinxAtStartPar
Notice how we can generate this by adding the payoff diagrams of a stock and a put. We have shown that the payoff diagram of a portfolio can be represented as the sum of payoff diagrams of its components.

\sphinxAtStartPar
\sphinxincludegraphics{{figure6}.png}


\subsubsection{Pricing Options}
\label{\detokenize{content/10-finance/options:pricing-options}}
\sphinxAtStartPar
We have only been studying one side of an option contract: the holder of the option. Of course, in order to own a contract that gives you the right to buy or sell a stock at a certain price, someone has to be willing to guarantee you that right. Offering you that right comes with some risk, because whoever sells you the contract might be obligated to buy or sell a stock from you at a price that is not favorable. Because of this, they will ask for payment in return. Therefore, just like any other form of insurance, options are not free.

\sphinxAtStartPar
Let’s think about what could contribute to an option’s price. We know that someone is taking on risk by selling you an option, so whatever puts that person at an increased risk of losing money should make the option more expensive. For this lesson let’s only think about the price of a call.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Strike price}. Suppose a stock is trading at \$100, and I am interested in a call with a strike of \$110. The person who sells me that call bears some risk, because the price of the stock might go above \$110 sometime in the future, in which case I would profit and the person who sold me the option would lose money. Now suppose I look at a call with a strike of \$120. The person selling me the \$120 call bears some risk, but not as much as the first person, because it is less likely that the stock’s price exceeds \$120 sometime in the future compared to the chance that it exceeds \$110. So which of these two options should cost more, holding all else equal? Naturally, the call with the strike of \$110 should cost more, because it is more likely that I make money with this call as opposed to the \$120 call, and therefore more likely that the person selling it to me loses money. \sphinxstylestrong{This shows that for calls, the lower the strike price, the more expensive the call becomes}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Time until expiration}. We briefly mentioned earlier in the definitions for calls and puts that options are only active for a certain time period. So if a call is only active for 1 week, while an otherwise identical call is active for 1 year, which should cost more? Using similar logic as above, the call lasting 1 year puts the option seller at a higher risk of losing money, since there is more time for the underlying stock price to move in such a way that is disadvantageous. The call lasting 1 week doesn’t have much time at all to move in such a way that the option seller loses money. \sphinxstylestrong{This shows that for calls, the farther away the expiration, the more expensive the call becomes}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Volatility}. Imagine a stock is trading at \$100, and historically this stock’s price does not move very much at all. Now, imagine another stock that is also trading at \$100, but has a history of wild price swings. In this example, if there exist two calls with otherwise identical attributes on these two stocks, which one should cost more? We say that the stock with a history of price swings is more volatile than the more tame stock. The more volatile stock has a higher chance of jumping up in price to a point where you can make a profit compared to the more tame stock. \sphinxstylestrong{This shows that for calls, the higher the volatility of the underlying stock, the more expensive the call becomes}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Underlying stock price}. This should be the most obvious factor that affects the prices of options. If someone is offering to sell a call with a strike of \$100 on some stock, and the stock’s price is \$90, then the call option will have some price. But if the stock jumps in value to \$95, then clearly the call option will be worth more. After the stock’s price increases to \$95, it becomes more likely that the stock’ price can exceed \$100 sometime in the future. This exposes the person selling you the call to a higher risk of losing money, and therefore the person will charge more for the call. \sphinxstylestrong{This shows that for calls, the higher the price of the underlying stock, the more expensive the call becomes}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{The risk\sphinxhyphen{}free interest rate}. This one is a bit less intuitive and we will not be discussing this in depth, but the prevailing interest rate of risk\sphinxhyphen{}free deposits also affects the prices of options.

\end{itemize}


\paragraph{Black\sphinxhyphen{}Scholes}
\label{\detokenize{content/10-finance/options:black-scholes}}
\sphinxAtStartPar
So how would we calculate the fair price of an option? Intuitively, the fair price of an option should be the payoff of the option for every possible price of the stock, weighted by the probability of that stock being at that particular price, discounted into the present (since you receive some payment in the future). It turns out that this is a pretty complicated problem to solve, and we will not ask you derive the following formulae. Below is an expression for the price of a call and a put.
\begin{equation*}
\begin{split}\begin{aligned}
C &= S \cdot N(d_1) - K \cdot e^{-r_{rf}T} \cdot N(d_2) \\
P &= K \cdot e^{-r_{rf}T} \cdot N(-d_2) - S \cdot N(-d_1)
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(S\) is the price of the stock, \(K\) is the strike of the call, \(r_{rf}\) is the risk\sphinxhyphen{}free interest rate, \(T\) is time till expiration, \(N()\) is the normal CDF, \(d_1 = \frac{ln(S/K) - (r_{rf} + \sigma^2/2)T}{\sigma\sqrt{T}}\), and \(d_2 = d_1 - \sigma\sqrt{T}\). This assumes that stock returns are normally distributed.

\begin{sphinxadmonition}{note}{Disclaimer}

\sphinxAtStartPar
These expressions are actually the prices \sphinxstylestrong{European options}. A European option is an option that only allows you to exercise (use the option) exactly on the expiration date, and not before. The definitions for options that we gave earlier correspond to \sphinxstylestrong{American options}, which allow you to exercise the option at any time, even before expiration. The reason we have the prices for European options and not American options is because the prices for American options are actually even more difficult to find. For example, American puts are priced quite differently from European puts. However, for a stock that does not pay dividends, the prices for American calls and European calls tend to be similar.
\end{sphinxadmonition}


\subsubsection{Trading Options}
\label{\detokenize{content/10-finance/options:trading-options}}
\sphinxAtStartPar
Options can be traded on an exchange just like stocks. You can buy an option today, and if something happens that makes you not want to hold the option anymore, you can sell it tomorrow. Options therefore have some prevailing market price that is determined by buyers and sellers, but in a rational market the prices of options must follow the rules/trends defined above.

\sphinxAtStartPar
Importantly, you aren’t restricted to just buying options. You can also assume the role of the person taking on risk by selling an option to someone else. Let’s think about how this would work.

\sphinxAtStartPar
Suppose you want to buy a call option from me on some underlying stock currently trading at \$90. You want the option to have a strike of \$100, and you want it to expire in 1 month. You would have to pay me whatever the fair market price for this option is, but there’s one more step that I would then have to take.

\sphinxAtStartPar
By owning a call, you have the right to buy the underlying stock from me at \$100, even if the price of the stock goes above \$100. From my perspective, that means that I might have the \sphinxstyleemphasis{obligation} to \sphinxstyleemphasis{sell} you stock at a price of \$100. In order to cover this obligation, I will have to put up some collateral to guarantee that I will be able to pay my obligation, should the time come. The specific rules for collateral vary with different brokers and other conditions.

\sphinxAtStartPar
Suppose I only needed to put up enough collateral to cover a \$20 increase in stock price. That means that I need to be able to afford buying stock at \$110, and selling it to you at \$100. That’s a difference of \$10. But recall that option contracts actually deal with increments of 100 shares. So I will actually have to post \$10 x 100 = \$1000 in collateral. If the stock price does in fact jump to \$110, my broker may then ask me to put even more money down for collateral, in the event that it continues to go up.

\sphinxAtStartPar
If for some reason the rules specify that I need to completely cover all the risk of selling this call, no amount of money will be sufficient to cover the cost of buying shares at some unknown price in the future and selling at \$100. This is because there is no theoretical limit to how high the price of a stock can reach. In this situation, I would actually have to post 100 shares of the stock as collateral at the same time that I sell you the call. This way, I am guaranteed to have 100 shares of stock to sell to you in the event that you use your call.

\sphinxAtStartPar
Selling calls works similarly, but instead I need to have enough money down as collateral to afford to \sphinxstyleemphasis{buy} shares from you at the strike price.


\subsubsection{Returns}
\label{\detokenize{content/10-finance/options:returns}}
\sphinxAtStartPar
This portion of the lecture is fairly simple. A return on security is essentially the money made or lost by investing in the security over a period of time.

\sphinxAtStartPar
The return on security has two components:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
The change in price of the security

\item {} 
\sphinxAtStartPar
Any cash flows associated with the security (dividends for stock, coupons for bonds)

\end{enumerate}

\sphinxAtStartPar
If we write the change in price over a time interval τ as
\(∆x_t = x_{t+τ} − x_t = x(t + τ) − x(t)\),
then we can write the rate of return r as
\(r(t) = \frac{x(t + τ) −x(t) + income − costs}{x(t)}\)


\paragraph{Calculating Returns Using an API}
\label{\detokenize{content/10-finance/options:calculating-returns-using-an-api}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}importing packages needed to access the API}
\PYG{o}{!}pip install yfinance
\PYG{k+kn}{import} \PYG{n+nn}{yfinance} \PYG{k}{as} \PYG{n+nn}{yf}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Requirement already satisfied: yfinance in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (0.1.64)
Requirement already satisfied: numpy\PYGZgt{}=1.15 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from yfinance) (1.20.1)
Requirement already satisfied: multitasking\PYGZgt{}=0.0.7 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from yfinance) (0.0.9)
Requirement already satisfied: pandas\PYGZgt{}=0.24 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from yfinance) (1.2.4)
Requirement already satisfied: lxml\PYGZgt{}=4.5.1 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from yfinance) (4.6.3)
Requirement already satisfied: requests\PYGZgt{}=2.20 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from yfinance) (2.25.1)
Requirement already satisfied: python\PYGZhy{}dateutil\PYGZgt{}=2.7.3 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from pandas\PYGZgt{}=0.24\PYGZhy{}\PYGZgt{}yfinance) (2.8.1)
Requirement already satisfied: pytz\PYGZgt{}=2017.3 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from pandas\PYGZgt{}=0.24\PYGZhy{}\PYGZgt{}yfinance) (2021.1)
Requirement already satisfied: six\PYGZgt{}=1.5 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from python\PYGZhy{}dateutil\PYGZgt{}=2.7.3\PYGZhy{}\PYGZgt{}pandas\PYGZgt{}=0.24\PYGZhy{}\PYGZgt{}yfinance) (1.15.0)
Requirement already satisfied: urllib3\PYGZlt{}1.27,\PYGZgt{}=1.21.1 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from requests\PYGZgt{}=2.20\PYGZhy{}\PYGZgt{}yfinance) (1.26.4)
Requirement already satisfied: certifi\PYGZgt{}=2017.4.17 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from requests\PYGZgt{}=2.20\PYGZhy{}\PYGZgt{}yfinance) (2020.12.5)
Requirement already satisfied: chardet\PYGZlt{}5,\PYGZgt{}=3.0.2 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from requests\PYGZgt{}=2.20\PYGZhy{}\PYGZgt{}yfinance) (4.0.0)
Requirement already satisfied: idna\PYGZlt{}3,\PYGZgt{}=2.5 in /Users/rohanjha/opt/anaconda3/lib/python3.8/site\PYGZhy{}packages (from requests\PYGZgt{}=2.20\PYGZhy{}\PYGZgt{}yfinance) (2.10)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{data} \PYG{o}{=} \PYG{n}{yf}\PYG{o}{.}\PYG{n}{download}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZca{}GSPC}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{start}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{1993\PYGZhy{}01\PYGZhy{}01}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{end}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{2021\PYGZhy{}01\PYGZhy{}01}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} In code above, we input the ticker symbol for S\PYGZam{}P500 and specify the start and end time intervals}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
[*********************100\PYGZpc{}***********************]  1 of 1 completed
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
                   Open         High          Low        Close    Adj Close  \PYGZbs{}
Date                                                                          
1993\PYGZhy{}01\PYGZhy{}04   435.700012   437.320007   434.480011   435.380005   435.380005   
1993\PYGZhy{}01\PYGZhy{}05   435.380005   435.399994   433.549988   434.339996   434.339996   
1993\PYGZhy{}01\PYGZhy{}06   434.339996   435.170013   432.519989   434.519989   434.519989   
1993\PYGZhy{}01\PYGZhy{}07   434.519989   435.459991   429.760010   430.730011   430.730011   
1993\PYGZhy{}01\PYGZhy{}08   430.730011   430.730011   426.880005   429.049988   429.049988   
...                 ...          ...          ...          ...          ...   
2020\PYGZhy{}12\PYGZhy{}24  3694.030029  3703.820068  3689.320068  3703.060059  3703.060059   
2020\PYGZhy{}12\PYGZhy{}28  3723.030029  3740.510010  3723.030029  3735.360107  3735.360107   
2020\PYGZhy{}12\PYGZhy{}29  3750.010010  3756.120117  3723.310059  3727.040039  3727.040039   
2020\PYGZhy{}12\PYGZhy{}30  3736.189941  3744.629883  3730.209961  3732.040039  3732.040039   
2020\PYGZhy{}12\PYGZhy{}31  3733.270020  3760.199951  3726.879883  3756.070068  3756.070068   

                Volume  
Date                    
1993\PYGZhy{}01\PYGZhy{}04   201210000  
1993\PYGZhy{}01\PYGZhy{}05   240350000  
1993\PYGZhy{}01\PYGZhy{}06   295240000  
1993\PYGZhy{}01\PYGZhy{}07   304850000  
1993\PYGZhy{}01\PYGZhy{}08   263470000  
...                ...  
2020\PYGZhy{}12\PYGZhy{}24  1885090000  
2020\PYGZhy{}12\PYGZhy{}28  3527460000  
2020\PYGZhy{}12\PYGZhy{}29  3387030000  
2020\PYGZhy{}12\PYGZhy{}30  3145200000  
2020\PYGZhy{}12\PYGZhy{}31  3172510000  

[7052 rows x 6 columns]
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{data}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
                   Open         High          Low        Close    Adj Close  \PYGZbs{}
Date                                                                          
1993\PYGZhy{}01\PYGZhy{}04   435.700012   437.320007   434.480011   435.380005   435.380005   
1993\PYGZhy{}01\PYGZhy{}05   435.380005   435.399994   433.549988   434.339996   434.339996   
1993\PYGZhy{}01\PYGZhy{}06   434.339996   435.170013   432.519989   434.519989   434.519989   
1993\PYGZhy{}01\PYGZhy{}07   434.519989   435.459991   429.760010   430.730011   430.730011   
1993\PYGZhy{}01\PYGZhy{}08   430.730011   430.730011   426.880005   429.049988   429.049988   
...                 ...          ...          ...          ...          ...   
2020\PYGZhy{}12\PYGZhy{}24  3694.030029  3703.820068  3689.320068  3703.060059  3703.060059   
2020\PYGZhy{}12\PYGZhy{}28  3723.030029  3740.510010  3723.030029  3735.360107  3735.360107   
2020\PYGZhy{}12\PYGZhy{}29  3750.010010  3756.120117  3723.310059  3727.040039  3727.040039   
2020\PYGZhy{}12\PYGZhy{}30  3736.189941  3744.629883  3730.209961  3732.040039  3732.040039   
2020\PYGZhy{}12\PYGZhy{}31  3733.270020  3760.199951  3726.879883  3756.070068  3756.070068   

                Volume  
Date                    
1993\PYGZhy{}01\PYGZhy{}04   201210000  
1993\PYGZhy{}01\PYGZhy{}05   240350000  
1993\PYGZhy{}01\PYGZhy{}06   295240000  
1993\PYGZhy{}01\PYGZhy{}07   304850000  
1993\PYGZhy{}01\PYGZhy{}08   263470000  
...                ...  
2020\PYGZhy{}12\PYGZhy{}24  1885090000  
2020\PYGZhy{}12\PYGZhy{}28  3527460000  
2020\PYGZhy{}12\PYGZhy{}29  3387030000  
2020\PYGZhy{}12\PYGZhy{}30  3145200000  
2020\PYGZhy{}12\PYGZhy{}31  3172510000  

[7052 rows x 6 columns]
\end{sphinxVerbatim}

\sphinxAtStartPar
Let’s plot the graph for the closing price of S\&P500.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Close}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{color}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{purple}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{8}\PYG{p}{)}\PYG{p}{,} \PYG{n}{title} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{S\PYGZam{}P500 Returns}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{options_14_0}.png}

\sphinxAtStartPar
The graph below shows the returns from S\&P500 as a function of time over the previous time interval.

\sphinxAtStartPar
\sphinxincludegraphics{{figure9}.png}


\section{Econometrics}
\label{\detokenize{content/11-econometrics/index:econometrics}}\label{\detokenize{content/11-econometrics/index::doc}}
\sphinxAtStartPar
One way to think about Econometrics is that it is the closest economists can usually get to doing experiments in the same way experiments are done in medicine and other fields involving people. The idealized experiment is one where people are randomly assigned to either the treatment or control group such that the participants \sphinxstyleemphasis{and} the researchers don’t know which group each person is in.

\sphinxAtStartPar
By randomly assigning a large sample of participants to two different groups, we can be fairly confident that on average the two groups are identical in their attributes, apart from the treatment that only one group receives. By having a double\sphinxhyphen{}blind experiment, we can be confident that the participants and researchers aren’t conciously or subconciously (placebo effect) affecting the results of the treatment group. Because of this setup, we can look at the difference in outcomes of the two groups and be fairly confident that any differences are due to the treatment and nothing else.

\sphinxAtStartPar
But it’s usually impossible or unethical to perform an ideal experiment in economics. Imagine trying to examine the effect of years of schooling on future earnings. Can you force people into a treatment group with more years of schooling and a control group with less? Is it sufficient to just collect a sample of people and compare the earnings of people with high schooling to those with low schooling?

\sphinxAtStartPar
How can we answer the above question and others like it? Econometrics. Econometrics is a vast field and today we will just focus on the basics of something called regression.


\subsection{Single Variable Regression}
\label{\detokenize{content/11-econometrics/single-variable:single-variable-regression}}\label{\detokenize{content/11-econometrics/single-variable::doc}}
\sphinxAtStartPar
Suppose we have some data that look like this:

\sphinxAtStartPar
\sphinxincludegraphics{{figure11}.png}

\sphinxAtStartPar
In Data 8 we learned that \(x\) and \(y\) above have some \sphinxstylestrong{correlation coefficient} \(r\), which is a measure of the strength of the linear relationship between the two variables.

\sphinxAtStartPar
It looks like there is some positive linear association between \(x\) and \(y\) such that larger values of \(x\) correspond to larger values of \(y\). We therefore expect \(r\) to be some positive number between 0 and 1, but not exactly 0 or exactly 1.

\sphinxAtStartPar
First, let’s convert the data (stored in the arrays \sphinxcode{\sphinxupquote{x}} and \sphinxcode{\sphinxupquote{y}}) to standard units. To convert a set of data points to standard units, we subtract out the mean of the data and scale by the standard deviation. This has the effect of changing the data so that the data in standard units have mean 0 and  standard deviation 1. Below we construct a function that does this.
\begin{equation*}
\begin{split}
x_{su} = \dfrac{x - \mu_x}{\sigma_x}
\end{split}
\end{equation*}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{standard\PYGZus{}units}\PYG{p}{(}\PYG{n}{array}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{p}{(}\PYG{n}{array} \PYG{o}{\PYGZhy{}} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{array}\PYG{p}{)}\PYG{p}{)} \PYG{o}{/} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{array}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{x\PYGZus{}standard} \PYG{o}{=} \PYG{n}{standard\PYGZus{}units}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\PYG{n}{y\PYGZus{}standard} \PYG{o}{=} \PYG{n}{standard\PYGZus{}units}\PYG{p}{(}\PYG{n}{y}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{single-variable_8_0}.png}

\sphinxAtStartPar
The plot looks the same as before, except now the axes are scaled such that we measure \(x\) and \(y\) in standard units. Now recall that \(r\) is calculated as the average of the product of two variables, when the variables are measured in standard units. Below we define a function that calculates \(r\), assuming that the inputs have already been converted to standard units.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{correlation}\PYG{p}{(}\PYG{n}{array1}\PYG{p}{,} \PYG{n}{array2}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{array1} \PYG{o}{*} \PYG{n}{array2}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
What is the correlation between these two variables?

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{correlation}\PYG{p}{(}\PYG{n}{x\PYGZus{}standard}\PYG{p}{,} \PYG{n}{y\PYGZus{}standard}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
0.7351364076052979
\end{sphinxVerbatim}

\sphinxAtStartPar
Recall from Data 8 that we use \(r\) to form a line called the \sphinxstyleemphasis{regression line}, which makes predictions for \(y\) given some \(x\). Our prediction for \(y\) in standard units is \(r \cdot x\). If we want to fit this regression line in the original units, recall that the slope of this line is given by
\begin{equation*}
\begin{split}
\text{slope} = r \cdot \dfrac{\hat{\sigma}_y}{\hat{\sigma}_x}
\end{split}
\end{equation*}
\sphinxAtStartPar
and the intercept is given by
\begin{equation*}
\begin{split}
\text{intercept} = \hat{\mu}_y - \text{slope} \cdot \hat{\mu}_x
\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\hat{\sigma}_x\) is the observed standard deviation of a variable \(x\) and \(\hat{\mu}_x\) is the observed mean. Our regression line will have the form
\begin{equation*}
\begin{split}
y = \hat{\alpha} + \hat{\beta} x
\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\hat{\alpha}\) is the intercept from above and \(\hat{\beta}\) the slope.

\sphinxAtStartPar
Below we plot this line.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{r} \PYG{o}{=} \PYG{n}{correlation}\PYG{p}{(}\PYG{n}{x\PYGZus{}standard}\PYG{p}{,} \PYG{n}{y\PYGZus{}standard}\PYG{p}{)}
\PYG{n}{slope} \PYG{o}{=} \PYG{n}{r} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{y}\PYG{p}{)} \PYG{o}{/} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\PYG{n}{intercept} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{y}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{slope} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{single-variable_15_0}.png}

\sphinxAtStartPar
Let’s take a closer look at the slope we found.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Slope:  1.3160907091507876
\end{sphinxVerbatim}

\sphinxAtStartPar
To generate the data above, we started with some range of \(x\) values, and generated \(y\) as a linear function of \(x\) with some random noise added in. Take a look:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{42}\PYG{p}{)}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{uniform}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{)}
\PYG{n}{noise} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{)} \PYG{o}{*} \PYG{l+m+mi}{4}
\PYG{n}{y} \PYG{o}{=} \PYG{l+m+mf}{1.5} \PYG{o}{*} \PYG{n}{x} \PYG{o}{+} \PYG{n}{noise}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice how I defined \(y\):
\begin{equation*}
\begin{split}
y = 1.5 \cdot x + u
\end{split}
\end{equation*}
\sphinxAtStartPar
where \(u\) is some normally\sphinxhyphen{}distributed random noise whose average is 0. So, while there is some randomness to the data, on average the “true” slope of the relationship is 1.5. Yet we predicted it to be roughly 1.3!

\sphinxAtStartPar
This highlights the following fact: Suppose we have some random data that we believe has a linear relationship. The least\sphinxhyphen{}squares slope we generate from the data is an \sphinxstyleemphasis{estimate} of the “true” slope of that data. Because of this, the estimated slope is a random variable that depends on the data we happen to have.

\sphinxAtStartPar
To highlight this fact, let’s repeat the procedure above but with a different \sphinxhref{https://en.wikipedia.org/wiki/Random\_seed}{random seed}, in order to get data with the same underlying relationship but different values.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{189}\PYG{p}{)}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{uniform}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{)}
\PYG{n}{noise} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{)} \PYG{o}{*} \PYG{l+m+mi}{4}
\PYG{n}{y} \PYG{o}{=} \PYG{l+m+mf}{1.5} \PYG{o}{*} \PYG{n}{x} \PYG{o}{+} \PYG{n}{noise}

\PYG{n}{r} \PYG{o}{=} \PYG{n}{correlation}\PYG{p}{(}\PYG{n}{x\PYGZus{}standard}\PYG{p}{,} \PYG{n}{y\PYGZus{}standard}\PYG{p}{)}
\PYG{n}{slope} \PYG{o}{=} \PYG{n}{r} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{y}\PYG{p}{)} \PYG{o}{/} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\PYG{n}{intercept} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{y}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{slope} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Slope:  1.5590151265266388
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{single-variable_22_1}.png}

\sphinxAtStartPar
Now the estimated slope is roughly 1.6, even though the underlying data was still generated using a slope of 1.5. This is a very important concept that we will revisit soon.

\sphinxAtStartPar
Keep in mind, however, that correlation in data \sphinxstyleemphasis{does not} imply causation. In this example we know the true causal relationship between \(x\) and \(y\) because we defined it ourselves. However, when using real data you do not see the “true” relation and thus cannot conclude causality from correlation. It could simply be that both your variables depend on an unseen third variable and have no causal effect on one another. Or even worse, while unlikely it could be the case that slight linear trends in two variables is a complete coincidence.


\subsubsection{Root\sphinxhyphen{}Mean\sphinxhyphen{}Squared Error}
\label{\detokenize{content/11-econometrics/single-variable:root-mean-squared-error}}
\sphinxAtStartPar
While we can arbitrarily pick \(\hat{\alpha}\) and \(\hat{\beta}\) values, we do want to pick the values that help predict \(\hat{y}\) that are closest to actual \(y\) values. To achieve this, we want to minimize a \sphinxstylestrong{loss function} that quantifies how far off our prediction \(\hat{y}\) is from \(y\) for some known data points. One of the most common loss functions is called the \sphinxstylestrong{root\sphinxhyphen{}mean\sphinxhyphen{}squared error}, and is defined as
\begin{equation*}
\begin{split}
\text{RMSE} = \sqrt{ \frac{1}{n} \sum_{i=1}^n \left ( y_i - \hat{y}_i \right ) ^2 }
\end{split}
\end{equation*}
\sphinxAtStartPar
where \(n\) is the number of observations. The effect of this is to take the mean of the distance of each value of \(\hat{y}\) from its corresponding value in \(y\); squaring these values keeps them positive, and then we take the square root to correct the units of the error.

\sphinxAtStartPar
Plugging in the formula \(\hat{y}\) in RMSE formula, we get,
\begin{equation*}
\begin{split}
\text{RMSE} = \sqrt{ \frac{1}{n} \sum_{i=1}^n \left ( y_i - (\hat{\alpha} + \hat{\beta}x_i) \right ) ^2 }
\end{split}
\end{equation*}
\sphinxAtStartPar
By doing a bit of calculus, we get the following formulas for \(\hat{\alpha}\) and \(\hat{\beta}\)
\begin{equation*}
\begin{split}\Large
\hat{\beta} = r\frac {\hat{\sigma}_y} {\hat{\sigma}_x} \qquad \qquad
\hat{\alpha} = \hat{\mu}_y - \hat{\beta}\hat{\mu}_x
\end{split}
\end{equation*}
\sphinxAtStartPar
where \(r\) is the \sphinxstylestrong{correlation} between \(x\) and \(y\), \(\hat{\sigma}_y\) is the standard deviation of \(y\), \(\hat{\sigma}_x\) is the standard deviation of \(x\), \(\hat{\mu}_y\) is the average of all our \(y\) values, and \(\hat{\mu}_x\) is the average of all our \(x\) values. (As an aside, note the hats on our \(\sigma\)’s and \(\mu\)’s; this is because these are \sphinxstyleemphasis{empirical estimates} of the parameters of these distributions, rather than the true values.) These are the same values we had above!

\sphinxAtStartPar
Note that our formula for \(\hat{\beta}\) involves the \sphinxstylestrong{correlation coefficient} \(r\) of \(x\) and \(y\). The correlation coefficient of two variables is a measure of the strength of a linear relationship between them. \(r\) goes from \sphinxhyphen{}1 to 1, where \(|r|=1\) is a perfect linear relationship and \(r=0\) is no linear relationship. The formula for \(r\) is
\begin{equation*}
\begin{split}
r = \frac{1}{n}\sum^n_{i=1} \left ( \frac{x_i - \hat{\mu}_x}{\hat{\sigma}_x} \right ) \left ( \frac{y_i - \hat{\mu}_y}{\hat{\sigma}_y} \right )
\end{split}
\end{equation*}
\sphinxAtStartPar
(Note: the form \(\frac{x_i - \hat{\mu}_x}{\hat{\sigma}_x}\) of a variable \(x\) is it’s representation in standard units, as mentioned above.)

\sphinxAtStartPar
To calculate the RMSE, we will write an \sphinxcode{\sphinxupquote{rmse}} function that makes use of sklearn’s \sphinxcode{\sphinxupquote{mean\_squared\_error}} function.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{rmse}\PYG{p}{(}\PYG{n}{target}\PYG{p}{,} \PYG{n}{pred}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sqrt}\PYG{p}{(}\PYG{n}{mean\PYGZus{}squared\PYGZus{}error}\PYG{p}{(}\PYG{n}{target}\PYG{p}{,} \PYG{n}{pred}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
To get a better idea of what the RMSE represents, the figures below show a small dataset, a proposed regression line, and the squared error that we are summing in the RMSE. The data points are


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(x\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(y\)
\\
\hline
\sphinxAtStartPar
0
&
\sphinxAtStartPar
1
\\
\hline
\sphinxAtStartPar
1
&
\sphinxAtStartPar
.5
\\
\hline
\sphinxAtStartPar
2
&
\sphinxAtStartPar
\sphinxhyphen{}1
\\
\hline
\sphinxAtStartPar
3
&
\sphinxAtStartPar
2
\\
\hline
\sphinxAtStartPar
4
&
\sphinxAtStartPar
\sphinxhyphen{}3
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Here are the proposed regression lines and their errors:






\subsubsection{Econometric Single Variable Regression}
\label{\detokenize{content/11-econometrics/single-variable:econometric-single-variable-regression}}
\sphinxAtStartPar
The regression line can have two purposes:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Of particular interest to data scientists is the line’s ability to predict values of \(y\) for new values of \(x\) that we didn’t see before.

\item {} 
\sphinxAtStartPar
Of particular interest to economists is the line’s ability to estimate the “true” underlying slope of the data via its slope.

\end{itemize}

\sphinxAtStartPar
This is why regression is such a powerful tool and forms the backbone of econometrics. If we believe that our data satisfy certain assumptions (which we won’t explore too much this lecture), then we can use the slope of the regression line to estimate the “true” relation between the variables in question and learn more about the world we live in.

\sphinxAtStartPar
In econometrics, we usually write the “true” underlying linear relationship as follows:
\begin{equation*}
\begin{split}
y = \alpha + \beta \cdot x + \varepsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
where \(y\) and \(x\) are values for any arbitrary point, \(\alpha\) is the intercept, \(\beta\) is the slope, and \(\varepsilon\) is some noise. This is entirely analogous to the code from earlier that determined the true linear relationship between the data:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{y} \PYG{o}{=} \PYG{l+m+mf}{1.5} \PYG{o}{*} \PYG{n}{x} \PYG{o}{+} \PYG{n}{noise}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here, \(\beta = 1.5\), \(\alpha = 0\), and \(\varepsilon = \text{noise}\).

\sphinxAtStartPar
When we fit a regression line onto the data, we express the line as:
\begin{equation*}
\begin{split}
\hat{y} = \hat{\alpha} + \hat{\beta} \cdot x
\end{split}
\end{equation*}
\sphinxAtStartPar
Here, we put hats over the slope and intercept terms because they are \sphinxstyleemphasis{estimates} of the true slope and intercept terms. Similarly, we put a hat over \(y\) because this is the \(y\) value that the regression line predicts.

\sphinxAtStartPar
Notice how the noise term \(\varepsilon\) does not appear in the expression for the regression line. This is because the noise term is a random variable that has no relation with \(x\), and is thus impossible to predict from the data. Furthermore, the noise term has a mean value of 0, so on average we actually don’t expect the noise term to have any impact on the underlying trends of the data.

\sphinxAtStartPar
For the Data 8 demonstration above, we forced these conditions to be true. However, with real data these are assumptions that we have to make, and is something that econometricians spend a lot of time thinking about.


\paragraph{Years of Schooling and Earnings}
\label{\detokenize{content/11-econometrics/single-variable:years-of-schooling-and-earnings}}
\sphinxAtStartPar
Consider a case where we want to study how years of schooling relate to a person’s earnings. This should be of particular interest to college students. Below we import a dataset that has the hourly wage, years of schooling, and other information on thousands of people sampled in the March 2012 Current Population Survey.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cps} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{cps.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{cps}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
state | age  | wagesal | imm  | hispanic | black | asian | educ | wage    | logwage | female | fedwkr | statewkr | localwkr
11    | 44   | 18000   | 0    | 0        | 0     | 0     | 14   | 9.10931 | 2.2093  | 1      | 1      | 0        | 0
11    | 39   | 18000   | 0    | 0        | 0     | 0     | 14   | 18      | 2.89037 | 0      | 0      | 0        | 0
11    | 39   | 35600   | 0    | 0        | 0     | 0     | 12   | 17.1154 | 2.83998 | 0      | 0      | 0        | 1
11    | 39   | 8000    | 0    | 0        | 0     | 0     | 14   | 5.12821 | 1.63476 | 1      | 0      | 0        | 0
11    | 39   | 100000  | 0    | 0        | 0     | 0     | 16   | 38.4615 | 3.64966 | 0      | 1      | 0        | 0
11    | 43   | 25000   | 0    | 0        | 0     | 0     | 12   | 10      | 2.30259 | 0      | 0      | 0        | 0
11    | 38   | 25000   | 0    | 0        | 0     | 0     | 16   | 27.1739 | 3.30226 | 1      | 0      | 0        | 0
11    | 39   | 26000   | 0    | 0        | 0     | 0     | 13   | 16.6667 | 2.81341 | 1      | 0      | 0        | 0
11    | 39   | 52000   | 0    | 0        | 0     | 0     | 16   | 16.6667 | 2.81341 | 0      | 0      | 0        | 0
11    | 37   | 4500    | 0    | 0        | 0     | 0     | 13   | 4       | 1.38629 | 1      | 0      | 0        | 0
... (21897 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
We want to consider a person’s wage and years of schooling. But first, we will convert wage to log\sphinxhyphen{}wage. Wage is a variable that we would expect to increase proportionally (or, exponentially) with changes in years of schooling. And as such, we usually take the natural log of wage instead. Below we plot log wage and years of schooling for the CPS data.

\noindent\sphinxincludegraphics{{single-variable_35_0}.png}

\sphinxAtStartPar
Now let’s fit a least\sphinxhyphen{}squares regression line onto this data. First, we’ll do it manually in the Data 8 style above.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{educ\PYGZus{}standard} \PYG{o}{=} \PYG{n}{standard\PYGZus{}units}\PYG{p}{(}\PYG{n}{educ}\PYG{p}{)}
\PYG{n}{logwage\PYGZus{}standard} \PYG{o}{=} \PYG{n}{standard\PYGZus{}units}\PYG{p}{(}\PYG{n}{logwage}\PYG{p}{)}

\PYG{n}{r} \PYG{o}{=} \PYG{n}{correlation}\PYG{p}{(}\PYG{n}{logwage\PYGZus{}standard}\PYG{p}{,} \PYG{n}{educ\PYGZus{}standard}\PYG{p}{)}
\PYG{n}{slope} \PYG{o}{=} \PYG{n}{r} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{logwage}\PYG{p}{)} \PYG{o}{/} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{educ}\PYG{p}{)}
\PYG{n}{intercept} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{logwage}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{slope} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{educ}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Slope:  0.10781133924799272
Intercept:  1.472287673006932
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{single-variable_38_1}.png}

\sphinxAtStartPar
So from the very simple and straight\sphinxhyphen{}forward model above, it seems that we estimate a slope of roughly 0.1, meaning we might expect that a one\sphinxhyphen{}year increase in schooling is associated with a 10\% increase in wage, on average.

\sphinxAtStartPar
We can also see that we have a non\sphinxhyphen{}zero intercept term. We should be careful how we interpret this term; from a strictly mathematical point of view, the intercept represents the expected value of \(y\) (in this case log wage) when \(x = 0\). However, in economics sometimes it makes no sense for \(x\) to be 0, and so we cannot use the above interpretation. We won’t go into detail this lecture, but regardless of whether the intercept is interpretable, we almost always want to include it.


\subsubsection{Uncertainty in \protect\(\hat{\beta}\protect\)}
\label{\detokenize{content/11-econometrics/single-variable:uncertainty-in-hat-beta}}
\sphinxAtStartPar
We mentioned earlier that the slope we estimate from regression is exactly that: an estimate of the “true” underlying slope. Because of this, the estimate \(\hat{\beta}\) is a random variable that depends on the underlying data.

\sphinxAtStartPar
Let’s assume there is the following true linear relation between log wage and years of schooling,
\begin{equation*}
\begin{split}
\text{logwage} = \alpha + \beta \cdot \text{years of schooling} + \varepsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
and we try to estimate \(\alpha\) and \(\beta\).

\sphinxAtStartPar
If our data are “well\sphinxhyphen{}behaved”, then even though there is uncertainty in our estimate \(\hat{\beta}\), on average \(\hat{\beta}\) will be \(\beta\); that is to say that the expectation of \(\hat{\beta}\) is \(\beta\). Additionally, if our data are “well\sphinxhyphen{}behaved”, then \(\hat{\beta}\) has some normal distribution with mean \(\beta\). We won’t worry too much about what assumptions need to be satisfied to make the data “well\sphinxhyphen{}behaved”.

\sphinxAtStartPar
You can think of each person as an observation of these variables, and using a sample of people we can estimate the relationship between the two variables. However, due to the noise term and the fact that we only have a finite sample of people, the true relationship is always hidden from us, and we can only hope to get better estimates by designing better experiments and sampling more people.

\sphinxAtStartPar
Let’s try to get an idea of how “certain” we can be of our estimate \(\hat{\beta}\). We’ll do this in classic Data 8 style: bootstrapping. Using our existing sample data, we’ll create new samples by bootstrapping from the existing data. Then, for each sample, we’ll fit a line, and keep the slope of that line in a list with all of the other slopes. Then, we’ll find the standard deviation of that list of slopes.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{slopes} \PYG{o}{=} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{educ\PYGZus{}logwage} \PYG{o}{=} \PYG{n}{cps}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{educ}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{logwage}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{42}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{200}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{educ\PYGZus{}logwage\PYGZus{}sample} \PYG{o}{=} \PYG{n}{educ\PYGZus{}logwage}\PYG{o}{.}\PYG{n}{sample}\PYG{p}{(}\PYG{p}{)}
    \PYG{n}{y} \PYG{o}{=} \PYG{n}{educ\PYGZus{}logwage\PYGZus{}sample}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{logwage}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{X} \PYG{o}{=} \PYG{n}{educ\PYGZus{}logwage\PYGZus{}sample}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{educ}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{model} \PYG{o}{=} \PYG{n}{sm}\PYG{o}{.}\PYG{n}{OLS}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{sm}\PYG{o}{.}\PYG{n}{add\PYGZus{}constant}\PYG{p}{(}\PYG{n}{X}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{p}{)}
    \PYG{n}{slopes}  \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{params}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{slopes}\PYG{p}{)}
    
\PYG{n}{Table}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}columns}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Slopes}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{slopes}\PYG{p}{)}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{p}{)}    
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Standard dev. of bootstrapped slopes: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{slopes}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Standard dev. of bootstrapped slopes:  0.0015948419317821812
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{single-variable_42_1}.png}

\sphinxAtStartPar
Our bootstrapped approximation standard error of 0.00159 is pretty close to the true standard error of 0.00144. \sphinxcode{\sphinxupquote{statsmodels}}, the package we will be using to perform regressions, actually uses a precise mathematical formula for finding the standard error whereas we tried to find this value through simulation, but the idea behind the standard error is the same.

\sphinxAtStartPar
Armed with a standard error, we can now form a 95\% confidence interval and perform a test of significance to see if \(\hat{\beta}\) is significantly different from 0.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Using our resampled slopes}
\PYG{n}{lower\PYGZus{}bound} \PYG{o}{=} \PYG{n}{percentile}\PYG{p}{(}\PYG{l+m+mf}{2.5}\PYG{p}{,} \PYG{n}{slopes}\PYG{p}{)}
\PYG{n}{upper\PYGZus{}bound} \PYG{o}{=} \PYG{n}{percentile}\PYG{p}{(}\PYG{l+m+mf}{97.5}\PYG{p}{,} \PYG{n}{slopes}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{95}\PYG{l+s+si}{\PYGZpc{} c}\PYG{l+s+s1}{onfidence interval: [}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{, }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{lower\PYGZus{}bound}\PYG{p}{,} \PYG{n}{upper\PYGZus{}bound}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
95\PYGZpc{} confidence interval: [0.1045603129388414, 0.1109373558983047]
\end{sphinxVerbatim}

\sphinxAtStartPar
The 95\% confidence interval does not contain 0, and so \(\beta\) is unlikely to be 0.


\subsubsection{Regression with a Binary Variable}
\label{\detokenize{content/11-econometrics/single-variable:regression-with-a-binary-variable}}
\sphinxAtStartPar
A binary variable is a variable that takes on the value of 1 if some condition is true, and 0 otherwise. These are also called dummy variables or indicator variables. It might sound strange at first, but you can actually perform regression of a variable like log earnings onto a binary variable.

\sphinxAtStartPar
Let’s import a different dataset that has the following features. Some will be useful to us later.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{nlsy} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{nlsy\PYGZus{}cleaned\PYGZus{}small.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{nlsy}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
male | AFQT   | real\PYGZus{}earnings\PYGZus{}1999 | weeks\PYGZus{}worked\PYGZus{}1999 | log\PYGZus{}earn\PYGZus{}1999 | college | mother\PYGZus{}college | father\PYGZus{}college
1    | 99.393 | 52354.4            | 52                | 10.8658       | 1       | 0              | 0
1    | 47.412 | 32721.5            | 52                | 10.3958       | 0       | 0              | 0
0    | 44.022 | 35862.8            | 52                | 10.4875       | 0       | 0              | 0
1    | 59.683 | 68060.7            | 52                | 11.1282       | 0       | 0              | 0
1    | 72.313 | 78531.6            | 52                | 11.2713       | 1       | 0              | 1
0    | 98.798 | 62825.3            | 52                | 11.0481       | 1       | 0              | 0
0    | 50.283 | 49736.7            | 52                | 10.8145       | 0       | 0              | 0
1    | 89.669 | 62825.3            | 52                | 11.0481       | 0       | 0              | 0
1    | 95.977 | 259311             | 52                | 12.4658       | 0       | 0              | 1
0    | 67.021 | 68060.7            | 52                | 11.1282       | 1       | 0              | 1
... (5403 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
Now let’s visualize log earnings vs. the binary variable corresponding to whether or not an observation went to college.

\noindent\sphinxincludegraphics{{single-variable_50_0}.png}

\noindent\sphinxincludegraphics{{single-variable_51_0}.png}

\sphinxAtStartPar
Now let’s fit a regression model:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{coll\PYGZus{}standard} \PYG{o}{=} \PYG{n}{standard\PYGZus{}units}\PYG{p}{(}\PYG{n}{coll}\PYG{p}{)}
\PYG{n}{logearn\PYGZus{}standard} \PYG{o}{=} \PYG{n}{standard\PYGZus{}units}\PYG{p}{(}\PYG{n}{logearn}\PYG{p}{)}

\PYG{n}{r} \PYG{o}{=} \PYG{n}{correlation}\PYG{p}{(}\PYG{n}{logearn\PYGZus{}standard}\PYG{p}{,} \PYG{n}{coll\PYGZus{}standard}\PYG{p}{)}
\PYG{n}{slope} \PYG{o}{=} \PYG{n}{r} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{logearn}\PYG{p}{)} \PYG{o}{/} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{coll}\PYG{p}{)}
\PYG{n}{intercept} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{logearn}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{slope} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{coll}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{y = }\PYG{l+s+si}{\PYGZob{}:.5f\PYGZcb{}}\PYG{l+s+s2}{ * x + }\PYG{l+s+si}{\PYGZob{}:.5f\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{slope}\PYG{p}{,} \PYG{n}{intercept}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
y = 0.72389 * x + 10.27883
\end{sphinxVerbatim}

\sphinxAtStartPar
Wow! This regression would imply that we expect, on average, observations who went to college to have 70\% higher earnings than those who did not go to college. Let’s now plot this line on the data:

\noindent\sphinxincludegraphics{{single-variable_55_0}.png}

\noindent\sphinxincludegraphics{{single-variable_56_0}.png}

\sphinxAtStartPar
When we perform a simple regression onto just a dummy variable, it is an important fact that \(\hat{\alpha}\) is the mean value of \(y\) for all observations in the sample where \(x = 0\), and \(\hat{\beta}\) is the difference between the mean value of \(y\) for observations in the sample where \(x = 1\) and observations where \(x = 0\). Proving this claim is beyond our scope this week, but let’s verify it with our data:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{avg\PYGZus{}logearn\PYGZus{}coll} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{logearn}\PYG{p}{[}\PYG{n}{coll} \PYG{o}{==} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{avg\PYGZus{}logearn\PYGZus{}nocoll} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{logearn}\PYG{p}{[}\PYG{n}{coll} \PYG{o}{==} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Avg logearn for coll = 1: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{avg\PYGZus{}logearn\PYGZus{}coll}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Avg logearn for coll = 0: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{avg\PYGZus{}logearn\PYGZus{}nocoll}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Difference between the two: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{avg\PYGZus{}logearn\PYGZus{}coll} \PYG{o}{\PYGZhy{}} \PYG{n}{avg\PYGZus{}logearn\PYGZus{}nocoll}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Avg logearn for coll = 1:  11.002722859240283
Avg logearn for coll = 0:  10.278831734712744
Difference between the two:  0.7238911245275386
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Intercept: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{intercept}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Slope: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{slope}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Intercept:  10.278831734712744
Slope:  0.72389112452754
\end{sphinxVerbatim}


\subsection{Using \sphinxstyleliteralintitle{\sphinxupquote{statsmodels}} for Regression}
\label{\detokenize{content/11-econometrics/statsmodels:using-statsmodels-for-regression}}\label{\detokenize{content/11-econometrics/statsmodels::doc}}
\sphinxAtStartPar
In the previous section, we used functions in NumPy and concepts taught in Data 8 to perform single variable regressions. It turns out that there are (several) Python packages that can perform these regressions for us and which extend nicely into the types of regressions we will cover in the next few sections. In this section, we introduce \sphinxcode{\sphinxupquote{statsmodels}} for performing single variable regressions, a foundation upon which we will build our discussion of multivariable regression.

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{statsmodels}} is a popular Python package used to create and analyze various statistical models. To create a linear regression model in \sphinxcode{\sphinxupquote{statsmodels}}, which is generally import as \sphinxcode{\sphinxupquote{sm}}, we use the following skeleton code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{x} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{n}{features}\PYG{p}{)}\PYG{o}{.}\PYG{n}{values}            \PYG{c+c1}{\PYGZsh{} Separate features (independent variables) }
\PYG{n}{y} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{n}{target}\PYG{p}{)}\PYG{o}{.}\PYG{n}{values}              \PYG{c+c1}{\PYGZsh{} Separate target (outcome variable)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{sm}\PYG{o}{.}\PYG{n}{OLS}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{sm}\PYG{o}{.}\PYG{n}{add\PYGZus{}constant}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}       \PYG{c+c1}{\PYGZsh{} Initialize the OLS regression model}
\PYG{n}{result} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{p}{)}                        \PYG{c+c1}{\PYGZsh{} Fit the regression model and save it to a variable}
\PYG{n}{result}\PYG{o}{.}\PYG{n}{summary}\PYG{p}{(}\PYG{p}{)}                            \PYG{c+c1}{\PYGZsh{} Display a summary of results}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstyleemphasis{You must manually add a constant column of all 1’s to your independent features. \sphinxcode{\sphinxupquote{statsmodels}} will not do this for you and if you fail to do this you will perform a regression without an intercept \(\alpha\) term. This is performed in the third line by calling \sphinxcode{\sphinxupquote{sm.add\_constant}} on \sphinxcode{\sphinxupquote{x}}.} Also note that we call \sphinxcode{\sphinxupquote{.values}} after we select the columns in \sphinxcode{\sphinxupquote{x}} and \sphinxcode{\sphinxupquote{y}}; this gives us \sphinxcode{\sphinxupquote{NumPy}} arrays containing the corresponding values, since \sphinxcode{\sphinxupquote{statsmodels}} can’t process \sphinxcode{\sphinxupquote{Table}}s.

\sphinxAtStartPar
Recall the \sphinxcode{\sphinxupquote{cps}} dataset we used in the previous section:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cps}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
state | age  | wagesal | imm  | hispanic | black | asian | educ | wage    | logwage | female | fedwkr | statewkr | localwkr
11    | 44   | 18000   | 0    | 0        | 0     | 0     | 14   | 9.10931 | 2.2093  | 1      | 1      | 0        | 0
11    | 39   | 18000   | 0    | 0        | 0     | 0     | 14   | 18      | 2.89037 | 0      | 0      | 0        | 0
11    | 39   | 35600   | 0    | 0        | 0     | 0     | 12   | 17.1154 | 2.83998 | 0      | 0      | 0        | 1
11    | 39   | 8000    | 0    | 0        | 0     | 0     | 14   | 5.12821 | 1.63476 | 1      | 0      | 0        | 0
11    | 39   | 100000  | 0    | 0        | 0     | 0     | 16   | 38.4615 | 3.64966 | 0      | 1      | 0        | 0
11    | 43   | 25000   | 0    | 0        | 0     | 0     | 12   | 10      | 2.30259 | 0      | 0      | 0        | 0
11    | 38   | 25000   | 0    | 0        | 0     | 0     | 16   | 27.1739 | 3.30226 | 1      | 0      | 0        | 0
11    | 39   | 26000   | 0    | 0        | 0     | 0     | 13   | 16.6667 | 2.81341 | 1      | 0      | 0        | 0
11    | 39   | 52000   | 0    | 0        | 0     | 0     | 16   | 16.6667 | 2.81341 | 0      | 0      | 0        | 0
11    | 37   | 4500    | 0    | 0        | 0     | 0     | 13   | 4       | 1.38629 | 1      | 0      | 0        | 0
... (21897 rows omitted)
\end{sphinxVerbatim}

\sphinxAtStartPar
Let’s use \sphinxcode{\sphinxupquote{statsmodels}} to perform our regression of \sphinxcode{\sphinxupquote{logwage}} on \sphinxcode{\sphinxupquote{educ}} again.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{x} \PYG{o}{=} \PYG{n}{cps}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{educ}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{values}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{cps}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{logwage}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{values}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{sm}\PYG{o}{.}\PYG{n}{OLS}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{sm}\PYG{o}{.}\PYG{n}{add\PYGZus{}constant}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{results} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{results}\PYG{o}{.}\PYG{n}{summary}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}class \PYGZsq{}statsmodels.iolib.summary.Summary\PYGZsq{}\PYGZgt{}
\PYGZdq{}\PYGZdq{}\PYGZdq{}
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R\PYGZhy{}squared:                       0.204
Model:                            OLS   Adj. R\PYGZhy{}squared:                  0.204
Method:                 Least Squares   F\PYGZhy{}statistic:                     5600.
Date:                Wed, 10 Jun 2020   Prob (F\PYGZhy{}statistic):               0.00
Time:                        10:43:19   Log\PYGZhy{}Likelihood:                \PYGZhy{}20513.
No. Observations:               21907   AIC:                         4.103e+04
Df Residuals:                   21905   BIC:                         4.105e+04
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P\PYGZgt{}|t|      [0.025      0.975]
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
const          1.4723      0.021     71.483      0.000       1.432       1.513
x1             0.1078      0.001     74.831      0.000       0.105       0.111
==============================================================================
Omnibus:                      989.972   Durbin\PYGZhy{}Watson:                   1.873
Prob(Omnibus):                  0.000   Jarque\PYGZhy{}Bera (JB):             2802.765
Skew:                           0.201   Prob(JB):                         0.00
Kurtosis:                       4.706   Cond. No.                         70.9
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
\PYGZdq{}\PYGZdq{}\PYGZdq{}
\end{sphinxVerbatim}

\sphinxAtStartPar
The summary above provides us with a lot of information. Let’s start with the most important pieces: the values of \(\hat{\alpha}\) and \(\hat{\beta}\). The middle table contains these values for us as \sphinxcode{\sphinxupquote{const}} and \sphinxcode{\sphinxupquote{x1}}’s \sphinxcode{\sphinxupquote{coef}} values: we have \(\hat{\alpha}\) is 1.4723 and \(\hat{\beta}\) is 0.1078.

\sphinxAtStartPar
Recall also our discussion of uncertainty in \(\hat{\beta}\). \sphinxcode{\sphinxupquote{statsmodels}} provides us with our calculated standard error in the \sphinxcode{\sphinxupquote{std err}} column, and we see that the standard error of \(\hat{\beta}\) is 0.001, matching our empirical estimate via bootstrapping from the last section. We can also see the 95\% confidence interval that we calculated in the two rightmost columns.

\sphinxAtStartPar
\sphinxincludegraphics{{statsmodels-coeffs}.png}

\sphinxAtStartPar
Earlier we said that \(\hat{\beta}\) has some normal distribution with mean \(\beta\) if certain assumptions are satisfied. We now can see that the standard deviation of that normal distribution is the standard error of \(\hat{\beta}\). We can also use this to test a null hypothesis that \(\beta = 0\). To do so, construct a \sphinxhref{https://en.wikipedia.org/wiki/T-statistic}{t\sphinxhyphen{}statistic} (which \sphinxcode{\sphinxupquote{statsmodels}} does for you) that indicates how many standard deviations away \(\hat{\beta}\) is from 0, assuming that the distribution of \(\hat{\beta}\) is in fact centered at 0.

\sphinxAtStartPar
We can see that \(\hat{\beta}\) is 74 standard deviations away from the null hypothesis mean of 0, which is an enormous number. How likely do you think it is to draw a random number roughly 74 standard deviations away from the mean, assuming a standard normal distribution? Essentially 0. This is strong evidence that the mean of the distribution (the mean of \(\hat{\beta}\) is the true value \(\beta\)) is not 0. Accompanying the t\sphinxhyphen{}statistic is a p\sphinxhyphen{}value that indicates the statistical significance.


\subsection{Multivariable Regression and Bias}
\label{\detokenize{content/11-econometrics/multivariable:multivariable-regression-and-bias}}\label{\detokenize{content/11-econometrics/multivariable::doc}}
\sphinxAtStartPar
Our procedure earlier showed that we expect to see roughly a 70\% increase in earnings in people who went to college vs. people who did not go to college. Does this imply that your decision to go to college was worthwhile, and now you can expect to have roughly 70\% higher earnings compared to the version of you who did not go to college?

\sphinxAtStartPar
Let’s go back to our discussion of experiments from earlier. In an ideal experiment, we would want a good sample of people who are about to graduate high school, and then randomly assign them to either a treatment group that gets sent to college, and a control group that does not. If you are in the treatment group you \sphinxstyleemphasis{must} go to college, and if you are in the control group you \sphinxstyleemphasis{cannot} go to college. Since the decision to go to college in this case is completely random, we can safely assume that the treatment and control groups are on average identical in attributes, apart from college attendance. We can therefore compare their log earnings in the future to see the effect of going to college.

\sphinxAtStartPar
Clearly this experiment is impossible to perform. We cannot randomly assign people to go to college. What’s different between this ideal experiment and our regression from earlier? What’s the issue with comparing the differences in log earnings for people in our sample who happened to go to college and those who did not?

\sphinxAtStartPar
In our sample, the treatment (went to college) and control (did not go to college) groups are not identical in every way except for college! People aren’t randomly assigned college, they \sphinxstyleemphasis{choose} to go to college. The factors that cause someone to go to college are complex and lead to differences between people who chose to go to college and those who did not. When we perform regression on the variable \sphinxcode{\sphinxupquote{college}}, since the groups in the sample are different, not only are we capturing the effect of going to college, but we are also capturing the effects of everything else that is different about the two groups that also affects earnings.

\sphinxAtStartPar
Imagine another variable that captures the wealth of your family. College can be very expensive, so it might be the case that the wealthier your family is, the more likely you are to go to college. Also, it’s easy to imagine that the wealthier your family is, the wealthier you are likely to be in the future. This implies that the group of people in the sample who went to college will tend to be wealthier than the group that did not. Also, the group of people who went to college is expected to earn more not necessarily because they went to college, but simply because they are wealthier.

\sphinxAtStartPar
Therefore, when we do regression to measure the differences in earnings between people who went to college and those who did not, we also capture differences in earnings between people who grew up wealthier and those who did not. Because of this, we \sphinxstyleemphasis{over\sphinxhyphen{}estimate} the effect of going to college. \(\hat{\beta}\) captures the average observed benefit of going to college \sphinxstyleemphasis{and} being wealthier, but we’re only interested in college. This is called \sphinxstyleemphasis{omitted variable bias}. Family wealth is an omitted variable in this regression and it’s causing our results to be biased.

\sphinxAtStartPar
Let’s think of another example of omitted variable bias. In the NLSY dataset, there is a variable called \sphinxcode{\sphinxupquote{AFQT}}. AFQT is a score on a particular standardized test that all people in the sample took. Let’s use AFQT as a proxy measurement for the abstract idea of academic capability. While a standardized test is by no means the sole indication of someone’s ability or intelligence, let’s ignore that very complicated issue for now and assume that AFQT does an O.K. job at capturing this ability variable that is otherwise very difficult to measure.

\sphinxAtStartPar
Is there omitted variable bias from AFQT? Almost certainly. It seems fair to believe that people who choose to go to college are on average more academically\sphinxhyphen{}capable, and it also seems fair to say that on average we expect more capable people to earn more. Therefore, \(\hat{\beta}\) above might be capturing the effects of being more capable, along with the effects of going to college.

\sphinxAtStartPar
How can we fix this issue? Multivariable regression.


\subsubsection{Multivariable Regression}
\label{\detokenize{content/11-econometrics/multivariable:multivariable-regression}}
\sphinxAtStartPar
So far we have only been regressing outcome variable \(y\) onto one explanatory variable \(x\). To find the regression line, we choose \(\hat{\alpha}\) and \(\hat{\beta}\) that minimize the mean squared error. But what if we believe that \(y\) is actually determined by two variables, \(x_1\) and \(x_2\)? Specifically, what if the “true” model is
\begin{equation*}
\begin{split}
y = \alpha + \beta_1 x_{1} + \beta_2 x_{2} + \epsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
and we would like to estimate
\begin{equation*}
\begin{split}
\hat{y} = \hat{\alpha} + \hat{\beta}_1 x_{1} + \hat{\beta}_2 x_{2}
\end{split}
\end{equation*}
\sphinxAtStartPar
Now our challenge is choosing \(\hat{\alpha}\), \(\hat{\beta}_1\), \sphinxstyleemphasis{and} \(\hat{\beta}_2\) that minimize the mean squared error. To this end, we will use the \sphinxcode{\sphinxupquote{minimize}} function to minimize a function \sphinxcode{\sphinxupquote{to\_minimize}} that takes in model parameters and returns the model’s RMSE.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{rmse}\PYG{p}{(}\PYG{n}{target}\PYG{p}{,} \PYG{n}{pred}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sqrt}\PYG{p}{(}\PYG{n}{mean\PYGZus{}squared\PYGZus{}error}\PYG{p}{(}\PYG{n}{target}\PYG{p}{,} \PYG{n}{pred}\PYG{p}{)}\PYG{p}{)} 

\PYG{k}{def} \PYG{n+nf}{to\PYGZus{}minimize}\PYG{p}{(}\PYG{n}{intercept}\PYG{p}{,} \PYG{n}{beta\PYGZus{}1}\PYG{p}{,} \PYG{n}{beta\PYGZus{}2}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{predictions} \PYG{o}{=} \PYG{n}{intercept} \PYG{o}{+} \PYG{n}{beta\PYGZus{}1} \PYG{o}{*} \PYG{n}{nlsy}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{college}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} \PYG{o}{+} \PYG{n}{beta\PYGZus{}2} \PYG{o}{*} \PYG{n}{nlsy}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{AFQT}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{actual} \PYG{o}{=} \PYG{n}{nlsy}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{log\PYGZus{}earn\PYGZus{}1999}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{rmse}\PYG{p}{(}\PYG{n}{predictions}\PYG{p}{,} \PYG{n}{actual}\PYG{p}{)}

\PYG{n}{minimize}\PYG{p}{(}\PYG{n}{to\PYGZus{}minimize}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([9.95595982e+00, 4.30179178e\PYGZhy{}01, 8.37569589e\PYGZhy{}03])
\end{sphinxVerbatim}

\sphinxAtStartPar
We see that \sphinxcode{\sphinxupquote{minimize}} return an \(\hat{\alpha}\) of 9.956, a \(\hat{\beta}_1\) of 0.430, and a \(\hat{\beta}_2\) of 0.008. Let’s perform the regression using \sphinxcode{\sphinxupquote{statsmodels}} and see what we get.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{y} \PYG{o}{=} \PYG{n}{nlsy}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{log\PYGZus{}earn\PYGZus{}1999}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{values}
\PYG{n}{X} \PYG{o}{=} \PYG{n}{nlsy}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{college}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFQT}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{values}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{sm}\PYG{o}{.}\PYG{n}{OLS}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{sm}\PYG{o}{.}\PYG{n}{add\PYGZus{}constant}\PYG{p}{(}\PYG{n}{X}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{summary}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}class \PYGZsq{}statsmodels.iolib.summary.Summary\PYGZsq{}\PYGZgt{}
\PYGZdq{}\PYGZdq{}\PYGZdq{}
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R\PYGZhy{}squared:                       0.126
Model:                            OLS   Adj. R\PYGZhy{}squared:                  0.125
Method:                 Least Squares   F\PYGZhy{}statistic:                     388.5
Date:                Sun, 19 Jul 2020   Prob (F\PYGZhy{}statistic):          2.12e\PYGZhy{}158
Time:                        14:07:49   Log\PYGZhy{}Likelihood:                \PYGZhy{}7421.0
No. Observations:                5413   AIC:                         1.485e+04
Df Residuals:                    5410   BIC:                         1.487e+04
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P\PYGZgt{}|t|      [0.025      0.975]
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
const          9.9563      0.025    401.520      0.000       9.908      10.005
x1             0.4301      0.037     11.731      0.000       0.358       0.502
x2             0.0084      0.001     16.083      0.000       0.007       0.009
==============================================================================
Omnibus:                     2898.806   Durbin\PYGZhy{}Watson:                   1.923
Prob(Omnibus):                  0.000   Jarque\PYGZhy{}Bera (JB):            34192.355
Skew:                          \PYGZhy{}2.307   Prob(JB):                         0.00
Kurtosis:                      14.415   Cond. No.                         155.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
\PYGZdq{}\PYGZdq{}\PYGZdq{}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here \(\hat{\beta}_1\) is 0.43, compared to 0.72 from the earlier biased (single variable) regression. That’s huge! This implies that when we control for a person’s ability (i.e. we get rid of that source of bias), we only see that on average going to college is associated with a 43\% increase in earnings instead of 72\%. Furthermore, looking at the 95\% confidence interval for \(\hat{\beta}_2\), we see that it does not contain 0, which would imply that AFQT score has a strong non\sphinxhyphen{}zero association with earnings.

\sphinxAtStartPar
These observations validate our claim that AFQT was probably an omitted variable causing \(\hat{\beta}_1\) to be biased. When interpreting \(\hat{\beta}\) coefficients, you should always be mindful of potential sources of bias that could make your coefficients misleading and not useful from an econometric context.

\sphinxAtStartPar
\sphinxstylestrong{Note:} A linear regression model makes predictions for \(y\) which we’ve been calling \(\hat{y}\). If you imagine that you are the model and are tasked with predicting people’s earnings, you will almost certainly want more than just their years of schooling to make an accurate prediction. The more relevant variables you are given, the better predictions you are likely to make compared to just using one variable. The Variable needs to be relevant though; the day of the week a person was born on is probably not useful in predicting earnings. This is just another way of thinking about the usefulness of multivariable regression.


\paragraph{Visualizing Multivariable Regression}
\label{\detokenize{content/11-econometrics/multivariable:visualizing-multivariable-regression}}
\sphinxAtStartPar
The 3D plots below show us our variables of interest and the regression plane from two different angles.

\noindent\sphinxincludegraphics{{multivariable_11_0}.png}

\noindent\sphinxincludegraphics{{multivariable_12_0}.png}

\noindent\sphinxincludegraphics{{multivariable_13_0}.png}

\sphinxAtStartPar
The regression plane, instead of the regression line, represents the values for log earnings that the regression model would predict for any given college and AFQT input. It’s a plane now because there are two possible inputs, as opposed to one.


\subsubsection{Colinearity and Dummy Variables}
\label{\detokenize{content/11-econometrics/multivariable:colinearity-and-dummy-variables}}
\sphinxAtStartPar
When we do regression onto the variable \sphinxcode{\sphinxupquote{college}}, why don’t we also include a variable that measures not going to college? In other words, why don’t we regress on college and the opposite of college so that way we can get an estimate of the average earnings of college\sphinxhyphen{}goers and non\sphinxhyphen{}college\sphinxhyphen{}goers. Why do we do this roundabout way of using the intercept term and a difference in means?

\sphinxAtStartPar
Imagine we have a dataset with a variable for college, a variable for not going to college, and the intercept term. The issue with this is that there is now redundant information.

\sphinxAtStartPar
Let’s look at just one element of the sample. Let’s say this person went to college, so this person’s features are the following:
\begin{itemize}
\item {} 
\sphinxAtStartPar
College = 1

\item {} 
\sphinxAtStartPar
Not College = 0

\item {} 
\sphinxAtStartPar
Intercept term = 1

\end{itemize}

\sphinxAtStartPar
Clearly there is a redundancy here; you can guess one of the variables from the others. More specifically, by redundancy we mean that \sphinxstyleemphasis{one variable can be written as a linear combination of the other variables}. In fact, there are three different combinations:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Intercept = College + Not College

\item {} 
\sphinxAtStartPar
Not College = Intercept \sphinxhyphen{} College

\item {} 
\sphinxAtStartPar
College = Intercept \sphinxhyphen{} Not College

\end{itemize}

\sphinxAtStartPar
These equalities aren’t just true for this one person; they actually hold true for any possible person in the sample. This is because of the way we defined “college” and “not college”. You can’t simultaneously be in both, and so adding them together you get 1, which is just the intercept term.

\sphinxAtStartPar
In general, we have redundancy whenever we have \sphinxstyleemphasis{mutually exclusive} and \sphinxstyleemphasis{exhaustive} dummy variables in combination with an intercept term.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Mutually exclusive: You cannot be in more than one dummy variable.

\item {} 
\sphinxAtStartPar
Exhaustive: You must be in at least one dummy variable.

\end{itemize}

\sphinxAtStartPar
You can see that “college” and “not college” satisfy these conditions. So why is this redundancy an issue? It becomes ambiguous what the values for \(\hat{\alpha}\), \(\hat{\beta}_1\), and \(\hat{\beta}_2\) should be in the model where we include all three terms:
\begin{equation*}
\begin{split}
\text{log earnings} = \hat{\alpha} + \hat{\beta}_1 \text{college} + \hat{\beta}_2 \text{not college}
\end{split}
\end{equation*}
\sphinxAtStartPar
Consider a case where we expect people who went to college to have log earnings of 10 and those who did not go to college to have log earnings of 8. What values for \(\hat{\beta}\) and \(\hat{\alpha}\) make sense?
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\hat{\beta}_1 = 10\)

\item {} 
\sphinxAtStartPar
\(\hat{\beta}_2 = 8\)

\item {} 
\sphinxAtStartPar
\(\hat{\alpha} = 0\)

\end{itemize}

\sphinxAtStartPar
make sense. These are valid values for \(\hat{\beta}\) and \(\hat{\alpha}\) that satisfy the condition above. To see why, consider a person with college:
\begin{equation*}
\begin{split}\begin{aligned}
\text{log earnings} &= \hat{\alpha} + \hat{\beta}_1 \cdot 1 + \hat{\beta}_2 \cdot 0 \\
\text{log earnings} &= \hat{\alpha} + \hat{\beta}_1 \\
\text{log earnings} &= 0 + 10 = 10
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
and a person without college:
\begin{equation*}
\begin{split}\begin{aligned}
\text{log earnings} &= \hat{\alpha} + \hat{\beta}_1 \cdot 0 + \hat{\beta}_2 \cdot 1 \\
\text{log earnings} &= \hat{\alpha} + \hat{\beta}_2 \\
\text{log earnings} &= 0 + 8 = 8
\end{aligned}\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\hat{\beta}_1 = 2\)

\item {} 
\sphinxAtStartPar
\(\hat{\beta}_2 = 0\)

\item {} 
\sphinxAtStartPar
\(\hat{\alpha} = 8\)

\end{itemize}

\sphinxAtStartPar
also make sense. To see why, consider a person with college:
\begin{equation*}
\begin{split}\begin{aligned}
\text{log earnings} &= \hat{\alpha} + \hat{\beta}_1 \cdot 1 + \hat{\beta}_2 \cdot 0 \\
\text{log earnings} &= \hat{\alpha} + \hat{\beta}_1 \\
\text{log earnings} &= 8 + 2 = 10
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
and a person without college:
\begin{equation*}
\begin{split}\begin{aligned}
\text{log earnings} &= \hat{\alpha} + \hat{\beta}_1 \cdot 0 + \hat{\beta}_2 \cdot 1 \\
\text{log earnings} &= \hat{\alpha} + \hat{\beta}_2 \\
\text{log earnings} &= 8 + 0 = 8
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
It turns out, there are actually infinitely many solutions for \(\hat{\beta}\) that satisfy the condition where people who went to college have mean log earnings of 10 and people who did not go to college have mean log earnings of 8. This holds true for all situations where you regress on a constant and a set of mutually exclusive and exhaustive dummies. There is no unique solution for \(\hat{\beta}\), which is a problem for econometricians who want unique and interpretable coefficients.

\sphinxAtStartPar
In fact, there is mathematical justification for this as well. At some point in the math involved in performing regression, having redundant variables causes a division by 0. This is particularly upsetting for your computer, and it will complain.

\sphinxAtStartPar
So how do we avoid this problem? We deliberately exclude one of the variables. It can technically either be one of the dummy variables or the intercept term, but we usually really want to have an intercept term present in our regression for other reasons. So we usually get rid of one of the dummy variables. Notice that we implicitly did this earlier. We did not include “not college” in our first regression.


\subsection{Reading Economics Papers}
\label{\detokenize{content/11-econometrics/reading-econ-papers:reading-economics-papers}}\label{\detokenize{content/11-econometrics/reading-econ-papers::doc}}
\sphinxAtStartPar
In upper division economics courses, you’ll often read economics papers that utilize ordinary least squares to conduct regression. Now that we have familiarized ourselves with multi\sphinxhyphen{}variate regression, let’s familiarize ourselves with reading the results of economics papers!

\sphinxAtStartPar
Let’s consider an existing empirical study conducted by David Card {[}\hyperlink{cite.content/references:id2}{Car99}{]}, a Nobel Prize winning professor at UC Berkeley, that regresses income on education:

\sphinxAtStartPar
\sphinxincludegraphics{{FPLII4s}.png}

\sphinxAtStartPar
Every column here is from a different regression: the first column predicts the log hourly earnings from years of education, the fifth column predicts the log annual earnings from years of education, and so on. For now, let’s focus on the first column, which states the linear regression as follows:
\begin{equation*}
\begin{split}
\ln{(\text{hourly earnings})_i} = \alpha + \beta \cdot (\text{years of schooling})_i + \varepsilon_i
\end{split}
\end{equation*}
\sphinxAtStartPar
From the table, the education coefficient is 0.100, with a (0.001) underneath it. This means that our \(\beta\) value is equal to 0.100. What does the (0.001) mean? It is the standard error, which is essentially a measure of our uncertainty. From Data 8, the standard error is most similar to the standard deviation of sample means, which is a measure of the spread in the population mean. Similarly, the the standard error here is a measure of the spread in the population coefficient. We can use the standard error to construct a confidence interval of the actual coefficient: a 95\% confidence interval is between 2 standard errors above and below the reported value.

\sphinxAtStartPar
The effects of schooling on income is captured by the education coefficient term: 0.100. This means that an increase in 1 unit (year) of education is correlated with a log hourly earnings by 0.1. This approximately corresponds to a 10\% increase in wages per year of schooling.


\section{Environmental Economics}
\label{\detokenize{content/12-environmental/index:environmental-economics}}\label{\detokenize{content/12-environmental/index::doc}}
\sphinxAtStartPar
\sphinxincludegraphics{{windmills}.png}

\sphinxAtStartPar
In a broad sense, the field of Environmental Economics aims to relate and apply economic concepts to the environment.

\sphinxAtStartPar
One tenet of Environmental Economics is that the enjoyment of “environmental amenities”   (or conversely that the usage or degradation  of those resources) has an intrinsic value to humans that goes unaccounted for in the purely market\sphinxhyphen{}based model. These unaccounted costs are considered \sphinxstyleemphasis{market failures} and carry \sphinxstyleemphasis{negative externalities}.

\sphinxAtStartPar
The greatest single example of a negative externality of global importance is the emission of greenhouse gases (carbon dioxide, methane, nitrous oxide) from the combustion of hydrocarbons (coal, gasoline, diesel, oil). The \sphinxstyleemphasis{true cost}  is not reflected in the lower price one pays at e.g the gas station. Consequently, the equilibrium quantity consumed is higher than the \sphinxstyleemphasis{socially optimal quantity}. Environmental economists seek to model the costs and benefits of a reduction.  How could we reduce the quantity to the social optimum and weigh in the \sphinxstyleemphasis{costs and benefits} of such a reduction?

\sphinxAtStartPar
As a result, a major proportion of research and work within the field is devoted to building tools to reveal, address, and evaluate economic policies aimed at \sphinxstyleemphasis{internalizing} these externalities.

\sphinxAtStartPar
Very often, these policy tools as applied by a government constitute interfering with the market to a varying degree. We can model environmental economic policies into two subsets:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Command and Control}: When the government limits the amount of pollution to control a negative externality, e.g letting each emitter in the market emit a fixed amount of GHG gases.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Market\sphinxhyphen{}based}: Where the government sets an emission goal, then introduces incentives or subsidies to alter market behavior. It is left to each market actor to decide how much to emit. A carbon tax and a cap\sphinxhyphen{}and\sphinxhyphen{}trade (carbon quotas) are examples of marked\sphinxhyphen{}based interventions.

\end{itemize}

\sphinxAtStartPar
A useful environmental economic model is \sphinxstylestrong{The Marginal Abatement Cost Curve (MAC)} which aims to describe the \sphinxstyleemphasis{cost of abatement} (not emitting) greenhouse gases into the atmosphere using various strategies. A famous version of this was contained in a report  McKinsey 2009 “Pathways to a Low Carbon Economy”.  This example we will discuss as an  example of the intersection between of Environmental Economics and Data Science. In this notebook, we’ll walk through the concepts of it and build one of our own!

\sphinxAtStartPar
Related to the discussion of global greenhouse gas emissions, we will also explore the \sphinxstylestrong{Environmental Kuznets Curve} through data, and compare the pathways of increasing emissions across countries and across time.

\sphinxAtStartPar
These are only a few of the applications of environmental economics, there are many more fields to explore, and even an entire major at UC Berkeley to explore.

\sphinxAtStartPar
\sphinxstylestrong{Student Learning Outcomes:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
An introduction to applications  of Environmental Economics with illustrations from global CO2 emissions

\item {} 
\sphinxAtStartPar
Motivation and understanding of the  Marginal Abatement Cost Curve for global Greenhouse Gas emissions, first by the (McKinsey 2009) curve for CO2, and then an application for Methane its data science application.

\item {} 
\sphinxAtStartPar
A discussion of the Marginal Abatement Curve’s limitations with the concept of Capital Intensity and static vs dynamic costs.

\item {} 
\sphinxAtStartPar
An understanding of the Environmental Kuznets Curve Hypothesis and its data science applications

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} HIDDEN}
\PYG{c+c1}{\PYGZsh{}Import packages}
\PYG{k+kn}{from} \PYG{n+nn}{datascience} \PYG{k+kn}{import} \PYG{o}{*}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline 

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k+kn}{import} \PYG{n}{patches}
\end{sphinxVerbatim}


\subsection{Marginal Abatement Cost Curves}
\label{\detokenize{content/12-environmental/textbook1:marginal-abatement-cost-curves}}\label{\detokenize{content/12-environmental/textbook1::doc}}

\subsubsection{Marginal Cost}
\label{\detokenize{content/12-environmental/textbook1:marginal-cost}}
\sphinxAtStartPar
As of know, you should be familiar with the economic concept of \sphinxstylestrong{marginal cost}. The classical textbook example is a production factory, so let’s call ours Peter’s Pens Limited. Whenever Peter’s Pens’ management is deciding whether or not to increase production to maximize their profit, they observe the firm’s marginal cost: the change in its \sphinxstylestrong{total cost} that occurs as 1 more pen is produced. In this case, we measure the marginal cost in \$ / per extra pen produced. In environmental economics, we talk about the \sphinxstylestrong{marginal cost of emissions} and the \sphinxstylestrong{marginal cost of emission abatement}. We think of it as follows:
\begin{equation*}
\begin{split} \text{MC of Emissions (\$/ton)} = \frac{\text{$\Delta$ Cost of Emissions (\$)}}{\text{$\Delta$ Quantity of Emissions (tons)}}\end{split}
\end{equation*}
\sphinxAtStartPar
And:
\begin{equation*}
\begin{split} \text{MC of Emission Abatement (\$/ton)} = \frac{\text{$\Delta$ Cost of Emissions Abatement (\$)}}{\text{$\Delta$ Quantity of Emission Abated (tons)}}\end{split}
\end{equation*}

\subsubsection{Government Intervention}
\label{\detokenize{content/12-environmental/textbook1:government-intervention}}
\sphinxAtStartPar
Let’s say that Peter’s Pens Limited is operating in a market where the government aims to make firms \sphinxstylestrong{internalize} the negative externality created by \(CO_2\) pollution from their production. From earlier, we know that the government may choose between \sphinxstylestrong{prescriptive} or \sphinxstylestrong{market\sphinxhyphen{}based} policies, but for this case we assume they chose the latter. In that case, the government introduces a \sphinxstyleemphasis{Pigouvian tax} on per ton of \(CO_2\) emitted from all firms. As any Pigouvian tax, its rate is set to the \sphinxstyleemphasis{social marginal cost of the negative externality} it is set to internalize. This is the \sphinxstyleemphasis{social cost of carbon}, quantified by extensive research. In the big picture, it pushes the private marginal cost towards the higher social marginal cost of emissions. As with any price increase, we assume the ‘supplied’ quantity of emissions to be pushed leftwards (decreased). This results in a new equilibrium quantity of emissions at a higher price (= social marginal cost) and the quantity reached becomes the \sphinxstyleemphasis{optimal quantity} of emissions in society. Now, how does the management of Peter’s Pens Limited react to the new market conditions?

\sphinxAtStartPar
\sphinxincludegraphics{{tax}.png}


\paragraph{The Firm’s Reaction}
\label{\detokenize{content/12-environmental/textbook1:the-firms-reaction}}
\sphinxAtStartPar
From a ‘bottom\sphinxhyphen{}up\sphinxhyphen{}perspective’, the management at Peter’s Pens Limited is faced with two choices in reaction to the new emissions tax: The Business\sphinxhyphen{}as\sphinxhyphen{}Usual (BAU) alternative or the Emissions Abatement alternative. The firm can either choose to continue emitting and pay the tax or invest in new, environmentally friendly technologies that abate their \(CO_2\) emissions. A rational decision maker ought to invest in abatement technologies with a marginal cost of abatement up to the emissions tax put in place. Assuming they chose to pursue the latter, how would they prioritize investments within the firm? By observing the cost and abatement potential of each investment, the firm sorts its options from cheapest to most expensive and starts ‘picking’ the low\sphinxhyphen{}hanging fruits of \(CO_2\) abatement. At any given carbon tax rate, they reduce their tax bill to \$0 and observe their total abatement as the sum of all technologies invested in. The resulting plot: The Marginal Abatement Cost (MAC) Curve of Peter’s Pens Limited. Here’s how a simple MAC for Peter’s Pens might look:

\sphinxAtStartPar
\sphinxincludegraphics{{SampleMACC_Nov23}.png}

\sphinxAtStartPar
In this example, the firm has a few activities with a low cost of abatement, and then a few with higher cost of abatement. It would make sense for the firm to start with the lowest cost of abatement first.


\paragraph{Back to the Government}
\label{\detokenize{content/12-environmental/textbook1:back-to-the-government}}
\sphinxAtStartPar
Returning to the government policymaker’s perspective, we can motivate this approach to a market wide perspective. Just as Peter’s Pens has their firm\sphinxhyphen{}specific MAC, society as a whole has one. Through research on policy and technological interventions, an environmental data science team can quantify the \sphinxstyleemphasis{abatement potential} and the \sphinxstyleemphasis{abatement cost} of different technologies (e.g electric cars, wind \& solar power generation), policies (e.g fuel standards), and land management projects (e.g  soil restoration). From here, public policy can start  ‘picking’ the low\sphinxhyphen{}hanging fruits of the lowest cost technology first.

\sphinxAtStartPar
Earlier, we described the effect of introducing a tax on the emissions ‘market’ and observed how rational decision\sphinxhyphen{}makers in individual firms react by constructing their own MAC curves. Now, let’s say that the government has set an emission reduction target but has not decided on a specific tax rate yet. How could they guarantee that the target is met? By taking the cumulative sum of the abatement potential of each intervention they expect to take place at a given rate, they should keep doing so until their sum equals the emission reduction target. From there, they observe the marginal abatement cost of the last intervention they added to the sum. This could be a way to set the emissions tax rate. Here’s how a simplified version could look:

\sphinxAtStartPar
\sphinxincludegraphics{{image}.png}


\paragraph{Conclusion}
\label{\detokenize{content/12-environmental/textbook1:conclusion}}
\sphinxAtStartPar
In conclusion, both an individual firm and society as a whole could be modeled to have MAC curves. By either choosing an emission reduction target or a emissions tax rate, one can arrive at a lowest cost level of abatement. Whenever an emission tax is introduced to the market, rational firms build their MAC curves and start investing in the cheapest relevant technologies up to the level of the given tax rate to avoid paying the tax. A rational policy maker can map out the different abatement opportunities in a society as a whole and prioritize the cheapest alternatives. Public policy could stop emissions abatement when the technology or policy we invest in has a higher marginal cost than the societal marginal cost of emissions. From there, any intervention reduces either individual (firm) or societal welfare.

\sphinxAtStartPar
Now, let’s delve deeper into the  MAC curve and build one of our own for Methane Abatement.


\subsubsection{The McKinsey Marginal Abatement Cost Curve (MAC)}
\label{\detokenize{content/12-environmental/textbook1:the-mckinsey-marginal-abatement-cost-curve-mac}}
\sphinxAtStartPar
As earlier described, the Marginal Abatement Cost Curve gives policy makers and firms an opportunity to differentiate the costs of the multiple approaches we have in reducing our carbon (CO2) emissions. It shows where society can get the best “bang for the buck” when the goal is to abate carbon emissions. The \sphinxstylestrong{Abatement Potential (GtCO2 per year)} follows the x\sphinxhyphen{}axis, and the ** Marginal Abatement Cost (€ per ton of CO2)** lies on the y\sphinxhyphen{}axis.

\sphinxAtStartPar
Each rectangle represents a specific technology or policy (e.g switch to LED lights or install Carbon Capture Systems (CCS) in older coal plants). The \sphinxstyleemphasis{wider} the rectangle, the \sphinxstyleemphasis{larger} the abatement potential, and the \sphinxstyleemphasis{taller} the rectangle, the \sphinxstyleemphasis{higher} abatement cost for that specific intervention.

\sphinxAtStartPar
Below you’ll find a very influential MAC out there, the McKinsey MAC from 2009. It has the goal of showing the tradoffs in a single visualization of GHG emissions across a variety of sectors and across all countries. A policy maker, or innovator, or investor could decide to focus on areas where GHG emissions can be reduced at a low cost.

\sphinxAtStartPar
\sphinxincludegraphics{{mac}.png}


\paragraph{Why are some costs negative?}
\label{\detokenize{content/12-environmental/textbook1:why-are-some-costs-negative}}
\sphinxAtStartPar
Something that understandably strikes a lot of observers from the plot above is the concept of \sphinxstyleemphasis{negative costs}. Take LEDs (about \sphinxhyphen{} €100 per tCO2) for instance: The negative cost here entails that for every investment that reduces CO2 from traditional lightning by 1 ton CO2, the investor receives a €100 saving. In one sense these are all investments that should happen regardless of the GHG consequences they make economic sense. One way to motivate this is that the decision maker may not be able to see the long term benefits in a short\sphinxhyphen{}term decision making framework. People dont rush out to buy \$5 LED light bulbs when they have working incandescent light bulbs.

\sphinxAtStartPar
The cause of negative costs are disputed, but a commonly used idea is that within our current market model, there exists \sphinxstyleemphasis{inefficiencies} such as lack of incentives or information that prohibit market participants from taking the full advantage of the returns offered from investing in technologies with negative costs.


\subsubsection{Constructing a MAC for Methane Gas Abatement}
\label{\detokenize{content/12-environmental/textbook1:constructing-a-mac-for-methane-gas-abatement}}
\sphinxAtStartPar
For an illustrative example we will construct a Marginal Abatement Curve for Methane emissions from the Oil and Gas Sector.We start by importing a dataset on methane abatement from the International Environmental Agency (IEA):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{abatement\PYGZus{}table} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{abatement\PYGZus{}data.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Cost}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{are}\PYG{o}{.}\PYG{n}{between}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{10.1}\PYG{p}{,}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Possible Savings}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{below}\PYG{p}{(}\PYG{l+m+mi}{200}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Possible Savings}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Potential}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{relabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Cost}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Cost}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{abatement\PYGZus{}table}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Country | Region       | Oil Gas | Production source        | Upstream Downstream | Reason | Abatement technology                | Abatement Potential | Abatement Cost
Japan   | Asia Pacific | Gas     | Onshore conventional gas | Upstream            | Vented | Replace pumps                       | 0.25                | \PYGZhy{}6.2
Japan   | Asia Pacific | Oil     | Onshore conventional oil | Upstream            | Vented | Blowdown capture                    | 0                   | \PYGZhy{}6.18
Japan   | Asia Pacific | Gas     | Offshore gas             | Upstream            | Vented | Replace with instrument air systems | 0.02                | \PYGZhy{}5.84
Japan   | Asia Pacific | Oil     | Offshore oil             | Upstream            | Vented | Replace with instrument air systems | 0.01                | \PYGZhy{}5.84
Japan   | Asia Pacific | Gas     | Downstream gas           | Downstream          | Vented | Replace with instrument air systems | 0.62                | \PYGZhy{}5.84
Japan   | Asia Pacific | Oil     | Offshore oil             | Upstream            | Vented | Replace compressor seal or rod      | 0                   | \PYGZhy{}5.58
Japan   | Asia Pacific | Gas     | Offshore gas             | Upstream            | Vented | Replace compressor seal or rod      | 0                   | \PYGZhy{}5.58
Japan   | Asia Pacific | Gas     | Onshore conventional gas | Upstream            | Vented | Blowdown capture                    | 0.59                | \PYGZhy{}5.57
India   | Asia Pacific | Gas     | Offshore gas             | Upstream            | Vented | Replace with instrument air systems | 2.75                | \PYGZhy{}5.33
India   | Asia Pacific | Gas     | Downstream gas           | Downstream          | Vented | Replace with instrument air systems | 0.91                | \PYGZhy{}5.33
... (8887 rows omitted)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{selection} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Asia Pacific}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{Group} \PYG{o}{=} \PYG{n}{abatement\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Region}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{selection}\PYG{p}{)}
\PYG{n}{Group}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Country | Region       | Oil Gas | Production source        | Upstream Downstream | Reason | Abatement technology                | Abatement Potential | Abatement Cost
Japan   | Asia Pacific | Gas     | Onshore conventional gas | Upstream            | Vented | Replace pumps                       | 0.25                | \PYGZhy{}6.2
Japan   | Asia Pacific | Oil     | Onshore conventional oil | Upstream            | Vented | Blowdown capture                    | 0                   | \PYGZhy{}6.18
Japan   | Asia Pacific | Gas     | Offshore gas             | Upstream            | Vented | Replace with instrument air systems | 0.02                | \PYGZhy{}5.84
Japan   | Asia Pacific | Oil     | Offshore oil             | Upstream            | Vented | Replace with instrument air systems | 0.01                | \PYGZhy{}5.84
Japan   | Asia Pacific | Gas     | Downstream gas           | Downstream          | Vented | Replace with instrument air systems | 0.62                | \PYGZhy{}5.84
Japan   | Asia Pacific | Oil     | Offshore oil             | Upstream            | Vented | Replace compressor seal or rod      | 0                   | \PYGZhy{}5.58
Japan   | Asia Pacific | Gas     | Offshore gas             | Upstream            | Vented | Replace compressor seal or rod      | 0                   | \PYGZhy{}5.58
Japan   | Asia Pacific | Gas     | Onshore conventional gas | Upstream            | Vented | Blowdown capture                    | 0.59                | \PYGZhy{}5.57
India   | Asia Pacific | Gas     | Offshore gas             | Upstream            | Vented | Replace with instrument air systems | 2.75                | \PYGZhy{}5.33
India   | Asia Pacific | Gas     | Downstream gas           | Downstream          | Vented | Replace with instrument air systems | 0.91                | \PYGZhy{}5.33
... (1915 rows omitted)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}The find\PYGZus{}x\PYGZus{}pos function used for plotting! (out of scope)}

\PYG{k}{def} \PYG{n+nf}{find\PYGZus{}x\PYGZus{}pos}\PYG{p}{(}\PYG{n}{widths}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{cumulative\PYGZus{}widths} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{n}{cumulative\PYGZus{}widths}\PYG{o}{.}\PYG{n}{extend}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{cumsum}\PYG{p}{(}\PYG{n}{widths}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{half\PYGZus{}widths} \PYG{o}{=} \PYG{p}{[}\PYG{n}{i}\PYG{o}{/}\PYG{l+m+mi}{2} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n}{widths}\PYG{p}{]}
    \PYG{n}{x\PYGZus{}pos} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{half\PYGZus{}widths}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{x\PYGZus{}pos}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{half\PYGZus{}widths}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{+} \PYG{n}{cumulative\PYGZus{}widths}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{x\PYGZus{}pos}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}Prepare the data for plotting}
\PYG{n}{width\PYGZus{}group} \PYG{o}{=} \PYG{n}{Group}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Potential}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{height\PYGZus{}group} \PYG{o}{=} \PYG{n}{Group}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Cost}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{new\PYGZus{}x\PYGZus{}group} \PYG{o}{=} \PYG{n}{find\PYGZus{}x\PYGZus{}pos}\PYG{p}{(}\PYG{n}{width\PYGZus{}group}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
With the following function, we introduce an arbritary level of taxation to measure the total abatement outcome later.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}The methane\PYGZus{}tax function \PYGZhy{}\PYGZhy{} Let\PYGZsq{}s introduce a tax!}
\PYG{k}{def} \PYG{n+nf}{methane\PYGZus{}tax}\PYG{p}{(}\PYG{n}{tax}\PYG{p}{,} \PYG{n}{table}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{if} \PYG{n}{tax} \PYG{o}{\PYGZlt{}} \PYG{n+nb}{min}\PYG{p}{(}\PYG{n}{table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Cost}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{No Abatement}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{n}{abatement} \PYG{o}{=} \PYG{n}{table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Cost}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{below\PYGZus{}or\PYGZus{}equal\PYGZus{}to}\PYG{p}{(}\PYG{n}{tax}\PYG{p}{)}\PYG{p}{)}
        \PYG{n}{total\PYGZus{}abatement} \PYG{o}{=} \PYG{n+nb}{sum}\PYG{p}{(}\PYG{n}{abatement}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Potential}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
        \PYG{n}{abatement\PYGZus{}technologies} \PYG{o}{=} \PYG{n}{abatement}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement technology}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Methane tax: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tax}\PYG{p}{)}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Total Abatement: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{total\PYGZus{}abatement}\PYG{p}{)}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Abatement Technologies}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{abatement\PYGZus{}technologies}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}The group\PYGZus{}plot function used for plotting (out of scope)}
\PYG{k}{def} \PYG{n+nf}{group\PYGZus{}plot}\PYG{p}{(}\PYG{n}{tax}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Methane: \PYGZdl{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{tax}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{methane\PYGZus{}tax}\PYG{p}{(}\PYG{n}{tax}\PYG{p}{,} \PYG{n}{Group}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{9}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{bar}\PYG{p}{(}\PYG{n}{new\PYGZus{}x\PYGZus{}group}\PYG{p}{,} \PYG{n}{height\PYGZus{}group}\PYG{p}{,}\PYG{n}{width}\PYG{o}{=}\PYG{n}{width\PYGZus{}group}\PYG{p}{,}\PYG{n}{edgecolor} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{black}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{n}{selection}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Potential}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Cost}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{axhline}\PYG{p}{(}\PYG{n}{y}\PYG{o}{=}\PYG{n}{tax}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{linewidth} \PYG{o}{=} \PYG{l+m+mi}{2}\PYG{p}{)}
    
\PYG{n}{group\PYGZus{}plot}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Methane: \PYGZdl{}4
Methane tax:  4
Total Abatement:  4579.399996707216

Abatement Technologies [\PYGZsq{}Replace pumps\PYGZsq{} \PYGZsq{}Blowdown capture\PYGZsq{} \PYGZsq{}Replace with instrument air systems\PYGZsq{}
 ... \PYGZsq{}Downstream LDAR\PYGZsq{} \PYGZsq{}Replace with electric motor\PYGZsq{}
 \PYGZsq{}Replace with electric motor\PYGZsq{}]
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{textbook1_20_1}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}Prepare data for plotting (second round)}
\PYG{n}{width} \PYG{o}{=} \PYG{n}{abatement\PYGZus{}table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Potential}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{height} \PYG{o}{=} \PYG{n}{abatement\PYGZus{}table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Cost}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{new\PYGZus{}x} \PYG{o}{=} \PYG{n}{find\PYGZus{}x\PYGZus{}pos}\PYG{p}{(}\PYG{n}{width}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}Let\PYGZsq{}s give each type of technology a different color!}
\PYG{n}{abatement\PYGZus{}colors\PYGZus{}dict} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{count} \PYG{o}{=} \PYG{l+m+mi}{0}
\PYG{n}{colors} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}EC5F67}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}F29056}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}F9C863}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}99C794}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}5FB3B3}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}6699CC}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}C594C5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}85E827}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}F165FD}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}1F9F7F}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}945CF8}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}ff3a1d}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}2a8506}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{set}\PYG{p}{(}\PYG{n}{abatement\PYGZus{}table}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement technology}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{abatement\PYGZus{}colors\PYGZus{}dict}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{=} \PYG{n}{colors}\PYG{p}{[}\PYG{n}{count}\PYG{p}{]}
    \PYG{n}{count} \PYG{o}{+}\PYG{o}{=} \PYG{l+m+mi}{1}

\PYG{n}{colors\PYGZus{}mapped} \PYG{o}{=} \PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{pd}\PYG{o}{.}\PYG{n}{Series}\PYG{p}{(}\PYG{n}{abatement\PYGZus{}table}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement technology}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{map}\PYG{p}{(}\PYG{n}{abatement\PYGZus{}colors\PYGZus{}dict}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{abatement\PYGZus{}table} \PYG{o}{=} \PYG{n}{abatement\PYGZus{}table}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Color}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{colors\PYGZus{}mapped}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}The Methane curve plot \PYGZhy{} function!}
\PYG{k}{def} \PYG{n+nf}{mckinsey\PYGZus{}curve}\PYG{p}{(}\PYG{n}{tax}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Methane Tax: \PYGZdl{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{tax}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{methane\PYGZus{}tax}\PYG{p}{(}\PYG{n}{tax}\PYG{p}{,} \PYG{n}{abatement\PYGZus{}table}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{18}\PYG{p}{,}\PYG{l+m+mi}{12}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{bar}\PYG{p}{(}\PYG{n}{new\PYGZus{}x}\PYG{p}{,} \PYG{n}{height}\PYG{p}{,} \PYG{n}{width}\PYG{o}{=}\PYG{n}{width}\PYG{p}{,} \PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{n}{abatement\PYGZus{}table}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Color}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{edgecolor} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{black}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{The McKinsey Abatement Cost Curve (MAC)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Potential}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Abatement Cost}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{axhline}\PYG{p}{(}\PYG{n}{y}\PYG{o}{=}\PYG{n}{tax}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{linewidth} \PYG{o}{=} \PYG{l+m+mi}{2}\PYG{p}{)}

    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{bar}\PYG{p}{(}\PYG{n}{abatement\PYGZus{}colors\PYGZus{}dict}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{color} \PYG{o}{=} \PYG{n}{abatement\PYGZus{}colors\PYGZus{}dict}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xticks}\PYG{p}{(}\PYG{n}{rotation}\PYG{o}{=}\PYG{l+m+mi}{60}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Legend}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    
\PYG{n}{mckinsey\PYGZus{}curve}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Methane Tax: \PYGZdl{}3
Methane tax:  3
Total Abatement:  19371.639972971752

Abatement Technologies [\PYGZsq{}Replace pumps\PYGZsq{} \PYGZsq{}Blowdown capture\PYGZsq{} \PYGZsq{}Replace with instrument air systems\PYGZsq{}
 ... \PYGZsq{}Install flares\PYGZsq{} \PYGZsq{}Install flares\PYGZsq{} \PYGZsq{}Replace with electric motor\PYGZsq{}]
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{textbook1_23_1}.png}

\noindent\sphinxincludegraphics{{textbook1_23_2}.png}

\sphinxAtStartPar
What a plot! From here, we can differentiate the multiple methane abatement technologies on a cost basis, finding the most efficient ways of reducing methane emissions from gas production. We also observe the result of introducing a tax: With a tax of \$3 per ton, we expect the total abatement to be almost 20.000 tons within our industry.


\subsubsection{The MAC curve’s important limitations}
\label{\detokenize{content/12-environmental/textbook1:the-mac-curve-s-important-limitations}}
\sphinxAtStartPar
Before moving on to the next topic of this chapter, we ought to consider the drawbacks of our newfound knowledge:


\paragraph{Limitation 1: Introducing Capital Intensity}
\label{\detokenize{content/12-environmental/textbook1:limitation-1-introducing-capital-intensity}}
\sphinxAtStartPar
From the MAC curve for CO2 (see figure 1), we are interested in finding the \sphinxstylestrong{capital intensity of an intervention}. This is different from the \sphinxstylestrong{Marginal Abatement Cost}, as it does not take potential savings from e.g lower energy consumption in the future into its calculation. However, it’s a great measurement for which technologies require the highest \sphinxstyleemphasis{upfront capital} investment to abate an amount of GHG.

\sphinxAtStartPar
The formula is as follows:
\begin{equation*}
\begin{split}CI = \frac{\text{Additional Investment}}{\text{Lifetime Emissions Savings}}\end{split}
\end{equation*}
\sphinxAtStartPar
Where Additional Investment is the the additional upfront investment for new technology relative to the Business as Usual (BAU) alternative).

\sphinxAtStartPar
Had we re\sphinxhyphen{}arranged the MAC curve from figure 1 for capital intensity, it would have looked like this:

\sphinxAtStartPar
\sphinxincludegraphics{{ci_curve}.png}


\paragraph{Limitation 2: Lack of Dynamic Cost Assessment}
\label{\detokenize{content/12-environmental/textbook1:limitation-2-lack-of-dynamic-cost-assessment}}
\sphinxAtStartPar
The most crucial limitations of the MAC curve is its inability to consider \sphinxstylestrong{Dynamic Costs}. In 2009, when the MAC was first created, it only considered \sphinxstylestrong{Static Costs}. Let’s define them within the context of solar energy prices (graph below):

\sphinxAtStartPar
\sphinxstylestrong{Static Costs}
\begin{itemize}
\item {} 
\sphinxAtStartPar
The fixed costs of a new intervention, unchanged over a lifetime of an investment. Think of it as the costs you observe from this current point of view in time and expect to pay years ahead. For example, the 1976 Solar Energy Price at +100 USD/Watt.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Dynamic Costs}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Cost considering potential cost\sphinxhyphen{}reduction from increased efficiency, learning\sphinxhyphen{}by\sphinxhyphen{}doing, and other positive spillovers. For example, the actual cost of Solar Energy in 2019 at below 1 USD/Watt.

\end{itemize}

\sphinxAtStartPar
As a result of this shortcoming, the MAC curve tends to \sphinxstyleemphasis{overestimate costs} and do not fully represent the required investments within the energy transition (Kesicki and Edwins, 2012; Vogt\sphinxhyphen{}Schilb et al., 2015). It is not hard to understand that people were skeptical of investing in solar energy when the static costs were that high! A current example of this is the Carbon Capture \& Storage (CCS) intervention: With high static costs, it might look like an unfavourable investment. What would it look like if we took dynamic costs into our calculations?

\sphinxAtStartPar
\sphinxstylestrong{A final note on the MAC curve:} As future data scientists, we have a responsibility to improve the MAC curve, and use our skills in prediction and analysis to assess dynamic costs in GHG abatement with higher certainty. The original McKinsey MAC has rounded its 10th year anniversary. Perhaps it’s time for you to build a new one?

\sphinxAtStartPar
\sphinxincludegraphics{{pv_prices}.png}


\subsubsection{What’s next?}
\label{\detokenize{content/12-environmental/textbook1:what-s-next}}
\sphinxAtStartPar
If you are interested in this area, there are even more fascinating applications of Data Science to environmental topics such as: finding the social cost of carbon, the valuation of our environment, and the economics of emissions trading. Besides purely economical modeling, the field of environmental data science is rapidly growing as we collect more and more data on our planet and its resources. Data Science can apply to these problems the power of Satellite Imagery, Machine Learning, and Geographic Information Systems (GIS).  These tools can help to build a positive impact in shaping a data\sphinxhyphen{}informed, sustainable future.


\subsubsection{Further recommended readings}
\label{\detokenize{content/12-environmental/textbook1:further-recommended-readings}}
\sphinxAtStartPar
Levelized Cost of Carbon Abatement: An Improved Cost\sphinxhyphen{}Assessment Methodology for a Net\sphinxhyphen{}Zero Emissions World (also the main source of this Jupyter Notebook)

\sphinxAtStartPar
\sphinxurl{https://www.energypolicy.columbia.edu/sites/default/files/file-uploads/LCCA\_CGEP-Report\_101620.pdf}

\sphinxAtStartPar
Dynamic vs. Static costs are described further in in K.Gillingham \& J.H Stock’s The Cost of Reducing Greenhouse Gas Emissions (italic) from 2018. \sphinxhyphen{} A highly recommended reading out of scope for this class.

\sphinxAtStartPar
\sphinxurl{https://scholar.harvard.edu/files/stock/files/gillingham\_stock\_cost\_080218\_posted.pdf}

\sphinxAtStartPar
Goldman Sachs Research: Carbonomics: The Future of Energy in the Age of Climate Change

\sphinxAtStartPar
\sphinxurl{https://www.goldmansachs.com/insights/pages/carbonomics.html}

\sphinxAtStartPar
EPA article on the Economics of Climate Change:
\sphinxurl{https://www.epa.gov/environmental-economics/economics-climate-change}

\sphinxAtStartPar
Draw your own curve program:
\sphinxurl{https://tamc.github.io/macc/}

\sphinxAtStartPar
Abatement curve for crops:
\sphinxurl{https://github.com/aj-sykes92/ggmacc/blob/main/README\_files/figure-gfm/full-macc-1.png}

\sphinxAtStartPar
Aalborg University’s software:
\sphinxurl{https://github.com/matpri/EPLANoptMAC}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} HIDDEN}
\PYG{c+c1}{\PYGZsh{}Importing packages}
\PYG{k+kn}{from} \PYG{n+nn}{datascience} \PYG{k+kn}{import} \PYG{o}{*}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k+kn}{import} \PYG{n}{patches}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\end{sphinxVerbatim}


\subsection{Environmental Kuznets Curve Hypothesis}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:environmental-kuznets-curve-hypothesis}}\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1::doc}}
\sphinxAtStartPar
The Environmental Kuznets curve hypothesis that the economic development of a nation is associated with a downward\sphinxhyphen{}facing U\sphinxhyphen{}shape.  The Y\sphinxhyphen{}axis is in terms of the level of environmental degradation (e.g pollution, water quality, deforestation.  The X\sphinxhyphen{}axis would be the GDP/capita.  The idea is that the environmental degradation worsens, until a certain level of income, and after which it gets better. In the US this could be seen in terms of air or water quality, where the skies or rivers were very polluted in the 1960s, until the Clean Air Act and Clean Water Act were passed and Air Quality and Water Quality improved.  Another motivation for the downward slope would be the idea that at some point a wealthier society demands environmental improvements.However \sphinxhyphen{} could this hold for the potentially most important Pollutant C02, the main driver of anthropogenic climate change.  Controversially the impacts of global CO2 pollution are not experienced locally, but are experienced as global effects. So it is not clear whether the Environmental Kuznets hypothesis will hold.

\sphinxAtStartPar
Today, we’ll look to build an C02 Kuznets curve for an \sphinxstyleemphasis{association} between the amount of CO2 emitted per capita (t/CO2) and the growing GDP per capita (USD). This dataset is collected from Our World in Data, a great source of all sorts of data types!

\sphinxAtStartPar
\sphinxincludegraphics{{kuznets}.png}


\subsubsection{Building our own Environmental Kuznets Curve}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:building-our-own-environmental-kuznets-curve}}
\sphinxAtStartPar
We start by importing data on GDP per capita and Per Capita CO2 emissions for every country in the world for as long as it has been recorded.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{co2\PYGZus{}table} \PYG{o}{=} \PYG{n}{Table}\PYG{o}{.}\PYG{n}{read\PYGZus{}table}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{co2\PYGZhy{}emissions\PYGZhy{}vs\PYGZhy{}gdp.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{145446\PYGZhy{}annotations}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Total population (Gapminder, HYDE \PYGZam{} UN)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Code}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{co2\PYGZus{}table} \PYG{o}{=} \PYG{n}{co2\PYGZus{}table}\PYG{o}{.}\PYG{n}{relabeled}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Entity}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{co2\PYGZus{}table}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Country     | Year | Per capita CO2 emissions | GDP per capita | Continent
Abkhazia    | 2015 | nan                      | nan            | Asia
Afghanistan | 1949 | 0.00191237               | nan            | nan
Afghanistan | 1950 | 0.010871                 | 1156           | nan
Afghanistan | 1951 | 0.0116837                | 1170           | nan
Afghanistan | 1952 | 0.0115423                | 1189           | nan
Afghanistan | 1953 | 0.0132159                | 1240           | nan
Afghanistan | 1954 | 0.0130359                | 1245           | nan
Afghanistan | 1955 | 0.0186057                | 1246           | nan
Afghanistan | 1956 | 0.0218121                | 1278           | nan
Afghanistan | 1957 | 0.0343433                | 1253           | nan
... (53427 rows omitted)
\end{sphinxVerbatim}


\paragraph{Low Income Countries}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:low-income-countries}}
\sphinxAtStartPar
Let’s start by selecting a set of Low Income Countries to graph the movement of CO2 intensity

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}Low\PYGZhy{}Income Nations}
\PYG{n}{LIH\PYGZus{}array} \PYG{o}{=} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Haiti}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Afghanistan}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Rwanda}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Pakistan}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Nicaragua}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{LIH\PYGZus{}table} \PYG{o}{=} \PYG{n}{co2\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{contained\PYGZus{}in}\PYG{p}{(}\PYG{n}{LIH\PYGZus{}array}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{LIH\PYGZus{}table} \PYG{o}{=} \PYG{n}{LIH\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{above\PYGZus{}or\PYGZus{}equal\PYGZus{}to}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{above\PYGZus{}or\PYGZus{}equal\PYGZus{}to}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dpi}\PYG{o}{=}\PYG{l+m+mi}{250}\PYG{p}{)}
\PYG{n}{LIH\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{group}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}Figure size 2000x1500 with 0 Axes\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_7_1}.png}

\sphinxAtStartPar
Note that each dot represents a nation at a given level of emissions and GDP per capita

\sphinxAtStartPar
With these three countries we see a few different stories:
\begin{itemize}
\item {} 
\sphinxAtStartPar
In Afghanistan, Haiti and Rwanda we see little income growth and little CO2 intensity growth with a slight upward trend

\item {} 
\sphinxAtStartPar
In Nicaragua we see some jumping around, in fact Nicaragua GDP per capita has gone up and down, as has CO2 per capita

\item {} 
\sphinxAtStartPar
In Pakistan, a larger and more populous country we see strong linear upward growth in both GDP per capita and CO2 per capita, with no signs of turning down

\end{itemize}

\sphinxAtStartPar
In these countries it is hard to tell the complete story without the exact time trend.


\paragraph{BRICS}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:brics}}
\sphinxAtStartPar
Lets look at the BRICS countries, the rapidly growing upper middle income countries

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{BRICS\PYGZus{}array} \PYG{o}{=} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Brazil}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Russia}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{India}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{China}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{South Africa}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{BRICS\PYGZus{}table} \PYG{o}{=} \PYG{n}{co2\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{contained\PYGZus{}in}\PYG{p}{(}\PYG{n}{BRICS\PYGZus{}array}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{BRICS\PYGZus{}table} \PYG{o}{=} \PYG{n}{BRICS\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{above\PYGZus{}or\PYGZus{}equal\PYGZus{}to}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{above\PYGZus{}or\PYGZus{}equal\PYGZus{}to}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{BRICS\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{group}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_10_0}.png}

\sphinxAtStartPar
The BRICS nations seem to have a variety of development pathways but all show the linear trend of increasing emissions as wealth grows.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Russia has an interesting dip while GDP per capita decrease and then increase again

\item {} 
\sphinxAtStartPar
South Africa has a recent period where growth in both GDP per capita and CO2 per capita have stagnated

\item {} 
\sphinxAtStartPar
China and India show linearly increasing trends, with China both wealthier and more CO2 intensive

\end{itemize}


\subsubsection{Individual country graphs}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:individual-country-graphs}}
\sphinxAtStartPar
Lets look at some individual countries, starting with the US.We can plot both total and logged quantities


\paragraph{USA}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:usa}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{US\PYGZus{}table} \PYG{o}{=} \PYG{n}{co2\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{United States}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Year}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{between}\PYG{p}{(}\PYG{l+m+mi}{1800}\PYG{p}{,}\PYG{l+m+mi}{2018}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{US\PYGZus{}table} \PYG{o}{=} \PYG{n}{US\PYGZus{}table}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogGDP}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{US\PYGZus{}table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogCO2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{US\PYGZus{}table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{US\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{US\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogGDP}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogCO2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_14_0}.png}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_14_1}.png}

\sphinxAtStartPar
\sphinxstylestrong{Looks like we have a curve!}

\sphinxAtStartPar
In the case of the US it does indeed look like the C02 per capita does indeed start to deline after about \$40,000
Somewhere around 2000\sphinxhyphen{}2004 the CO2 emissions leveled off and then began to decline


\paragraph{China}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:china}}
\sphinxAtStartPar
In COP26, China has been a large part of the discussion (and emissions). Let’s have a look at their curve!

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}China Example + LOG}
\PYG{n}{NO\PYGZus{}table} \PYG{o}{=} \PYG{n}{co2\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{China}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Year}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{between}\PYG{p}{(}\PYG{l+m+mi}{1800}\PYG{p}{,}\PYG{l+m+mi}{2018}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{NO\PYGZus{}table} \PYG{o}{=} \PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogGDP}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogCO2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogGDP}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogCO2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_17_0}.png}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_17_1}.png}

\sphinxAtStartPar
Indeed it appears that China has an inflection point and is starting to level off in the Carbon intensity per capita


\paragraph{India}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:india}}
\sphinxAtStartPar
What about India?

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}India Example + LOG}
\PYG{n}{NO\PYGZus{}table} \PYG{o}{=} \PYG{n}{co2\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{India}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Year}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{between}\PYG{p}{(}\PYG{l+m+mi}{1800}\PYG{p}{,}\PYG{l+m+mi}{2018}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{NO\PYGZus{}table} \PYG{o}{=} \PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogGDP}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogCO2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogGDP}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogCO2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_20_0}.png}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_20_1}.png}


\paragraph{Norway}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:norway}}
\sphinxAtStartPar
As I’m Norwegian, I thought it might be cool to see how things are going back home as well:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}Norway Example + LOG}
\PYG{n}{NO\PYGZus{}table} \PYG{o}{=} \PYG{n}{co2\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Norway}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Year}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{between}\PYG{p}{(}\PYG{l+m+mi}{1800}\PYG{p}{,}\PYG{l+m+mi}{2018}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{NO\PYGZus{}table} \PYG{o}{=} \PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogGDP}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{with\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogCO2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{column}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{NO\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogGDP}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LogCO2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_22_0}.png}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_22_1}.png}

\sphinxAtStartPar
Turns out we’re ahead of the US in CO2 emissions per capita, but there’s still a long way to go until our development resembles a full Kuznets curve. However, it certainly looks like something! An almost vertical linear growth in terms of per capita CO2 emissions in the early economic stages stagnated into a period of fluctuations. As of now, it looks like it’s heading in a downward trend.

\sphinxAtStartPar
Let’s look at a set of other High Income Nations:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{HIN\PYGZus{}array} \PYG{o}{=} \PYG{n}{make\PYGZus{}array}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{United States}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Netherlands}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{United Kingdom}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Germany}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Canada}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{HIN\PYGZus{}table} \PYG{o}{=} \PYG{n}{co2\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{contained\PYGZus{}in}\PYG{p}{(}\PYG{n}{HIN\PYGZus{}array}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{HIN\PYGZus{}table} \PYG{o}{=} \PYG{n}{HIN\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{above\PYGZus{}or\PYGZus{}equal\PYGZus{}to}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{above\PYGZus{}or\PYGZus{}equal\PYGZus{}to}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{HIN\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{group}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_24_0}.png}

\sphinxAtStartPar
As in the US and Norway, these nations have experienced a boom, stagnation, and now to some extent a downward trend. Let’s finally plot all the previously observed nations together:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ALL\PYGZus{}array} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{LIH\PYGZus{}array}\PYG{p}{,}\PYG{n}{BRICS\PYGZus{}array}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{HIN\PYGZus{}array}\PYG{p}{)}
\PYG{n}{ALL\PYGZus{}table} \PYG{o}{=} \PYG{n}{co2\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{contained\PYGZus{}in}\PYG{p}{(}\PYG{n}{ALL\PYGZus{}array}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{ALL\PYGZus{}table} \PYG{o}{=} \PYG{n}{ALL\PYGZus{}table}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{above\PYGZus{}or\PYGZus{}equal\PYGZus{}to}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{are}\PYG{o}{.}\PYG{n}{above\PYGZus{}or\PYGZus{}equal\PYGZus{}to}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{ALL\PYGZus{}table}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GDP per capita}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Per capita CO2 emissions}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{group}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Country}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}What do we see? Can we spot the Environmental Kuznets Curve?}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{KuznetsHypothesis-Copy1_26_0}.png}

\sphinxAtStartPar
Here we see evidence for an Environmental Kuznets Curve.

\sphinxAtStartPar
It seems, at least to some extent, that as nations develop economically, the level of environmental degradation reaches a peak and then declines, mapping a downward\sphinxhyphen{}facing U\sphinxhyphen{}curve.


\subsubsection{Criticism of the Environmental Kuznets Curve Hypothesis}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:criticism-of-the-environmental-kuznets-curve-hypothesis}}
\sphinxAtStartPar
Some questions we ought to ask ourselves in the end are:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Do all types of environmental degradation follow the curve? What if we plot Energy, Land, \& Resource usage?

\item {} 
\sphinxAtStartPar
What we plotted today shows the ratio between GDP and CO2 per capita, but what about the \sphinxstyleemphasis{absolute} numbers of emissions?

\item {} 
\sphinxAtStartPar
What is the true long\sphinxhyphen{}term shape of the curve? Could it reshape itself to an “N” as an economy passes a certain threshold?

\item {} 
\sphinxAtStartPar
What about its applicability on a global scale? Knowing that the HINs have a habit of exporting pollution to LINs, what will happen as LIN grow economically?

\end{itemize}

\sphinxAtStartPar
These are just some questions environmental economists have asked themselves throughout the years since the curve was hypothesized in 1955. Some, including Perman and Stern (2003) conclude that the level of environmental degradation has much more to do with a constant “battle” between scale and time than income alone. As nations scale up (BRICS, for instance) the growth results in higher emissions, while countries with lower growth (LIN \& HIN) seem more influenced by the “time\sphinxhyphen{}effect”, which results in lower emissions. Others, among Krueger \& Grossman, argue that there is “no evidence that environmental quality deteriorates steadily with economic growth.”

\sphinxAtStartPar
More on these theories can be found in the recommended readings below.

\sphinxAtStartPar
As data scientists motivated to help heal the plant with the tools of environmental economics, we can help to find these answers!


\subsubsection{What’s next?}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:what-s-next}}
\sphinxAtStartPar
If you are interested in this area, there are even more fascinating applications of Data Science to environmental topics such as: finding the social cost of carbon, the valuation of our environment, and the economics of emissions trading. Besides purely economical modeling, the field of environmental data science is rapidly growing as we collect more and more data on our planet and its resources. Applying the power of Satellite Imagery, Machine Learning, and Geographic Information Systems (GIS), one can follow both technology and policy\sphinxhyphen{}based paths, both ensured to have a positive impact in shaping a data\sphinxhyphen{}driven, sustainable future.


\subsubsection{Further recommended readings}
\label{\detokenize{content/12-environmental/KuznetsHypothesis-Copy1:further-recommended-readings}}
\sphinxAtStartPar
Levelized Cost of Carbon Abatement: An Improved Cost\sphinxhyphen{}Assessment Methodology for a Net\sphinxhyphen{}Zero Emissions World (also the main source of this Jupyter Notebook)

\sphinxAtStartPar
\sphinxurl{https://www.energypolicy.columbia.edu/sites/default/files/file-uploads/LCCA\_CGEP-Report\_101620.pdf}

\sphinxAtStartPar
Dynamic vs. Static costs are described further in K.Gillingham \& J.H Stock’s The Cost of Reducing Greenhouse Gas Emissions (italic) from 2018. \sphinxhyphen{} A highly recommended reading out of scope for this class.

\sphinxAtStartPar
\sphinxurl{https://scholar.harvard.edu/files/stock/files/gillingham\_stock\_cost\_080218\_posted.pdf}

\sphinxAtStartPar
Goldman Sachs Research: Carbonomics: The Future of Energy in the Age of Climate Change

\sphinxAtStartPar
\sphinxurl{https://www.goldmansachs.com/insights/pages/carbonomics.html}

\sphinxAtStartPar
EPA article on the Economics of Climate Change:
\sphinxurl{https://www.epa.gov/environmental-economics/economics-climate-change}

\sphinxAtStartPar
Draw your own curve program:
\sphinxurl{https://tamc.github.io/macc/}

\sphinxAtStartPar
Abatement curve for crops:
\sphinxurl{https://github.com/aj-sykes92/ggmacc/blob/main/README\_files/figure-gfm/full-macc-1.png}

\sphinxAtStartPar
Aalborg University’s software:
\sphinxurl{https://github.com/matpri/EPLANoptMAC}


\section{Bibliography}
\label{\detokenize{content/references:bibliography}}\label{\detokenize{content/references::doc}}
\sphinxAtStartPar


\begin{sphinxthebibliography}{Car99}
\bibitem[BdP]{content/references:id5}
\sphinxAtStartPar
Marijn Bolhuis and Alexandra de Pleijt. Inequality fuels population growth: new cross\sphinxhyphen{}national evidence 1870\sphinxhyphen{}2000. URL: \sphinxurl{https://www.ehs.org.uk/press/inequality-fuels-population-growth-new-cross-national-evidence-1870-2000}.
\bibitem[Car99]{content/references:id2}
\sphinxAtStartPar
David Card. The causal effect of education on earnings. \sphinxstyleemphasis{Handbook of Labor Economics}, 1999. URL: \sphinxurl{https://davidcard.berkeley.edu/papers/causal\_educ\_earnings.pdf}.
\bibitem[Hoo41]{content/references:id3}
\sphinxAtStartPar
S Hoos. An investigation on complementarity relations between fresh fruits. \sphinxstyleemphasis{Journal of Farm Economics}, 23(2):421–433, 1941.
\bibitem[KS]{content/references:id4}
\sphinxAtStartPar
Homi Kharas and Brina Seidel. What's happening to the world income distribution? the elephant chart revisited. URL: \sphinxurl{https://www.brookings.edu/research/whats-happening-to-the-world-income-distribution-the-elephant-chart-revisited/}.
\bibitem[MIL16]{content/references:id6}
\sphinxAtStartPar
BRANKO MILANOVIC. \sphinxstyleemphasis{Global Inequality: A New Approach for the Age of Globalization}. Harvard University Press, 2016. ISBN 9780674737136. URL: \sphinxurl{http://www.jstor.org/stable/j.ctvjghwk4}.
\bibitem[Mor11]{content/references:id7}
\sphinxAtStartPar
Hanan Morsy. Unemployed in europe. \sphinxstyleemphasis{Finance \& development}, 09 2011. URL: \sphinxurl{https://www.researchgate.net/publication/341109902\_Unemployed\_in\_Europe}.
\end{sphinxthebibliography}







\renewcommand{\indexname}{Index}
\printindex
\end{document}